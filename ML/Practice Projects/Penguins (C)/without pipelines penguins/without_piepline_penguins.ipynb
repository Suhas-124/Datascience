{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the dataset:\n",
      "species               0\n",
      "island                0\n",
      "bill_length_mm        2\n",
      "bill_depth_mm         2\n",
      "flipper_length_mm     2\n",
      "body_mass_g           2\n",
      "sex                  11\n",
      "dtype: int64\n",
      "Missing values after imputation:\n",
      "species              0\n",
      "island               0\n",
      "bill_length_mm       0\n",
      "bill_depth_mm        0\n",
      "flipper_length_mm    0\n",
      "body_mass_g          0\n",
      "sex                  0\n",
      "dtype: int64\n",
      "\n",
      "Training with Random Forest...\n",
      "Accuracy for Random Forest: 1.0\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        69\n",
      "   macro avg       1.00      1.00      1.00        69\n",
      "weighted avg       1.00      1.00      1.00        69\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[32  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 21]]\n",
      "\n",
      "Training with Decision Tree...\n",
      "Accuracy for Decision Tree: 0.9855072463768116\n",
      "Classification Report for Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.99        69\n",
      "   macro avg       0.98      0.99      0.99        69\n",
      "weighted avg       0.99      0.99      0.99        69\n",
      "\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[31  0  1]\n",
      " [ 0 16  0]\n",
      " [ 0  0 21]]\n",
      "\n",
      "Training with SVM...\n",
      "Accuracy for SVM: 0.9855072463768116\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        32\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.99        69\n",
      "   macro avg       0.99      0.98      0.98        69\n",
      "weighted avg       0.99      0.99      0.99        69\n",
      "\n",
      "Confusion Matrix for SVM:\n",
      "[[32  0  0]\n",
      " [ 1 15  0]\n",
      " [ 0  0 21]]\n",
      "\n",
      "Training with Logistic Regression...\n",
      "Accuracy for Logistic Regression: 1.0\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        69\n",
      "   macro avg       1.00      1.00      1.00        69\n",
      "weighted avg       1.00      1.00      1.00        69\n",
      "\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[32  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 21]]\n",
      "\n",
      "Training with XGBoost...\n",
      "Accuracy for XGBoost: 0.9855072463768116\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.99        69\n",
      "   macro avg       0.98      0.99      0.99        69\n",
      "weighted avg       0.99      0.99      0.99        69\n",
      "\n",
      "Confusion Matrix for XGBoost:\n",
      "[[31  0  1]\n",
      " [ 0 16  0]\n",
      " [ 0  0 21]]\n",
      "\n",
      "Summary of results for all classifiers:\n",
      "\n",
      "Random Forest Classifier:\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        69\n",
      "   macro avg       1.00      1.00      1.00        69\n",
      "weighted avg       1.00      1.00      1.00        69\n",
      "\n",
      "Confusion Matrix:\n",
      "[[32  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 21]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Decision Tree Classifier:\n",
      "Accuracy: 0.9855072463768116\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.99        69\n",
      "   macro avg       0.98      0.99      0.99        69\n",
      "weighted avg       0.99      0.99      0.99        69\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31  0  1]\n",
      " [ 0 16  0]\n",
      " [ 0  0 21]]\n",
      "--------------------------------------------------\n",
      "\n",
      "SVM Classifier:\n",
      "Accuracy: 0.9855072463768116\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        32\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.99        69\n",
      "   macro avg       0.99      0.98      0.98        69\n",
      "weighted avg       0.99      0.99      0.99        69\n",
      "\n",
      "Confusion Matrix:\n",
      "[[32  0  0]\n",
      " [ 1 15  0]\n",
      " [ 0  0 21]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier:\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        69\n",
      "   macro avg       1.00      1.00      1.00        69\n",
      "weighted avg       1.00      1.00      1.00        69\n",
      "\n",
      "Confusion Matrix:\n",
      "[[32  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 21]]\n",
      "--------------------------------------------------\n",
      "\n",
      "XGBoost Classifier:\n",
      "Accuracy: 0.9855072463768116\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.99        69\n",
      "   macro avg       0.98      0.99      0.99        69\n",
      "weighted avg       0.99      0.99      0.99        69\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31  0  1]\n",
      " [ 0 16  0]\n",
      " [ 0  0 21]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Predictions for raw input data:\n",
      "Prediction using Random Forest: Adelie\n",
      "Prediction using Decision Tree: Gentoo\n",
      "Prediction using SVM: Adelie\n",
      "Prediction using Logistic Regression: Adelie\n",
      "Prediction using XGBoost: Adelie\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "df = sns.load_dataset('penguins')\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in the dataset:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Impute missing values\n",
    "numerical_columns = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "categorical_columns = ['sex', 'island']\n",
    "\n",
    "num_impute = SimpleImputer(strategy='median')\n",
    "df[numerical_columns] = num_impute.fit_transform(df[numerical_columns])\n",
    "\n",
    "cat_impute = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_columns] = cat_impute.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Check again for missing values\n",
    "print(\"Missing values after imputation:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns='species')\n",
    "y = df['species']\n",
    "\n",
    "# Encode the target variable\n",
    "y_encode = LabelEncoder()\n",
    "y = y_encode.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing steps\n",
    "ohe_encoded = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "# ColumnTransformer for categorical and numerical columns\n",
    "column_trans = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('island', ohe_encoded, ['island']),\n",
    "        ('sex', ohe_encoded, ['sex'])\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Preprocessing pipeline (imputation, one-hot encoding, scaling)\n",
    "preprocessor = Pipeline(steps=[\n",
    "    ('preprocessing', column_trans),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "pipelines = {}  # To store trained pipelines for predictions\n",
    "\n",
    "# Train and evaluate classifiers\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining with {name}...\")\n",
    "    \n",
    "    # Create a pipeline for each classifier\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Train the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Save the trained pipeline for this classifier\n",
    "    joblib.dump(pipeline, f'{name}_penguin_classifier.pkl')\n",
    "    pipelines[name] = pipeline  # Store pipeline for predictions\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate and store performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    cfm = confusion_matrix(y_test, y_pred)\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": classification_rep,\n",
    "        \"confusion_matrix\": cfm\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy for {name}: {accuracy}\")\n",
    "    print(f\"Classification Report for {name}:\\n{classification_rep}\")\n",
    "    print(f\"Confusion Matrix for {name}:\\n{cfm}\")\n",
    "    \n",
    "\n",
    "# Summary of results for all classifiers\n",
    "print(\"\\nSummary of results for all classifiers:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n{name} Classifier:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"Classification Report:\\n{metrics['classification_report']}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\")\n",
    "    print('-'*50)\n",
    "\n",
    "# Separate Section for Predictions\n",
    "# Raw input data\n",
    "raw_data = {\n",
    "    'bill_length_mm': [44.1],\n",
    "    'bill_depth_mm': [17.4],\n",
    "    'flipper_length_mm': [192.0],\n",
    "    'body_mass_g': [3400.0],\n",
    "    'sex': ['Female'],\n",
    "    'island': ['Torgersen']\n",
    "}\n",
    "raw_df = pd.DataFrame(raw_data)\n",
    "\n",
    "# Ensure the input columns match the training data columns\n",
    "expected_columns = X.columns.tolist()\n",
    "raw_df = raw_df[expected_columns]\n",
    "\n",
    "# Impute missing values (if necessary)\n",
    "raw_df[numerical_columns] = num_impute.transform(raw_df[numerical_columns])\n",
    "raw_df[categorical_columns] = cat_impute.transform(raw_df[categorical_columns])\n",
    "\n",
    "# Make predictions using each classifier\n",
    "print(\"\\nPredictions for raw input data:\")\n",
    "for name, pipeline in pipelines.items():\n",
    "    y_pred_raw = pipeline.predict(raw_df)\n",
    "    predicted_class = y_encode.inverse_transform(y_pred_raw)\n",
    "    print(f\"Prediction using {name}: {predicted_class[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
