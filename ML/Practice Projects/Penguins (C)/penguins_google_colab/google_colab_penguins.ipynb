{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBNetyYeRUgg",
        "outputId": "0f15f7aa-e8c9-4447-9a85-c09441a05b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in the dataset:\n",
            "species               0\n",
            "island                0\n",
            "bill_length_mm        2\n",
            "bill_depth_mm         2\n",
            "flipper_length_mm     2\n",
            "body_mass_g           2\n",
            "sex                  11\n",
            "dtype: int64\n",
            "Missing values after imputation:\n",
            "species              0\n",
            "island               0\n",
            "bill_length_mm       0\n",
            "bill_depth_mm        0\n",
            "flipper_length_mm    0\n",
            "body_mass_g          0\n",
            "sex                  0\n",
            "dtype: int64\n",
            "\n",
            "Training with Random Forest...\n",
            "Accuracy for Random Forest: 1.0\n",
            "Classification Report for Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        32\n",
            "           1       1.00      1.00      1.00        16\n",
            "           2       1.00      1.00      1.00        21\n",
            "\n",
            "    accuracy                           1.00        69\n",
            "   macro avg       1.00      1.00      1.00        69\n",
            "weighted avg       1.00      1.00      1.00        69\n",
            "\n",
            "Confusion Matrix for Random Forest:\n",
            "[[32  0  0]\n",
            " [ 0 16  0]\n",
            " [ 0  0 21]]\n",
            "--------------------------------------------------\n",
            "\n",
            "Training with Decision Tree...\n",
            "Accuracy for Decision Tree: 0.9420289855072463\n",
            "Classification Report for Decision Tree:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94        32\n",
            "           1       1.00      0.94      0.97        16\n",
            "           2       0.91      0.95      0.93        21\n",
            "\n",
            "    accuracy                           0.94        69\n",
            "   macro avg       0.95      0.94      0.95        69\n",
            "weighted avg       0.94      0.94      0.94        69\n",
            "\n",
            "Confusion Matrix for Decision Tree:\n",
            "[[30  0  2]\n",
            " [ 1 15  0]\n",
            " [ 1  0 20]]\n",
            "--------------------------------------------------\n",
            "\n",
            "Training with SVM...\n",
            "Accuracy for SVM: 0.9855072463768116\n",
            "Classification Report for SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98        32\n",
            "           1       1.00      0.94      0.97        16\n",
            "           2       1.00      1.00      1.00        21\n",
            "\n",
            "    accuracy                           0.99        69\n",
            "   macro avg       0.99      0.98      0.98        69\n",
            "weighted avg       0.99      0.99      0.99        69\n",
            "\n",
            "Confusion Matrix for SVM:\n",
            "[[32  0  0]\n",
            " [ 1 15  0]\n",
            " [ 0  0 21]]\n",
            "--------------------------------------------------\n",
            "\n",
            "Training with Logistic Regression...\n",
            "Accuracy for Logistic Regression: 1.0\n",
            "Classification Report for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        32\n",
            "           1       1.00      1.00      1.00        16\n",
            "           2       1.00      1.00      1.00        21\n",
            "\n",
            "    accuracy                           1.00        69\n",
            "   macro avg       1.00      1.00      1.00        69\n",
            "weighted avg       1.00      1.00      1.00        69\n",
            "\n",
            "Confusion Matrix for Logistic Regression:\n",
            "[[32  0  0]\n",
            " [ 0 16  0]\n",
            " [ 0  0 21]]\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "df = sns.load_dataset('penguins')\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values in the dataset:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Impute missing values\n",
        "numerical_columns = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
        "categorical_columns = ['sex', 'island']\n",
        "\n",
        "num_impute = SimpleImputer(strategy='median')\n",
        "df[numerical_columns] = num_impute.fit_transform(df[numerical_columns])\n",
        "\n",
        "cat_impute = SimpleImputer(strategy='most_frequent')\n",
        "df[categorical_columns] = cat_impute.fit_transform(df[categorical_columns])\n",
        "\n",
        "# Check again for missing values\n",
        "print(\"Missing values after imputation:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns='species')\n",
        "y = df['species']\n",
        "\n",
        "# Encode the target variable\n",
        "y_encode = LabelEncoder()\n",
        "y = y_encode.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define preprocessing steps\n",
        "ohe_encoded = OneHotEncoder(drop='first', sparse_output=False)\n",
        "\n",
        "# ColumnTransformer for categorical and numerical columns\n",
        "column_trans = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('island', ohe_encoded, ['island']),\n",
        "        ('sex', ohe_encoded, ['sex'])\n",
        "    ], remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Preprocessing pipeline (imputation, one-hot encoding, scaling)\n",
        "preprocessor = Pipeline(steps=[\n",
        "    ('preprocessing', column_trans),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    # \"XGBoost\": xgb.XGBClassifier(eval_metric='mlogloss')\n",
        "}\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "pipelines = {}  # To store trained pipelines for predictions\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "for name, clf in classifiers.items():\n",
        "    print(f\"\\nTraining with {name}...\")\n",
        "\n",
        "    # Create a pipeline for each classifier\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', clf)\n",
        "    ])\n",
        "\n",
        "    # Train the pipeline\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Save the trained pipeline for this classifier\n",
        "    joblib.dump(pipeline, f'{name}_penguin_classifier.pkl')\n",
        "    pipelines[name] = pipeline  # Store pipeline for predictions\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Calculate and store performance metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    classification_rep = classification_report(y_test, y_pred)\n",
        "    cfm = confusion_matrix(y_test, y_pred)\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"classification_report\": classification_rep,\n",
        "        \"confusion_matrix\": cfm\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Accuracy for {name}: {accuracy}\")\n",
        "    print(f\"Classification Report for {name}:\\n{classification_rep}\")\n",
        "    print(f\"Confusion Matrix for {name}:\\n{cfm}\")\n",
        "    print('-'*50)\n",
        "\n"
      ]
    }
  ]
}