{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in sample_df: 15\n",
      "Columns in sample_df: ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
      "Model: random_forest\n",
      "Prediction: [0]\n",
      "Prediction Probabilities: [[0.7 0.3]]\n",
      "--------------------------------------------------\n",
      "Model: decision_tree\n",
      "Prediction: [0]\n",
      "Prediction Probabilities: [[1. 0.]]\n",
      "--------------------------------------------------\n",
      "Model: svm\n",
      "Prediction: [0]\n",
      "--------------------------------------------------\n",
      "Model: lr\n",
      "Prediction: [1]\n",
      "Prediction Probabilities: [[0.1892058 0.8107942]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved models\n",
    "random_forest_pipeline = joblib.load(\"random_forest.pkl\")\n",
    "decision_tree_pipeline = joblib.load(\"decision_tree.pkl\")\n",
    "svm_pipeline = joblib.load(\"svm.pkl\")\n",
    "lr_pipeline = joblib.load(\"lr.pkl\")\n",
    "\n",
    "# List of loaded models for easy iteration\n",
    "models = {\n",
    "    \"random_forest\": random_forest_pipeline,\n",
    "    \"decision_tree\": decision_tree_pipeline,\n",
    "    \"svm\": svm_pipeline,\n",
    "    \"lr\": lr_pipeline\n",
    "}\n",
    "\n",
    "# Define the columns used during training\n",
    "# These columns must match the columns used in the training data\n",
    "training_columns = [\n",
    "    'age', 'job', 'marital', 'education', 'default', 'housing', 'loan', \n",
    "    'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', \n",
    "    'previous', 'poutcome'\n",
    "]\n",
    "\n",
    "# Example input for prediction\n",
    "sample_input = {\n",
    "    'age': None,                          # Numerical feature\n",
    "    'duration': [180],                    # Numerical feature\n",
    "    'campaign': [2],                      # Numerical feature\n",
    "    'pdays': [10],                        # Numerical feature\n",
    "    'previous': [0],                      # Numerical feature\n",
    "    'job': ['admin.'],                    # Categorical feature\n",
    "    'marital': ['married'],               # Categorical feature\n",
    "    'education': ['university.degree'],   # Categorical feature\n",
    "    'default': ['no'],                    # Categorical feature\n",
    "    'housing': ['no'],                   # Categorical feature\n",
    "    'loan': [np.NaN],                       # Categorical feature\n",
    "    'contact': ['cellular'],              # Categorical feature\n",
    "    'month': ['may'],                     # Categorical feature\n",
    "    'day_of_week': ['mon'],               # Categorical feature\n",
    "    'poutcome': ['success']               # Categorical feature\n",
    "}\n",
    "\n",
    "# Convert the sample input into a DataFrame\n",
    "sample_df = pd.DataFrame(sample_input)\n",
    "\n",
    "# Ensure all columns from training data are present in sample_df\n",
    "missing_columns = set(training_columns) - set(sample_df.columns)\n",
    "for col in missing_columns:\n",
    "    sample_df[col] = 0  # Default value for missing columns (adjust as needed)\n",
    "\n",
    "# Reorder columns to match the training data\n",
    "sample_df = sample_df[training_columns]\n",
    "\n",
    "print(f\"Number of features in sample_df: {sample_df.shape[1]}\")\n",
    "print(f\"Columns in sample_df: {sample_df.columns.tolist()}\")\n",
    "\n",
    "# Make predictions using all models\n",
    "for name, model in models.items():\n",
    "    prediction = model.predict(sample_df)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    if hasattr(model, \"predict_proba\"):  # Check if the model supports probability estimates\n",
    "        prediction_proba = model.predict_proba(sample_df)\n",
    "        print(f\"Prediction Probabilities: {prediction_proba}\")\n",
    "    print('-' * 50)\n",
    "\n",
    "# Save predictions to a CSV file (optional)\n",
    "predictions = []\n",
    "for name, model in models.items():\n",
    "    prediction = model.predict(sample_df)\n",
    "    predictions.append({\n",
    "        \"Model\": name,\n",
    "        \"Prediction\": prediction[0]\n",
    "    })\n",
    "\n",
    "# Convert predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Save to CSV\n",
    "predictions_df.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
