{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ **What is Hypothesis Testing?**\n",
    "\n",
    "Hypothesis testing is like being a detective for data! ğŸ•µï¸â€â™‚ï¸ Itâ€™s a statistical method to decide whether a claim (hypothesis) about a population is supported by sample data. Think of it as answering: **â€œIs there enough evidence to believe this claim?â€**\n",
    "\n",
    "\n",
    "### ğŸŒŸ **Key Components of Hypothesis Testing:**\n",
    "\n",
    "1. **ğŸ¯ Null Hypothesis ($H_0$)**:  \n",
    "   - The starting assumption or default claim.  \n",
    "   - Typically states **\"no effect\"** or **\"no difference.\"**  \n",
    "   - Example: **\"The average test score is 75.\"**\n",
    "\n",
    "2. **ğŸ” Alternative Hypothesis ($H_a$)**:  \n",
    "   - The statement we aim to find evidence for.  \n",
    "   - Opposite of the null hypothesis.  \n",
    "   - Example: **\"The average test score is NOT 75.\"**\n",
    "\n",
    "3. **ğŸ“ Significance Level ($\\alpha$)**:  \n",
    "   - The threshold to decide if the results are statistically significant.  \n",
    "   - Common values: **5% (0.05)** or **1% (0.01).**  \n",
    "   - Itâ€™s the risk of rejecting $H_0$ when itâ€™s actually true (Type I error).\n",
    "\n",
    "4. **ğŸ“Š Test Statistic**:  \n",
    "   - A number calculated from the data.  \n",
    "   - Shows how far the sample data is from $H_0$.  \n",
    "   - Examples: **$z$-score, $t$-score.**\n",
    "\n",
    "5. **ğŸ² P-Value**:  \n",
    "   - The probability of observing the test results (or more extreme ones) assuming $H_0$ is true.  \n",
    "   - **Low P-value (< $\\alpha$)**: Reject $H_0$.  \n",
    "   - **High P-value (> $\\alpha$)**: Fail to reject $H_0$.\n",
    "\n",
    "6. **âœ… Conclusion**:  \n",
    "   - Decide whether to reject or fail to reject $H_0$ based on the P-value.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§ª **Steps in Hypothesis Testing**:\n",
    "\n",
    "1. **Define Hypotheses**:  \n",
    "   Example:  \n",
    "   - **$H_0$**: The average cookie weight is 50 grams. ğŸª  \n",
    "   - **$H_a$**: The average cookie weight is NOT 50 grams.\n",
    "\n",
    "2. **Set Significance Level ($\\alpha$)**:  \n",
    "   - Example: Choose **$\\alpha = 0.05$ (5%)**.\n",
    "\n",
    "3. **Collect Data**:  \n",
    "   - Example: Weigh a sample of cookies (say, 30 cookies). ğŸª\n",
    "\n",
    "4. **Compute Test Statistic**:  \n",
    "   - Calculate how different the sample data is from $H_0$.\n",
    "\n",
    "5. **Find the P-Value**:  \n",
    "   - Use statistical software or tables to calculate the probability of the observed data.\n",
    "\n",
    "6. **Make a Decision**:  \n",
    "   - **If P-value â‰¤ $\\alpha$:** Reject $H_0$ ğŸ‰  \n",
    "   - **If P-value > $\\alpha$:** Fail to reject $H_0$ ğŸ¤”  \n",
    "\n",
    "7. **Draw a Conclusion**:  \n",
    "   - Example: â€œThe cookies likely donâ€™t weigh 50 grams on average.â€\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ” **Types of Hypothesis Tests:**\n",
    "\n",
    "1. **ğŸ‘‰ One-Tailed Test**:  \n",
    "   Tests if a parameter is **greater than** or **less than** a certain value.  \n",
    "   Example:  \n",
    "   - $H_0$: \"Mean â‰¤ 75.\"  \n",
    "   - $H_a$: \"Mean > 75.\"\n",
    "\n",
    "2. **ğŸ”„ Two-Tailed Test**:  \n",
    "   Tests if a parameter is **different (either higher or lower)** from a certain value.  \n",
    "   Example:  \n",
    "   - $H_0$: \"Mean = 75.\"  \n",
    "   - $H_a$: \"Mean â‰  75.\"\n",
    "\n",
    "\n",
    "\n",
    "### ğŸª **Example in Laymanâ€™s Terms: The Cookie Detective!**\n",
    "\n",
    "You claim: **\"My cookies weigh 50 grams on average.\"** A skeptical customer decides to test your claim.\n",
    "\n",
    "1. **Null Hypothesis ($H_0$)**: Your claim is true (cookies weigh 50g).  \n",
    "2. **Alternative Hypothesis ($H_a$)**: Your claim is false (cookies donâ€™t weigh 50g).  \n",
    "3. **Significance Level ($\\alpha$)**: The customer sets $\\alpha = 0.05$.  \n",
    "4. **Data Collection**: The customer weighs 30 cookies.  \n",
    "5. **Test Statistic**: A calculation based on the weights.  \n",
    "6. **P-Value**: Probability of getting these weights if $H_0$ is true.  \n",
    "7. **Conclusion**:  \n",
    "   - **If P â‰¤ 0.05**: The customer rejects $H_0$, saying, â€œYour cookies donâ€™t weigh 50g!â€  \n",
    "   - **If P > 0.05**: The customer fails to reject $H_0$, accepting the claim as plausible.\n",
    "\n",
    "### ğŸ¨ **Visual Summary:**\n",
    "\n",
    "| **Component**          | **Explanation**                           | **Example**                   |\n",
    "|-------------------------|-------------------------------------------|-------------------------------|\n",
    "| **Null Hypothesis ($H_0$)** | The default claim                     | \"Cookies weigh 50g.\" ğŸª        |\n",
    "| **Alternative Hypothesis ($H_a$)** | What we want to prove             | \"Cookies donâ€™t weigh 50g.\"    |\n",
    "| **Significance Level ($\\alpha$)** | Risk of false rejection            | 5% (0.05)                     |\n",
    "| **P-Value**             | Evidence against $H_0$                 | P = 0.036 (Reject $H_0$)    |\n",
    "| **Decision**            | Reject or Fail to Reject $H_0$         | \"Cookies likely â‰  50g.\" ğŸ‰    |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ’¡ **Common Mistakes to Avoid:**\n",
    "\n",
    "1. **Confusing \"Failing to Reject $H_0$\" with \"Accepting $H_0$\"**:  \n",
    "   - Failing to reject $H_0$ doesnâ€™t mean $H_0$ is true! It just means the evidence isnâ€™t strong enough.\n",
    "\n",
    "2. **Ignoring Sample Size**:  \n",
    "   - Small sample sizes can lead to unreliable results. ğŸ“‰\n",
    "\n",
    "3. **Misinterpreting P-Values**:  \n",
    "   - A low P-value doesnâ€™t mean $H_a$ is 100% true, just that $H_0$ is unlikely.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸš¦ **Rejection Region Approach in Hypothesis Testing**\n",
    "\n",
    "The **Rejection Region Approach** is a classic method used in hypothesis testing to decide whether to reject the null hypothesis ($H_0$). Itâ€™s like drawing a boundary on a graph ğŸ“‰â€”if the test statistic falls in the **\"Rejection Region\"**, we reject $H_0$.  \n",
    "\n",
    "Letâ€™s break it down step by step with a splash of color ğŸŒˆ!\n",
    "\n",
    "\n",
    "\n",
    "### ğŸŒŸ **Key Concepts in Rejection Region Approach**\n",
    "\n",
    "1. **Rejection Region** ğŸ¯:  \n",
    "   - This is the area in the tails of the distribution where the null hypothesis ($H_0$) is unlikely to be true.  \n",
    "   - If your test statistic lands here, itâ€™s a signal to reject $H_0$. ğŸš«  \n",
    "\n",
    "2. **Critical Value** ğŸš©:  \n",
    "   - The cutoff point(s) that define the boundary of the rejection region.  \n",
    "   - Determined based on the **significance level ($\\alpha$)**.  \n",
    "\n",
    "3. **Test Statistic** ğŸ“Š:  \n",
    "   - A value calculated from the sample data.  \n",
    "   - If this value is more extreme than the critical value, itâ€™s in the rejection region.\n",
    "\n",
    "4. **Decision Rule** âœ…:  \n",
    "   - **If Test Statistic is in the Rejection Region:** Reject $H_0$.  \n",
    "   - **If Test Statistic is outside the Rejection Region:** Fail to reject $H_0$.  \n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§ª **Steps in Rejection Region Approach**\n",
    "\n",
    "1. **State the Hypotheses** ğŸ¯:  \n",
    "   - Define $H_0$ and $H_a$ based on the problem.  \n",
    "\n",
    "2. **Choose the Significance Level ($\\alpha$)** ğŸ“:  \n",
    "   - Example: $\\alpha = 0.05$.  \n",
    "\n",
    "3. **Determine the Critical Value(s)** ğŸš©:  \n",
    "   - Use statistical tables (e.g., $z$-table, $t$-table) or software to find the cutoff.  \n",
    "\n",
    "4. **Calculate the Test Statistic** ğŸ“Š:  \n",
    "   - Compute the test statistic based on the sample data.  \n",
    "\n",
    "5. **Compare Test Statistic to Critical Value(s)** ğŸ†š:  \n",
    "   - Check if the test statistic falls within the rejection region.  \n",
    "\n",
    "6. **Make a Decision** âœ…:  \n",
    "   - **In Rejection Region:** Reject $H_0$.  \n",
    "   - **Outside Rejection Region:** Fail to reject $H_0$.  \n",
    "\n",
    "\n",
    "\n",
    "### ğŸ”„ **Types of Rejection Regions**\n",
    "\n",
    "1. **One-Tailed Test (Left-Tail or Right-Tail)** ğŸ‘‰:  \n",
    "   - **Left-Tailed Test:** Reject $H_0$ if the test statistic is less than the critical value.  \n",
    "   - **Right-Tailed Test:** Reject $H_0$ if the test statistic is greater than the critical value.  \n",
    "\n",
    "   **Example:** Testing if the mean is less than a specific value.\n",
    "\n",
    "   **Graph**:  \n",
    "   ```\n",
    "   |Rejection Region          | (One tail)\n",
    "           ^\n",
    "       Critical Value\n",
    "   ```\n",
    "\n",
    "2. **Two-Tailed Test** ğŸ”„:  \n",
    "   - Reject $H_0$ if the test statistic is **too low** or **too high** compared to the critical values.  \n",
    "\n",
    "   **Example:** Testing if the mean is **not equal** to a specific value.\n",
    "\n",
    "   **Graph**:  \n",
    "   ```\n",
    "   Rejection Region |-|-Rejection Region (Two tails)\n",
    "                            ^\n",
    "                      Critical Values\n",
    "   ```\n",
    "\n",
    "\n",
    "\n",
    "### ğŸª **Example: Cookie Weights**\n",
    "\n",
    "Imagine you claim your cookies weigh **50g on average**. Someone doubts it and conducts a test:  \n",
    "\n",
    "1. **Null Hypothesis ($H_0$)**: Cookies weigh 50g ($\\mu = 50$).  \n",
    "2. **Alternative Hypothesis ($H_a$)**: Cookies donâ€™t weigh 50g ($\\mu \\neq 50$).  \n",
    "\n",
    "#### **Step-by-Step Using Rejection Region:**\n",
    "\n",
    "1. **Choose $\\alpha = 0.05$** (5% significance level).  \n",
    "2. **Two-Tailed Test** â†’ Divide $\\alpha$ into two tails: $0.025$ in each.  \n",
    "3. **Find Critical Values**:  \n",
    "   - Using a $z$-table for $\\alpha = 0.025$ (two-tailed), the critical values are $-1.96$ and $+1.96$.  \n",
    "4. **Calculate Test Statistic**:  \n",
    "   - Suppose the test statistic is $z = -2.5$.  \n",
    "5. **Compare Test Statistic to Critical Values**:  \n",
    "   - $z = -2.5$ falls in the **left rejection region** ($z < -1.96$).  \n",
    "6. **Conclusion**:  \n",
    "   - Reject $H_0$! The cookies donâ€™t weigh 50g on average.  \n",
    "\n",
    "\n",
    "\n",
    "### ğŸ¨ **Visual Representation**  \n",
    "\n",
    "#### Two-Tailed Test  \n",
    "```\n",
    "Rejection Region ||| Rejection Region\n",
    "                 -1.96    0     +1.96\n",
    "                   ^\n",
    "         Test Statistic (-2.5)\n",
    "```\n",
    "\n",
    "#### One-Tailed Test (Right-Tail)  \n",
    "```\n",
    "                       |Rejection Region\n",
    "                                    +1.645\n",
    "                                      ^\n",
    "                            Test Statistic (+2.0)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ”” **Key Points to Remember**\n",
    "\n",
    "1. **Rejection Region Depends on $\\alpha$:**  \n",
    "   - Smaller $\\alpha$ â†’ Narrower rejection region.  \n",
    "   - Larger $\\alpha$ â†’ Wider rejection region.\n",
    "\n",
    "2. **Critical Values Depend on the Test Type:**  \n",
    "   - **$z$-test:** Standard normal distribution.  \n",
    "   - **$t$-test:** Studentâ€™s $t$-distribution (for small samples).\n",
    "\n",
    "3. **Rejection â‰  Proof of $H_a$:**  \n",
    "   - Rejecting $H_0$ means the data provides strong evidence against it, not absolute proof of $H_a$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](rejection_region.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ **One-Sided vs. Two-Sided Tests in Hypothesis Testing**\n",
    "\n",
    "When performing hypothesis testing, you must decide whether youâ€™re looking for a specific direction in your results (**one-sided test**) or any significant difference, regardless of direction (**two-sided test**). Letâ€™s explore the differences between the two types of tests with a colorful, interactive explanation! ğŸŒˆ\n",
    "\n",
    "\n",
    "\n",
    "### ğŸŒŸ **One-Sided Test**\n",
    "\n",
    "A **one-sided test** is used when you want to check for a difference in a specific directionâ€”**either greater than** or **less than** a given value.  \n",
    "\n",
    "#### ğŸ’¡ Key Features:\n",
    "- Focuses on **one tail** of the distribution.\n",
    "- The entire significance level ($\\alpha$) is concentrated in that one tail.\n",
    "- Typically used when thereâ€™s a strong reason to expect a change in one direction.\n",
    "\n",
    "#### ğŸ§® **Example Scenarios:**\n",
    "- Testing if a new drug **increases** recovery rates compared to the standard treatment.\n",
    "- Determining if a machine produces **less than** 500 defective items per batch.\n",
    "\n",
    "#### ğŸ”¢ **Hypotheses for a One-Sided Test**:\n",
    "1. **Right-tailed Test** (Checking if the value is **greater**):  \n",
    "   $$\n",
    "   H_0: \\mu \\leq \\mu_0 \\quad \\text{vs.} \\quad H_a: \\mu > \\mu_0\n",
    "   $$\n",
    "2. **Left-tailed Test** (Checking if the value is **less**):  \n",
    "   $$\n",
    "   H_0: \\mu \\geq \\mu_0 \\quad \\text{vs.} \\quad H_a: \\mu < \\mu_0\n",
    "   $$\n",
    "\n",
    "#### ğŸ¨ **Graph for One-Sided Test**  \n",
    "For a **right-tailed test** ($H_a: \\mu > \\mu_0$):  \n",
    "```\n",
    "        |---------------------------|--- Rejection Region\n",
    "                                    ^\n",
    "                                Critical Value\n",
    "```\n",
    "\n",
    "For a **left-tailed test** ($H_a: \\mu < \\mu_0$):  \n",
    "```\n",
    "Rejection Region ---|---------------------------|\n",
    "                    ^\n",
    "                Critical Value\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### ğŸŒŸ **Two-Sided Test**\n",
    "\n",
    "A **two-sided test** is used when you want to check for any **difference** (either higher or lower) from a given value.  \n",
    "\n",
    "#### ğŸ’¡ Key Features:\n",
    "- Focuses on **both tails** of the distribution.\n",
    "- The significance level ($\\alpha$) is split equally between the two tails.\n",
    "- Typically used when thereâ€™s no specific direction expected in the change.\n",
    "\n",
    "#### ğŸ§® **Example Scenarios:**\n",
    "- Testing if a new teaching method changes the average test scores (could be higher or lower).\n",
    "- Determining if a batch of products has a mean weight **different** from 1 kg.\n",
    "\n",
    "#### ğŸ”¢ **Hypotheses for a Two-Sided Test**:\n",
    "$$\n",
    "H_0: \\mu = \\mu_0 \\quad \\text{vs.} \\quad H_a: \\mu \\neq \\mu_0\n",
    "$$\n",
    "\n",
    "#### ğŸ¨ **Graph for Two-Sided Test**  \n",
    "```\n",
    "Rejection Region ---|---|----------------|---|--- Rejection Region\n",
    "                  Lower    Center         Upper\n",
    "                  Critical Critical       Critical\n",
    "                   Value    Value          Value\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ”‘ **Key Differences Between One-Sided and Two-Sided Tests**\n",
    "\n",
    "| Feature             | One-Sided Test                           | Two-Sided Test                        |\n",
    "|---------------------|------------------------------------------|---------------------------------------|\n",
    "| **Direction**        | Tests in **one specific direction**.     | Tests for **any difference** (higher or lower). |\n",
    "| **Significance Level** | Entire $\\alpha$ is in **one tail**.    | $\\alpha$ is **split between two tails**. |\n",
    "| **Critical Region**  | Located in **one tail** of the distribution. | Located in **both tails**.            |\n",
    "| **Hypotheses**       | Focus on $>$ or $<$.                 | Focus on $\\neq$.                   |\n",
    "| **Sensitivity**      | More **sensitive** to detecting differences in the specified direction. | Less sensitive but captures differences in both directions. |\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§ª **Example: Cookie Weights**\n",
    "\n",
    "Letâ€™s say youâ€™re testing if your cookies weigh **exactly 50g** or not.\n",
    "\n",
    "#### **Scenario 1: One-Sided Test (Right-Tailed)**  \n",
    "You believe your cookies weigh **more than** 50g.\n",
    "\n",
    "- $H_0: \\mu \\leq 50$ (Cookies weigh 50g or less).  \n",
    "- $H_a: \\mu > 50$ (Cookies weigh more than 50g).  \n",
    "\n",
    "If the test statistic is **greater than the critical value**, you reject $H_0$.\n",
    "\n",
    "#### **Scenario 2: Two-Sided Test**  \n",
    "You suspect your cookies weigh **different** from 50g, but youâ€™re unsure if itâ€™s higher or lower.\n",
    "\n",
    "- $H_0: \\mu = 50$ (Cookies weigh exactly 50g).  \n",
    "- $H_a: \\mu \\neq 50$ (Cookies weigh something other than 50g).  \n",
    "\n",
    "If the test statistic falls in **either tail** (too high or too low), you reject $H_0$.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ¨ **Visual Representation**\n",
    "\n",
    "#### **One-Sided Test (Right-Tailed)**\n",
    "```\n",
    "                          |------------ Rejection Region\n",
    "Critical Value --->     ^\n",
    "```\n",
    "\n",
    "#### **Two-Sided Test**\n",
    "```\n",
    "Rejection Region ---|---|-----------------|---|--- Rejection Region\n",
    "                   Lower                  Upper\n",
    "                   Critical               Critical\n",
    "                   Value                  Value\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ› ï¸ **When to Use Which Test?**\n",
    "\n",
    "1. **Use One-Sided Test When**:  \n",
    "   - You have a specific direction in mind.\n",
    "   - Example: Checking if a new drug increases recovery time.\n",
    "\n",
    "2. **Use Two-Sided Test When**:  \n",
    "   - Youâ€™re open to differences in **any direction**.  \n",
    "   - Example: Checking if a new drug has a different effect, regardless of whether itâ€™s better or worse.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](one_sided.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒŸ **What is a Z-Test? (Simplified!)**\n",
    "\n",
    "Think of a z-test as a way to **check if a claim about a group of things makes sense**. Imagine youâ€™re testing if cookies from a bakery are really 50g each, as the bakery claims. A z-test helps you figure out if your measurements (sample data) agree with the bakery's claim (population data).\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ”‘ **Key Ideas Behind a Z-Test**\n",
    "\n",
    "1. **Population**: The whole group youâ€™re studying (e.g., all cookies in the bakery).\n",
    "2. **Sample**: A smaller group you test (e.g., 30 cookies you randomly pick).\n",
    "3. **Null Hypothesis ($H_0$)**: The bakeryâ€™s claim is correct (cookies = 50g).\n",
    "4. **Alternative Hypothesis ($H_a$)**: The bakeryâ€™s claim is wrong (cookies â‰  50g).\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ› ï¸ **How Does a Z-Test Work?**\n",
    "\n",
    "It compares:\n",
    "1. **The claim (population mean)** against\n",
    "2. **What you actually measured (sample mean)**.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸš€ **When Do You Use a Z-Test?**\n",
    "\n",
    "Use it when:\n",
    "- ğŸ§® The data is **normally distributed** (or your sample size is large, $n \\geq 30$).\n",
    "- ğŸ“Š You **know the population standard deviation** ($\\sigma$).\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§ª **How to Conduct a Z-Test**\n",
    "\n",
    "1. **State Your Hypotheses**:\n",
    "   - Null Hypothesis ($H_0$): â€œThe claim is true.â€\n",
    "   - Alternative Hypothesis ($H_a$): â€œThe claim is false.â€\n",
    "\n",
    "2. **Decide the Significance Level ($\\alpha$)**:\n",
    "   - Example: $\\alpha = 0.05$ (You allow a 5% chance of being wrong).\n",
    "\n",
    "3. **Calculate the Z-Statistic**:\n",
    "   Use the formula:\n",
    "   $$\n",
    "   Z = \\frac{\\text{Sample Mean} - \\text{Population Mean}}{\\text{Standard Error}}\n",
    "   $$\n",
    "   **Standard Error**:\n",
    "   $$\n",
    "   \\text{Standard Error} = \\frac{\\sigma}{\\sqrt{n}}\n",
    "   $$\n",
    "\n",
    "4. **Find the Critical Value**:\n",
    "   - Use a z-table or standard chart.\n",
    "   - For $\\alpha = 0.05$ (two-tailed test): Critical values are $-1.96$ and $1.96$.\n",
    "\n",
    "5. **Make a Decision**:\n",
    "   - If the z-statistic lies in the rejection region (beyond critical values), reject $H_0$.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸª **Letâ€™s Simplify with a Cookie Example**\n",
    "\n",
    "#### Problem:\n",
    "You think the bakeryâ€™s cookies donâ€™t weigh 50g on average. You measure 30 cookies and find:\n",
    "- Sample Mean ($\\bar{X}$) = 48g\n",
    "- Population Mean ($\\mu$) = 50g\n",
    "- Standard Deviation ($\\sigma$) = 4g\n",
    "\n",
    "Test this at a 5% significance level ($\\alpha = 0.05$).\n",
    "\n",
    "\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "1. **State Hypotheses**:\n",
    "   - $H_0$: Cookies weigh 50g ($\\mu = 50$).\n",
    "   - $H_a$: Cookies donâ€™t weigh 50g ($\\mu \\neq 50$).\n",
    "\n",
    "2. **Significance Level**: $\\alpha = 0.05$.\n",
    "\n",
    "3. **Calculate Z-Statistic**:\n",
    "   $$\n",
    "   Z = \\frac{\\bar{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n",
    "   $$\n",
    "   Substituting values:\n",
    "   $$\n",
    "   Z = \\frac{48 - 50}{\\frac{4}{\\sqrt{30}}} = \\frac{-2}{0.73} \\approx -2.74\n",
    "   $$\n",
    "\n",
    "4. **Find Critical Values**:\n",
    "   - For $\\alpha = 0.05$ (two-tailed): Critical values are $-1.96$ and $1.96$.\n",
    "\n",
    "5. **Decision**:\n",
    "   - $Z = -2.74$, which is less than $-1.96$.\n",
    "   - **Reject $H_0$**. The cookies donâ€™t weigh 50g on average.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](z-test.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒŸ **What is a P-Value?** ğŸŒŸ\n",
    "\n",
    "A **p-value** is a probability that helps us decide whether the evidence we have from a sample is strong enough to reject the null hypothesis in statistical hypothesis testing. \n",
    "\n",
    "To put it simply, the p-value is **how likely** you would see your results (or something more extreme) **if the null hypothesis were true**.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ”‘ **Key Concept: Null Hypothesis and P-Value**\n",
    "\n",
    "1. **Null Hypothesis ($H_0$)**: This is a statement we want to test. It often represents the status quo or a claim we want to challenge. For example, \"The average weight of cookies is 50g.\"\n",
    "\n",
    "2. **P-Value**: The probability of obtaining results at least as extreme as the ones you actually observed, **given that the null hypothesis is true**.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ“Š **What Does the P-Value Tell Us?**\n",
    "\n",
    "- **Small p-value (< 0.05)**: If the p-value is smaller than the significance level $ \\alpha $ (typically 0.05), it suggests that the observed data is **unlikely** under the null hypothesis, **so we reject $H_0$**.\n",
    "  \n",
    "- **Large p-value (â‰¥ 0.05)**: If the p-value is larger than the significance level $ \\alpha $, it suggests that the observed data is **consistent** with the null hypothesis, **so we fail to reject $H_0$**.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸš€ **Interpreting P-Value in Action**\n",
    "\n",
    "Let's use a **cookie example** to visualize it:\n",
    "\n",
    "#### Problem:\n",
    "You are testing the claim that cookies weigh 50g on average, and you have a sample of cookies with a sample mean of 48g. You want to check if this evidence is strong enough to reject the bakeryâ€™s claim at a 5% significance level ($ \\alpha = 0.05 $).\n",
    "\n",
    "- Null Hypothesis ($H_0$): Cookies weigh 50g on average ($ \\mu = 50 $).\n",
    "- Alternative Hypothesis ($H_a$): Cookies do not weigh 50g on average ($ \\mu \\neq 50 $).\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "1. **Calculate the Z-Statistic**: \n",
    "   $$\n",
    "   Z = \\frac{\\bar{X} - \\mu}{\\text{SE}} = \\frac{48 - 50}{0.73} = -2.74\n",
    "   $$\n",
    "\n",
    "2. **Look up the p-value**: The p-value corresponds to the area to the left of **z = -2.74** (or the area to the right if z is positive). \n",
    "\n",
    "   - From the z-table or using a calculator, youâ€™ll find the **p-value â‰ˆ 0.006**.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ” **What Does the P-Value of 0.006 Mean?**\n",
    "\n",
    "Since **0.006** is **less than 0.05**, it means the observed sample mean of 48g is **highly unlikely** if the true average weight of the cookies were 50g.\n",
    "\n",
    "So, **we reject the null hypothesis ($H_0$)** and conclude that the cookies **do not** weigh 50g on average.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸŒˆ **Visualizing the P-Value**\n",
    "\n",
    "Letâ€™s visualize what happens with a z-test and the p-value:\n",
    "\n",
    "1. **Z-Distribution Curve**: This shows the distribution of the test statistic (Z-value).\n",
    "2. **Rejection Region**: If the p-value is small, the test statistic falls in the tail (rejection region).\n",
    "3. **P-Value Area**: The smaller the p-value, the larger the tail area, indicating stronger evidence against $H_0$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great question! Let's walk through the process of **calculating the p-value** step by step using the z-statistic we found earlier.\n",
    "\n",
    "### Step-by-Step Guide to Calculate P-Value\n",
    "\n",
    "1. **Z-Statistic Calculation** (we already calculated this):\n",
    "   $$\n",
    "   Z = \\frac{\\bar{X} - \\mu}{\\text{Standard Error}} = \\frac{48 - 50}{0.73} = -2.74\n",
    "   $$\n",
    "   So, the z-statistic is **-2.74**.\n",
    "\n",
    "2. **Understanding the P-Value**:\n",
    "   - The p-value corresponds to the **area under the standard normal curve** that is **more extreme** than the z-statistic.\n",
    "   - Since we're doing a **two-tailed test**, we want to find the probability (p-value) that the test statistic is **either less than -2.74** or **greater than +2.74**.\n",
    "\n",
    "\n",
    "\n",
    "### How to Find the P-Value:\n",
    "\n",
    "- **Step 1**: Look up the z-statistic **-2.74** in a **z-table** or use a statistical function to get the cumulative probability for this value.\n",
    "  \n",
    "  In the **z-table**:\n",
    "  - Look up **2.74** (ignoring the negative sign) in the table.\n",
    "  - The table will give you the **area to the left** of this z-value.\n",
    "  - For **z = 2.74**, the area to the left is approximately **0.0031**.\n",
    "\n",
    "- **Step 2**: Since the z-statistic is negative (-2.74), the area to the left of this z-value is **0.0031**, which represents the probability of getting a value less than **-2.74**.\n",
    "\n",
    "- **Step 3**: Multiply that probability by **2** (because it's a two-tailed test) to account for both sides of the distribution:\n",
    "  $$\n",
    "  \\text{p-value} = 2 \\times 0.0031 = 0.0062\n",
    "  $$\n",
    "\n",
    "\n",
    "\n",
    "### Why is the P-Value ~0.006?\n",
    "\n",
    "- The p-value of **0.0062** means there's a **0.62% chance** of observing a sample mean as extreme as **48g** (or more extreme) if the true population mean was 50g.\n",
    "- Since **0.0062** is **smaller than 0.05** (our significance level), it tells us the evidence **strongly suggests** that the true mean is **not** 50g, so we **reject the null hypothesis**.\n",
    "\n",
    "\n",
    "\n",
    "### TL;DR\n",
    "- The **z-statistic** of **-2.74** corresponds to a **cumulative probability of 0.0031** (for the left tail).\n",
    "- Multiply by 2 for the two-tailed test: **p-value â‰ˆ 0.006**.\n",
    "- A **small p-value (< 0.05)** means we reject the null hypothesis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒŸ **What is a T-Test?** ğŸŒŸ\n",
    "\n",
    "A **t-test** is a statistical test used to compare the means of two groups or a sample mean with a population mean. It's particularly useful when the **sample size is small** and the **population standard deviation is unknown** (which is often the case in real-life situations). The t-test helps us determine if there is a significant difference between the groups being compared.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ”‘ **Key Concepts in T-Test** ğŸ”‘\n",
    "\n",
    "1. **Null Hypothesis ($H_0$)**: The idea that there is **no significant difference** between the groups or the sample mean and the population mean. For example, \"The average height of students in class A is the same as class B.\"\n",
    "2. **Alternative Hypothesis ($H_a$)**: The idea that there **is a significant difference** between the groups or the sample mean and the population mean. For example, \"The average height of students in class A is different from class B.\"\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§ª **Types of T-Tests** ğŸ§ª\n",
    "\n",
    "1. **One-Sample T-Test**: \n",
    "   - Compares the sample mean to a known population mean.\n",
    "   - Example: You want to check if the average weight of cookies in your sample is different from the claimed 50g.\n",
    "\n",
    "2. **Independent Two-Sample T-Test**: \n",
    "   - Compares the means of two independent groups.\n",
    "   - Example: You compare the average height of male and female students in a class.\n",
    "\n",
    "3. **Paired Sample T-Test**: \n",
    "   - Compares the means from the **same group** at two different times or conditions.\n",
    "   - Example: You test if studentsâ€™ test scores improve after attending a study session.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ› ï¸ **How Does a T-Test Work?** ğŸ› ï¸\n",
    "\n",
    "The **t-test** involves calculating the **t-statistic**, which is a measure of the difference between the sample mean and the population mean (or the means of two groups), **normalized by the variation in the data**.\n",
    "\n",
    "The formula for the **t-statistic** is:\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- **$\\bar{X}$** = sample mean\n",
    "- **$\\mu$** = population mean (for one-sample t-test) or mean of the other group (for two-sample t-test)\n",
    "- **$s$** = sample standard deviation\n",
    "- **$n$** = sample size\n",
    "\n",
    "\n",
    "\n",
    "### ğŸš€ **When Do You Use a T-Test?** ğŸš€\n",
    "\n",
    "Use a **t-test** when:\n",
    "- The **sample size** is small (typically $n < 30$).\n",
    "- The **population standard deviation** is **unknown**.\n",
    "- You want to compare means between **one or two groups**.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ“Š **Steps to Perform a T-Test:**\n",
    "\n",
    "1. **State Your Hypotheses**:\n",
    "   - **Null Hypothesis ($H_0$)**: There is no difference (e.g., the means are equal).\n",
    "   - **Alternative Hypothesis ($H_a$)**: There is a difference (e.g., the means are not equal).\n",
    "\n",
    "2. **Choose the Significance Level ($\\alpha$)**: \n",
    "   - Common choices are **0.05** (5% risk of Type I error) or **0.01** (1% risk).\n",
    "\n",
    "3. **Calculate the T-Statistic**: \n",
    "   - Using the formula above, calculate the t-statistic for your data.\n",
    "\n",
    "4. **Find the Critical Value**:\n",
    "   - Use a **t-distribution table** or a calculator to find the critical t-value for your chosen significance level ($\\alpha$) and degrees of freedom ($df = n - 1$).\n",
    "\n",
    "5. **Make a Decision**:\n",
    "   - Compare your **calculated t-statistic** with the **critical t-value**:\n",
    "     - If **t-statistic** is **greater than the critical value** (in absolute terms), reject the **null hypothesis**.\n",
    "     - If **t-statistic** is **less than the critical value**, fail to reject the null hypothesis.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸª **T-Test with a Cookie Example**\n",
    "\n",
    "#### Problem:\n",
    "You have a batch of **30 cookies** and you want to check if the **average weight** is different from the bakeryâ€™s claim of **50g**. After measuring the cookies, you find:\n",
    "- **Sample Mean ($\\bar{X}$) = 48g**\n",
    "- **Sample Standard Deviation ($s$) = 4g**\n",
    "- **Sample Size ($n$) = 30**\n",
    "\n",
    "Youâ€™ll test the null hypothesis $H_0$: \"The cookies weigh 50g on average.\"\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "1. **State Hypotheses**:\n",
    "   - $H_0$: Cookies weigh 50g ($\\mu = 50$).\n",
    "   - $H_a$: Cookies do not weigh 50g ($\\mu \\neq 50$).\n",
    "\n",
    "2. **Significance Level**: $\\alpha = 0.05$.\n",
    "\n",
    "3. **Calculate T-Statistic**:\n",
    "   Using the formula for the t-statistic:\n",
    "   $$\n",
    "   t = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}} = \\frac{48 - 50}{\\frac{4}{\\sqrt{30}}} = \\frac{-2}{0.73} \\approx -2.74\n",
    "   $$\n",
    "\n",
    "4. **Find Critical Value**:\n",
    "   - For a **two-tailed test** with **30 - 1 = 29** degrees of freedom and a **5% significance level**, you can use a t-table or statistical software to find the **critical t-value â‰ˆ Â±2.045**.\n",
    "\n",
    "5. **Decision**:\n",
    "   - Since **t = -2.74** and the critical value is **Â±2.045**, the **t-statistic falls in the rejection region** (since $-2.74 < -2.045$), so we **reject the null hypothesis**.\n",
    "\n",
    "**Conclusion**: The cookies do not weigh 50g on average.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](t-test.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it's absolutely possible to help you understand how to use a **t-table**! Below is an explanation of how to read and use the **t-table** for different scenarios:\n",
    "\n",
    "### Key Points:\n",
    "- **Degrees of Freedom (df)**: For a **t-test**, degrees of freedom is calculated as **n - 1**, where **n** is the sample size.\n",
    "- **One-Tailed and Two-Tailed**: You need to choose between these two based on your hypothesis. In a **two-tailed test**, we check both ends of the distribution.\n",
    "\n",
    "Here is a **t-table** with highlights on what to check, and Iâ€™ll explain where to look depending on your scenario:\n",
    "\n",
    "### Table: How to Check Values for t-test\n",
    "\n",
    "| **df** | **0.50 (One-Tail)** | **0.75 (One-Tail)** | **0.80 (One-Tail)** | **0.85 (One-Tail)** | **0.90 (One-Tail)** | **0.95 (One-Tail)** | **0.975 (One-Tail)** | **0.99 (One-Tail)** | **0.995 (One-Tail)** | **0.999 (One-Tail)** | **0.9995 (One-Tail)** |\n",
    "|--------|--------------------|--------------------|--------------------|--------------------|--------------------|--------------------|---------------------|--------------------|--------------------|--------------------|----------------------|\n",
    "| **1**  | 0.000              | 1.000              | 1.376              | 1.963              | 3.078              | 6.314              | 12.71               | 31.82              | 63.66              | 318.31             | 636.62               |\n",
    "| **2**  | 0.000              | 0.816              | 1.061              | 1.386              | 1.886              | 2.920              | 4.303               | 6.965              | 9.925              | 22.327             | 31.599              |\n",
    "| **3**  | 0.000              | 0.765              | 0.978              | 1.250              | 1.638              | 2.353              | 3.182               | 4.541              | 5.841              | 10.215             | 12.924              |\n",
    "| **4**  | 0.000              | 0.741              | 0.941              | 1.190              | 1.533              | 2.132              | 2.776               | 3.747              | 4.604              | 7.173              | 8.610               |\n",
    "| **5**  | 0.000              | 0.727              | 0.920              | 1.156              | 1.476              | 2.015              | 2.571               | 3.365              | 4.032              | 5.893              | 6.869               |\n",
    "| **6**  | 0.000              | 0.718              | 0.906              | 1.134              | 1.440              | 1.943              | 2.447               | 3.143              | 3.707              | 5.208              | 5.959               |\n",
    "\n",
    "### **How to Read the t-Table:**\n",
    "\n",
    "#### **Steps:**\n",
    "1. **Identify Degrees of Freedom (df):**  \n",
    "   This depends on your **sample size (n)**. The formula for **df** is **n - 1**.\n",
    "   \n",
    "   For example, if you have **30** data points, then **df = 30 - 1 = 29**.\n",
    "   \n",
    "2. **Select One-Tailed or Two-Tailed Test:**\n",
    "   - For **one-tailed tests**, check the left part of the table.\n",
    "   - For **two-tailed tests**, check the right part of the table.\n",
    "   \n",
    "3. **Find the Significance Level (Î±)**:  \n",
    "   The significance level (e.g., **0.05**, **0.01**) will help you identify the critical values. For example, in a **95% confidence level**, we use **Î± = 0.05** (split into two tails for a two-tailed test).\n",
    "\n",
    "4. **Find the Corresponding t-Value:**\n",
    "   - If you have **Î± = 0.05** for a **two-tailed test**, you'll look for the critical t-value that corresponds to **Î± = 0.025** on each side of the distribution.\n",
    "   \n",
    "5. **Compare the Calculated t-Statistic with Critical t-Value:**\n",
    "   If your **calculated t-statistic** is greater than the critical value, you reject the null hypothesis.\n",
    "\n",
    "\n",
    "\n",
    "### **Highlighting Key Values:**\n",
    "If you're working with a **two-tailed test** and **Î± = 0.05**:\n",
    "- You would look for the column corresponding to **0.025** for the **two-tailed** test (as the tail is split).\n",
    "- **Critical t-value** for **df = 29** and **Î± = 0.05** (two-tailed test) would be **Â±2.045** (from the table).\n",
    "\n",
    "For **one-tailed tests**, you check the values in the one-tail column. For example, for **Î± = 0.05**, the **critical t-value** would be **1.699** for **df = 29**.\n",
    "\n",
    "\n",
    "\n",
    "### **Visual Representation for Two-Tailed Test:**\n",
    "\n",
    "| **df** | **Critical t-Value (Two-Tails, Î±=0.05)** | **t-statistic Range for Accepting Hâ‚€** | **t-statistic Range for Rejecting Hâ‚€** |\n",
    "|--------|----------------------------------------|--------------------------------------|--------------------------------------|\n",
    "| **1**  | Â±12.71                                  | | |\n",
    "| **2**  | Â±4.303                                  | | |\n",
    "| **3**  | Â±3.182                                  | | |\n",
    "| **4**  | Â±2.776                                  | | |\n",
    "| **5**  | Â±2.571                                  | | |\n",
    "| **29** | Â±2.045                                  | | |\n",
    "\n",
    "For **df = 29**, you can look at the value **Â±2.045** for **Î± = 0.05 (two-tailed)**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Chi-Square test**:\n",
    "\n",
    "The **Chi-Square test** is a statistical test used to determine if there is a significant association between categorical variables or if a dataset matches an expected distribution. It is commonly used in hypothesis testing to compare observed and expected frequencies.\n",
    "\n",
    "\n",
    "\n",
    "### Types of Chi-Square Tests\n",
    "1. **Chi-Square Test of Independence**: \n",
    "   - Used to test if two categorical variables are independent of each other.\n",
    "   - Example: Is there a relationship between gender and voting preference?\n",
    "\n",
    "2. **Chi-Square Goodness-of-Fit Test**:\n",
    "   - Used to determine if a sample data matches an expected distribution.\n",
    "   - Example: Do observed dice rolls match the expected probabilities of a fair die?\n",
    "\n",
    "\n",
    "\n",
    "### Formula for Chi-Square Test\n",
    "$$\n",
    "\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
    "$$\n",
    "Where:\n",
    "- $ O_i $: Observed frequency for category $ i $.\n",
    "- $ E_i $: Expected frequency for category $ i $.\n",
    "\n",
    "\n",
    "\n",
    "### Steps to Perform a Chi-Square Test\n",
    "#### 1. **Set Up Hypotheses**\n",
    "- **Null Hypothesis ($ H_0 $)**:\n",
    "  - For independence: The variables are independent.\n",
    "  - For goodness-of-fit: The observed data matches the expected distribution.\n",
    "- **Alternative Hypothesis ($ H_a $)**:\n",
    "  - For independence: The variables are not independent.\n",
    "  - For goodness-of-fit: The observed data does not match the expected distribution.\n",
    "\n",
    "#### 2. **Calculate Expected Frequencies**\n",
    "- **For Test of Independence**:\n",
    "  $$\n",
    "  E_{ij} = \\frac{(Row \\ Total \\times Column \\ Total)}{Grand \\ Total}\n",
    "  $$\n",
    "  Where $ E_{ij} $ is the expected frequency for cell $ (i, j) $.\n",
    "- **For Goodness-of-Fit**:\n",
    "  $$\n",
    "  E_i = N \\times P_i\n",
    "  $$\n",
    "  Where $ P_i $ is the expected proportion, and $ N $ is the total sample size.\n",
    "\n",
    "#### 3. **Compute the Chi-Square Statistic**\n",
    "Use the formula:\n",
    "$$\n",
    "\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
    "$$\n",
    "Sum across all categories.\n",
    "\n",
    "#### 4. **Determine Degrees of Freedom**\n",
    "- **For Test of Independence**:\n",
    "  $$\n",
    "  df = (R - 1)(C - 1)\n",
    "  $$\n",
    "  Where $ R $ is the number of rows, and $ C $ is the number of columns in the contingency table.\n",
    "- **For Goodness-of-Fit**:\n",
    "  $$\n",
    "  df = k - 1\n",
    "  $$\n",
    "  Where $ k $ is the number of categories.\n",
    "\n",
    "#### 5. **Find the Critical Value**\n",
    "- Use a Chi-Square distribution table with the degrees of freedom and significance level ($ \\alpha $, usually 0.05).\n",
    "\n",
    "#### 6. **Make a Decision**\n",
    "- If $ \\chi^2 $ (calculated) > $ \\chi^2 $ (critical value): Reject $ H_0 $.\n",
    "- Otherwise: Fail to reject $ H_0 $.\n",
    "\n",
    "### Example: Chi-Square Test of Independence\n",
    "**Question**: Is there a relationship between gender and preference for a product?\n",
    "\n",
    "|              | Product A | Product B | Product C | Total |\n",
    "|--------------|-----------|-----------|-----------|-------|\n",
    "| **Male**     | 20        | 15        | 25        | 60    |\n",
    "| **Female**   | 30        | 25        | 35        | 90    |\n",
    "| **Total**    | 50        | 40        | 60        | 150   |\n",
    "\n",
    "\n",
    "\n",
    "1. **Calculate Expected Frequencies**:\n",
    "   For **Male, Product A**:\n",
    "   $$\n",
    "   E_{11} = \\frac{(Row \\ Total \\times Column \\ Total)}{Grand \\ Total} = \\frac{(60 \\times 50)}{150} = 20\n",
    "   $$\n",
    "   Repeat for all cells.\n",
    "\n",
    "2. **Calculate $ \\chi^2 $**:\n",
    "   Use the formula:\n",
    "   $$\n",
    "   \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
    "   $$\n",
    "\n",
    "3. **Degrees of Freedom**:\n",
    "   $$\n",
    "   df = (R - 1)(C - 1) = (2 - 1)(3 - 1) = 2\n",
    "   $$\n",
    "\n",
    "4. **Compare with Critical Value**:\n",
    "   At $ \\alpha = 0.05 $, critical value for $ df = 2 $ is 5.991.\n",
    "\n",
    "5. **Decision**:\n",
    "   - If $ \\chi^2 $ > 5.991, reject $ H_0 $: Gender and product preference are not independent.\n",
    "   - Otherwise: Fail to reject $ H_0 $.\n",
    "\n",
    "\n",
    "\n",
    "### Example: Chi-Square Goodness-of-Fit Test\n",
    "**Question**: Is a die fair?  \n",
    "Observed frequencies: [16, 14, 18, 12, 20, 10]  \n",
    "Expected frequencies (for a fair die): [15, 15, 15, 15, 15, 15]\n",
    "\n",
    "1. **Calculate $ \\chi^2 $**:\n",
    "   $$\n",
    "   \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i} = \\frac{(16-15)^2}{15} + \\frac{(14-15)^2}{15} + \\dots\n",
    "   $$\n",
    "\n",
    "2. **Degrees of Freedom**:\n",
    "   $$\n",
    "   df = k - 1 = 6 - 1 = 5\n",
    "   $$\n",
    "\n",
    "3. **Critical Value**:\n",
    "   At $ \\alpha = 0.05 $, critical value for $ df = 5 $ is 11.07.\n",
    "\n",
    "4. **Decision**:\n",
    "   - If $ \\chi^2 $ > 11.07, reject $ H_0 $: The die is not fair.\n",
    "   - Otherwise: Fail to reject $ H_0 $.\n",
    "\n",
    "\n",
    "\n",
    "### Key Assumptions\n",
    "1. Observations are independent.\n",
    "2. Expected frequencies in each category should be at least 5.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### ğŸ” **What is the Chi-Square Test?**\n",
    "Itâ€™s a test to answer questions like:\n",
    "1. Are two things related? (e.g., Does gender affect voting preference? ğŸ¤”)\n",
    "2. Does my data look like what I expected? (e.g., Are the colors in a bag of M&Ms evenly distributed? ğŸ«)\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ² **How Does It Work?**\n",
    "1. **Collect Your Observed Data (O)**:\n",
    "   These are the actual numbers you see in your data.\n",
    "\n",
    "2. **Calculate the Expected Data (E)**:\n",
    "   This is what you think the data should look like if your guess (hypothesis) is true.\n",
    "\n",
    "3. **Compare Observed vs. Expected**:\n",
    "   If theyâ€™re very different, something might be going on!\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§® **The Formula**:\n",
    "$$\n",
    "\\chi^2 = \\sum \\frac{(O - E)^2}{E}\n",
    "$$\n",
    "\n",
    "Think of it as:\n",
    "1. Take the difference between observed and expected: $ O - E $.\n",
    "2. Square it to make everything positive: $ (O - E)^2 $.\n",
    "3. Divide by the expected value to account for size: $ \\frac{(O - E)^2}{E} $.\n",
    "4. Add it all up for every category. ğŸ‰\n",
    "\n",
    "\n",
    "\n",
    "### **Types of Chi-Square Tests**\n",
    "#### 1. **Test of Independence** (Are two things related? ğŸ¤)\n",
    "   - Example: Does **gender** affect whether someone prefers Product A or Product B? ğŸ›ï¸\n",
    "   - You use a table of counts (contingency table) to check for relationships.\n",
    "\n",
    "#### 2. **Goodness-of-Fit Test** (Does my data fit the expected distribution? ğŸ¨)\n",
    "   - Example: Does a die roll give equal numbers for 1, 2, 3, 4, 5, 6? ğŸ²\n",
    "   - You compare your observed data to an expected distribution.\n",
    "\n",
    "### ğŸŒˆ **Letâ€™s Make It Fun With an Example!**\n",
    "Imagine you have a bag of Skittles ğŸ¬, and you want to see if the colors are evenly distributed.\n",
    "\n",
    "#### ğŸ› ï¸ Your Data:\n",
    "| Color     | Observed (O) | Expected (E) |\n",
    "|-----------|--------------|--------------|\n",
    "| Red       | 12           | 10           |\n",
    "| Green     | 15           | 10           |\n",
    "| Blue      | 8            | 10           |\n",
    "| Yellow    | 5            | 10           |\n",
    "| Purple    | 10           | 10           |\n",
    "\n",
    "\n",
    "\n",
    "#### ğŸ¯ Step 1: Compute $ \\chi^2 $:\n",
    "For each color:\n",
    "$$\n",
    "\\text{Chi-Square for each color} = \\frac{(O - E)^2}{E}\n",
    "$$\n",
    "- Red: $ \\frac{(12 - 10)^2}{10} = 0.4 $\n",
    "- Green: $ \\frac{(15 - 10)^2}{10} = 2.5 $\n",
    "- Blue: $ \\frac{(8 - 10)^2}{10} = 0.4 $\n",
    "- Yellow: $ \\frac{(5 - 10)^2}{10} = 2.5 $\n",
    "- Purple: $ \\frac{(10 - 10)^2}{10} = 0.0 $\n",
    "\n",
    "Total $ \\chi^2 $:\n",
    "$$\n",
    "\\chi^2 = 0.4 + 2.5 + 0.4 + 2.5 + 0.0 = 5.8\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "#### ğŸ¯ Step 2: Find Degrees of Freedom ($ df $):\n",
    "$$\n",
    "df = k - 1\n",
    "$$\n",
    "Where $ k $ is the number of categories. Here:\n",
    "$$\n",
    "df = 5 - 1 = 4\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "#### ğŸ¯ Step 3: Compare With Critical Value:\n",
    "- Look up a **Chi-Square Table** for $ df = 4 $ and $ \\alpha = 0.05 $ (5% significance level). Critical value = **9.488**.\n",
    "- If $ \\chi^2 $ < 9.488, your data is fine (no evidence of uneven distribution).\n",
    "- If $ \\chi^2 $ > 9.488, something unusual is happening.\n",
    "\n",
    "Here:\n",
    "$$\n",
    "\\chi^2 = 5.8 < 9.488\n",
    "$$\n",
    "So, we **donâ€™t reject the null hypothesis**. ğŸ‰ The Skittles are evenly distributed.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ–ï¸ **Key Points to Remember**\n",
    "1. A big $ \\chi^2 $ value means your data and expectations are quite different. ğŸš¨\n",
    "2. Small $ \\chi^2 $ means your data matches your expectations well. âœ…\n",
    "3. Always check degrees of freedom (df) and the Chi-Square table.\n",
    "\n",
    "``` python\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Observed data (O) - number of Skittles of each color\n",
    "observed = [12, 15, 8, 5, 10]\n",
    "\n",
    "# Expected data (E) - assuming equal distribution\n",
    "expected = [10, 10, 10, 10, 10]\n",
    "\n",
    "# Perform Chi-Square Test\n",
    "chi2, p_value = stats.chisquare(f_obs=observed, f_exp=expected)\n",
    "\n",
    "# Results\n",
    "print(f\"Chi-Square Statistic: {chi2}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# Decision based on significance level (alpha = 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The distribution is not as expected.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The distribution matches expectations.\")\n",
    "\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ **What is ANOVA?**(**Analysis of Variance**)\n",
    "\n",
    "- **ANOVA** is a statistical test that compares the means of **two or more groups** to see if they are **significantly different** from each other.  \n",
    "- It answers: **\"Do these groups have the same average?\"**  \n",
    "  Think of comparing the exam scores of students in three different classes. ğŸ«\n",
    "\n",
    "\n",
    "\n",
    "## **Key Concepts**\n",
    "\n",
    "1. **Null Hypothesis ($ H_0 $)**:  \n",
    "   All group means are equal.  \n",
    "   Example: The average exam scores of the three classes are the same.\n",
    "\n",
    "2. **Alternative Hypothesis ($ H_1 $)**:  \n",
    "   At least one group mean is different.  \n",
    "   Example: At least one class has a different average exam score.\n",
    "\n",
    "3. **F-Statistic**:  \n",
    "   Measures how much the group means differ relative to the variability within the groups.  \n",
    "   Larger $ F $-values indicate more difference between group means.\n",
    "\n",
    "4. **P-Value**:  \n",
    "   If $ p $-value < 0.05, reject $ H_0 $: Thereâ€™s a significant difference.\n",
    "\n",
    "\n",
    "\n",
    "## **How ANOVA Works (Simple Steps)**\n",
    "\n",
    "1. **Calculate Group Means**: Find the average of each group.\n",
    "2. **Measure Variability**:  \n",
    "   - **Between Groups**: How much group means differ from the overall mean.  \n",
    "   - **Within Groups**: How much individual data points differ within each group.\n",
    "3. **Calculate F-Statistic**:  \n",
    "   $ F = \\frac{\\text{Variance Between Groups}}{\\text{Variance Within Groups}} $\n",
    "4. **Compare P-Value to 0.05**: Decide if differences are significant.\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ”¢ **Types of ANOVA**\n",
    "\n",
    "1. **One-Way ANOVA**:  \n",
    "   Compares means of **one factor** (e.g., scores across 3 classes).  \n",
    "2. **Two-Way ANOVA**:  \n",
    "   Compares means of **two factors** (e.g., scores by class and gender).  \n",
    "3. **Repeated Measures ANOVA**:  \n",
    "   Measures the same group multiple times (e.g., performance before and after training).\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ“Š **Python Code for One-Way ANOVA**\n",
    "\n",
    "Hereâ€™s a simple example with studentsâ€™ scores from three classes.\n",
    "\n",
    "```python\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Scores from three classes\n",
    "class_a = [85, 88, 92, 95, 90]\n",
    "class_b = [78, 82, 80, 84, 79]\n",
    "class_c = [92, 94, 89, 96, 91]\n",
    "\n",
    "# Perform One-Way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(class_a, class_b, class_c)\n",
    "\n",
    "# Results\n",
    "print(f\"F-Statistic: {f_stat}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# Decision\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: At least one group mean is different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The group means are similar.\")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§ª **Example Output**\n",
    "```\n",
    "F-Statistic: 24.87\n",
    "P-Value: 0.0001\n",
    "Reject the null hypothesis: At least one group mean is different.\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## ğŸŒŸ **Key Takeaways**\n",
    "\n",
    "- ANOVA helps you determine if group means differ, but it doesnâ€™t tell **which groups** are different. For that, we use **post-hoc tests** like Tukeyâ€™s test.\n",
    "- ANOVA assumes:\n",
    "  - Data is normally distributed.\n",
    "  - Variances are similar across groups.\n",
    "  - Observations are independent.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ **What is ANOVA (Super Simple Explanation)?**\n",
    "\n",
    "Imagine ğŸ• **you have 3 pizza brands**â€”A, B, and Câ€”and you want to know:  \n",
    "**\"Do people like one brand more than the others?\"**\n",
    "\n",
    "1. ğŸ• People taste pizza from **Brand A**, **Brand B**, and **Brand C**.\n",
    "2. They give scores (ratings) for each brand.\n",
    "3. You collect the scores and now you ask:  \n",
    "   **\"Are these scores different enough to say people prefer one brand?\"**\n",
    "\n",
    "\n",
    "\n",
    "## ğŸš¦ **How ANOVA Works (The Pizza Story)**\n",
    "\n",
    "To answer this question, ANOVA checks **two things**:\n",
    "\n",
    "1. **How far apart are the average scores for the brands?**  \n",
    "   (This is **Between-Group Variance**â€”how the brands differ.)\n",
    "\n",
    "2. **How much variation is there within each brandâ€™s scores?**  \n",
    "   (This is **Within-Group Variance**â€”how people differ in scoring the same brand.)\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ• **Key Idea**: Compare **Between-Group Variance** with **Within-Group Variance**  \n",
    "- If the **differences between groups** are much bigger than the **variations within groups**, then the groups are **different**.\n",
    "- If not, the groups are probably **similar**.\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ“Š **Simple Steps for ANOVA**\n",
    "\n",
    "1. ğŸ§® **Calculate the group averages (means):**  \n",
    "   For each pizza brand, find the average score.\n",
    "\n",
    "2. ğŸ“ˆ **Measure Variations:**\n",
    "   - **Between Groups:** How different the group averages are.\n",
    "   - **Within Groups:** How much peopleâ€™s scores differ **within the same group**.\n",
    "\n",
    "3. ğŸ¯ **Calculate the F-Statistic:**  \n",
    "   This tells us if the differences between groups are **significant**.\n",
    "\n",
    "4. ğŸ¤” **Check P-Value:**  \n",
    "   - If $ p $-value < 0.05, it means **YES, the groups are different**.\n",
    "   - If $ p $-value >= 0.05, it means **NO, the groups are not different**.\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ **Python Example (Pizza Ratings)**\n",
    "\n",
    "Letâ€™s say these are the scores for each brand:\n",
    "\n",
    "- Brand A: [4, 5, 3, 4, 5]  \n",
    "- Brand B: [2, 3, 2, 3, 2]  \n",
    "- Brand C: [5, 5, 4, 5, 4]\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Pizza scores\n",
    "brand_a = [4, 5, 3, 4, 5]\n",
    "brand_b = [2, 3, 2, 3, 2]\n",
    "brand_c = [5, 5, 4, 5, 4]\n",
    "\n",
    "# Perform One-Way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(brand_a, brand_b, brand_c)\n",
    "\n",
    "# Results\n",
    "print(f\"F-Statistic: {f_stat:.2f}\")\n",
    "print(f\"P-Value: {p_value:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"The groups are significantly different. ğŸ• Someone has a favorite!\")\n",
    "else:\n",
    "    print(\"The groups are not significantly different. ğŸ• All brands are equally liked!\")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§ª **Output**  \n",
    "```\n",
    "F-Statistic: 25.71  \n",
    "P-Value: 0.0002  \n",
    "The groups are significantly different. ğŸ• Someone has a favorite!\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## ğŸŒŸ **What Happens Behind the Scenes?**\n",
    "\n",
    "- **Group Averages**: Calculate the mean for each group (e.g., Brand A, B, C).  \n",
    "- **Variability**: Check how scores differ within and between groups.  \n",
    "- **F-Test**: Combine these numbers to see if group differences are real or just random.\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ¥³ **Key Takeaways (Pizza Style):**\n",
    "\n",
    "- ANOVA checks if **group averages** (means) are significantly different.  \n",
    "- If $ p $-value < 0.05: The differences are **real**!  \n",
    "- If $ p $-value â‰¥ 0.05: The differences are **not real** (just random).  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ **Example: Testing Donut Shop Sales**\n",
    "\n",
    "Three donut shopsâ€”**Shop A**, **Shop B**, and **Shop C**â€”track their daily sales (in dollars) for a week.  \n",
    "You want to know:  \n",
    "**\"Do the shops have significantly different average sales?\"**\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ›ï¸ **Data Collection**  \n",
    "Hereâ€™s the sales data:  \n",
    "\n",
    "- **Shop A**: \\$100, \\$120, \\$110, \\$115, \\$105  \n",
    "- **Shop B**: \\$80, \\$85, \\$90, \\$95, \\$85  \n",
    "- **Shop C**: \\$130, \\$140, \\$125, \\$135, \\$145  \n",
    "\n",
    "\n",
    "\n",
    "### ğŸ”¢ **Step 1: Calculate Group Averages**\n",
    "\n",
    "1. Calculate the average sales for each shop:\n",
    "   - Shop A: $ (100 + 120 + 110 + 115 + 105) / 5 = 110 $\n",
    "   - Shop B: $ (80 + 85 + 90 + 95 + 85) / 5 = 87 $\n",
    "   - Shop C: $ (130 + 140 + 125 + 135 + 145) / 5 = 135 $\n",
    "\n",
    "2. The group means are:\n",
    "   - **Shop A**: 110  \n",
    "   - **Shop B**: 87  \n",
    "   - **Shop C**: 135  \n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§® **Step 2: Calculate Overall Mean**\n",
    "\n",
    "- Combine all sales data:\n",
    "  $$\n",
    "  \\text{Overall Mean} = \\frac{100 + 120 + 110 + 115 + 105 + 80 + 85 + 90 + 95 + 85 + 130 + 140 + 125 + 135 + 145}{15} = 110\n",
    "  $$\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ“Š **Step 3: Measure Variations**\n",
    "\n",
    "1. **Between-Group Variation**:  \n",
    "   How much do the group means (Shop A, B, C) differ from the overall mean?  \n",
    "   Use this formula:  \n",
    "   $$\n",
    "   SS_{\\text{between}} = n \\cdot \\sum (\\text{Group Mean} - \\text{Overall Mean})^2\n",
    "   $$  \n",
    "   Where $ n $ is the number of data points per group.  \n",
    "\n",
    "   $$\n",
    "   SS_{\\text{between}} = 5 \\cdot \\left[(110 - 110)^2 + (87 - 110)^2 + (135 - 110)^2\\right]\n",
    "   $$  \n",
    "   $$\n",
    "   SS_{\\text{between}} = 5 \\cdot \\left[0 + 529 + 625\\right] = 5770\n",
    "   $$\n",
    "\n",
    "2. **Within-Group Variation**:  \n",
    "   How much do individual data points vary within each group?  \n",
    "   Use this formula:  \n",
    "   $$\n",
    "   SS_{\\text{within}} = \\sum (\\text{Data Point} - \\text{Group Mean})^2\n",
    "   $$  \n",
    "\n",
    "   For Shop A:  \n",
    "   $$\n",
    "   (100 - 110)^2 + (120 - 110)^2 + (110 - 110)^2 + (115 - 110)^2 + (105 - 110)^2 = 250\n",
    "   $$  \n",
    "   Similarly, calculate for Shop B and Shop C:\n",
    "   - Shop B: $ 250 $\n",
    "   - Shop C: $ 500 $\n",
    "\n",
    "   $$\n",
    "   SS_{\\text{within}} = 250 + 250 + 500 = 1000\n",
    "   $$\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§ª **Step 4: Calculate the F-Statistic**\n",
    "\n",
    "The F-statistic compares the **Between-Group Variation** and the **Within-Group Variation**:  \n",
    "$$\n",
    "F = \\frac{\\text{Mean Square Between Groups}}{\\text{Mean Square Within Groups}}\n",
    "$$  \n",
    "Where:  \n",
    "$$\n",
    "\\text{Mean Square Between Groups} = \\frac{SS_{\\text{between}}}{k - 1} \\quad \\text{and} \\quad \\text{Mean Square Within Groups} = \\frac{SS_{\\text{within}}}{N - k}\n",
    "$$  \n",
    "- $ k = $ Number of groups = 3  \n",
    "- $ N = $ Total data points = 15  \n",
    "\n",
    "1. **Mean Square Between Groups**:\n",
    "   $$\n",
    "   MS_{\\text{between}} = \\frac{5770}{3 - 1} = \\frac{5770}{2} = 2885\n",
    "   $$\n",
    "\n",
    "2. **Mean Square Within Groups**:\n",
    "   $$\n",
    "   MS_{\\text{within}} = \\frac{1000}{15 - 3} = \\frac{1000}{12} \\approx 83.33\n",
    "   $$\n",
    "\n",
    "3. **F-Statistic**:\n",
    "   $$\n",
    "   F = \\frac{2885}{83.33} \\approx 34.61\n",
    "   $$\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ“Š **Step 5: Check the P-Value**\n",
    "\n",
    "- Use the F-distribution table or Python to find the p-value for $ F = 34.61 $ with $ df_{\\text{between}} = 2 $ and $ df_{\\text{within}} = 12 $.\n",
    "- The p-value is **very small** (e.g., $ p < 0.05 $), meaning the group means are significantly different.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ **Python Code**\n",
    "\n",
    "```python\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data\n",
    "shop_a = [100, 120, 110, 115, 105]\n",
    "shop_b = [80, 85, 90, 95, 85]\n",
    "shop_c = [130, 140, 125, 135, 145]\n",
    "\n",
    "# Perform One-Way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(shop_a, shop_b, shop_c)\n",
    "\n",
    "# Results\n",
    "print(f\"F-Statistic: {f_stat:.2f}\")\n",
    "print(f\"P-Value: {p_value:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"The groups are significantly different. ğŸ‰\")\n",
    "else:\n",
    "    print(\"The groups are not significantly different. ğŸ¤”\")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ¥³ **Key Takeaway from the Donut Story**  \n",
    "- If $ p $-value < 0.05, **Yes, the shops have different average sales!**\n",
    "- If $ p $-value â‰¥ 0.05, **No, the shops perform similarly.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
