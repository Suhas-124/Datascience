{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Non-Gaussian Distribution?**\n",
    "\n",
    "\n",
    "## üîç **What is a Probability Distribution?**\n",
    "\n",
    "A **probability distribution** shows how the values of a random variable are distributed. It tells you:\n",
    "- **Which values** the variable can take.\n",
    "- **How likely** each value is to occur.\n",
    "\n",
    "The most commonly known probability distribution is the **Gaussian distribution (Normal distribution)**, which looks like a **bell curve**. It assumes that data is centered around a mean, with symmetrical spread (variance) on both sides.\n",
    "\n",
    "\n",
    "\n",
    "## üö® **What is a Non-Gaussian Distribution?**\n",
    "\n",
    "A **non-Gaussian distribution** is any distribution that does **NOT** follow the shape of the normal bell curve. These distributions can be skewed, heavy-tailed, multimodal, or have other unique characteristics.\n",
    "\n",
    "In real-world data, many datasets are **non-Gaussian**!\n",
    "\n",
    "### üîé **How to Identify a Non-Gaussian Distribution?**\n",
    "Look for these signs:\n",
    "\n",
    "| Property               | Gaussian (Normal) Distribution      | Non-Gaussian Distribution            |\n",
    "|------------------------|-------------------------------------|--------------------------------------|\n",
    "| Shape                  | Bell curve                          | Skewed, heavy-tailed, multimodal     |\n",
    "| Mean = Median = Mode   | Yes                                  | No                                   |\n",
    "| Symmetry               | Symmetrical                         | Asymmetrical                         |\n",
    "| Tails                  | Thin (light tails)                   | Thick (heavy tails)                  |\n",
    "\n",
    "\n",
    "\n",
    "### üìä **Types of Non-Gaussian Distributions**\n",
    "\n",
    "1Ô∏è‚É£ **Skewed Distribution**  \n",
    "- **Example**: Income distribution in a population.\n",
    "- **Explanation**: Most people earn around a lower amount, but a few individuals earn very high salaries, causing a **right-skewed** distribution.\n",
    "\n",
    "2Ô∏è‚É£ **Bimodal Distribution**  \n",
    "- **Example**: Test scores from two groups of students.\n",
    "- **Explanation**: The distribution has **two peaks** (modes), meaning two different groups exist within the data.\n",
    "\n",
    "3Ô∏è‚É£ **Heavy-Tailed Distribution**  \n",
    "- **Example**: Stock market returns.\n",
    "- **Explanation**: Heavy-tailed distributions have more extreme values (outliers) compared to a Gaussian distribution. This makes risk analysis in finance very challenging.\n",
    "\n",
    "4Ô∏è‚É£ **Uniform Distribution**  \n",
    "- **Example**: Rolling a fair die.\n",
    "- **Explanation**: Each outcome has **equal probability**.\n",
    "\n",
    "5Ô∏è‚É£ **Exponential Distribution**  \n",
    "- **Example**: Time between arrivals of customers at a store.\n",
    "- **Explanation**: This is used to model **time-based events**, where shorter intervals are more likely than longer intervals.\n",
    "\n",
    "\n",
    "\n",
    "### üß™ **Why Does Non-Gaussian Data Matter in Machine Learning?**\n",
    "\n",
    "Most ML algorithms (like Linear Regression, Logistic Regression, etc.) **assume Gaussian distributions** for features. However, if your data is non-Gaussian, you might need to apply **transformations** to make it more normal-like.\n",
    "\n",
    "üîß **Techniques to Handle Non-Gaussian Data:**\n",
    "1. **Log Transformation** ‚Äì Used for right-skewed data.\n",
    "2. **Box-Cox Transformation** ‚Äì Makes data more Gaussian-like.\n",
    "3. **Standard Scaling (Z-score)** ‚Äì Centers data but doesn‚Äôt change distribution shape.\n",
    "\n",
    "\n",
    "\n",
    "### üìö **Real-World Examples of Non-Gaussian Data in Machine Learning**\n",
    "\n",
    "| Use Case               | Distribution Type         | Explanation                               |\n",
    "|------------------------|---------------------------|-------------------------------------------|\n",
    "| Customer Income        | Skewed Distribution        | Most customers earn low, few earn high.   |\n",
    "| Website Traffic        | Bimodal Distribution       | Peaks during morning and evening.         |\n",
    "| Social Media Likes     | Heavy-Tailed Distribution  | Some posts go viral, most don‚Äôt.          |\n",
    "| Call Center Wait Times | Exponential Distribution   | Short wait times are more common.         |\n",
    "\n",
    "\n",
    "### ü§î **Key Takeaways**\n",
    "- **Gaussian distribution** is not always a good assumption for real-world data.\n",
    "- **Non-Gaussian distributions** can be skewed, multimodal, or heavy-tailed.\n",
    "- Handling non-Gaussian data requires **feature transformation techniques** in ML.\n",
    "- Understanding the distribution helps in **better model selection** and **more accurate predictions**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](non-gauss.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](uniform.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß **1Ô∏è‚É£ Log Transformation (for Right-Skewed Data)**\n",
    "### üìò **What is Log Transformation?**\n",
    "A **log transformation** is a mathematical technique used to handle **right-skewed data**. It **compresses larger values more than smaller values**, reducing the impact of outliers and making the data closer to a normal distribution.\n",
    "\n",
    "### üìà **When to Use:**\n",
    "- When your data has a **long right tail** (right-skewed).\n",
    "- When dealing with **income**, **prices**, **population sizes**, etc., where the values grow exponentially.\n",
    "\n",
    "\n",
    "\n",
    "### ü§î **Why Use Log Transformation?**\n",
    "Imagine you have the following data:\n",
    "\n",
    "| Income ($) |\n",
    "|------------|\n",
    "| 30,000     |\n",
    "| 50,000     |\n",
    "| 100,000    |\n",
    "| 500,000    |\n",
    "| 1,000,000  |\n",
    "\n",
    "Without a log transformation, the **larger incomes dominate** the dataset. A log transformation **scales down** these large values, making the dataset more balanced.\n",
    "\n",
    "\n",
    "\n",
    "### ‚úÖ **Example:**\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Original right-skewed data\n",
    "data = np.random.exponential(scale=2, size=1000)\n",
    "\n",
    "# Apply log transformation\n",
    "log_data = np.log1p(data)\n",
    "\n",
    "# Plot original vs transformed data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=30, color='orange', alpha=0.7)\n",
    "plt.title(\"Original Data (Right-Skewed)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(log_data, bins=30, color='green', alpha=0.7)\n",
    "plt.title(\"Log Transformed Data\")\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### üîç **Key Points:**\n",
    "- **`np.log1p(data)`** applies a **log transformation**.\n",
    "- Notice how the long right tail is **compressed**, making the data closer to a normal distribution.\n",
    "\n",
    "\n",
    "\n",
    "## üîß **2Ô∏è‚É£ Box-Cox Transformation (General Transformation)**\n",
    "### üìò **What is Box-Cox Transformation?**\n",
    "The **Box-Cox Transformation** is a **general method** to make data **more Gaussian-like** by adjusting the distribution shape using a **lambda (Œª)** parameter.\n",
    "\n",
    "Unlike the log transformation, **Box-Cox** works for both **right-skewed** and **left-skewed** data.\n",
    "\n",
    "\n",
    "\n",
    "### ü§î **Why Use Box-Cox?**\n",
    "It‚Äôs more flexible than a log transformation because it can handle **various types of skewness** by tuning the **lambda (Œª)** parameter.\n",
    "\n",
    "| Lambda (Œª) Value | Transformation Applied     |\n",
    "|------------------|----------------------------|\n",
    "| Œª = 0            | Log Transformation         |\n",
    "| Œª = 1            | No Transformation (Original Data) |\n",
    "| Œª = -1           | Reciprocal Transformation   |\n",
    "\n",
    "\n",
    "\n",
    "### ‚úÖ **Example:**\n",
    "```python\n",
    "from scipy import stats\n",
    "\n",
    "# Original right-skewed data\n",
    "data = np.random.exponential(scale=2, size=1000)\n",
    "\n",
    "# Apply Box-Cox transformation\n",
    "box_cox_data, _ = stats.boxcox(data + 1)  # Add 1 to avoid issues with zero values\n",
    "\n",
    "# Plot original vs transformed data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=30, color='orange', alpha=0.7)\n",
    "plt.title(\"Original Data (Right-Skewed)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(box_cox_data, bins=30, color='blue', alpha=0.7)\n",
    "plt.title(\"Box-Cox Transformed Data\")\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### üîç **Key Points:**\n",
    "- **Box-Cox works best for positive values.** \n",
    "- The transformation adjusts based on the **lambda (Œª)** parameter to make data more Gaussian-like.\n",
    "\n",
    "\n",
    "\n",
    "## üîß **3Ô∏è‚É£ Standard Scaling (Z-Score Normalization)**\n",
    "### üìò **What is Standard Scaling?**\n",
    "**Standard Scaling** (also known as **Z-score normalization**) transforms the data by **centering it at 0** and scaling it to have a **standard deviation of 1**.\n",
    "\n",
    "Unlike log or Box-Cox transformations, **Z-score scaling doesn‚Äôt change the distribution shape**. It just **standardizes** the values to make them easier to compare.\n",
    "\n",
    "\n",
    "\n",
    "### üßÆ **Formula for Z-Score:**\n",
    "$$\n",
    "Z = \\frac{X - \\mu}{\\sigma}\n",
    "$$\n",
    "Where:\n",
    "- $ X $ = Original value\n",
    "- $ \\mu $ = Mean of the data\n",
    "- $ \\sigma $ = Standard deviation of the data\n",
    "\n",
    "\n",
    "\n",
    "### ü§î **Why Use Standard Scaling?**\n",
    "- When you want to ensure all features in your dataset are on the **same scale**.\n",
    "- It‚Äôs particularly useful for **machine learning algorithms** that are sensitive to different scales, such as **KNN**, **SVM**, and **PCA**.\n",
    "\n",
    "\n",
    "\n",
    "### ‚úÖ **Example:**\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sample data\n",
    "data = np.random.rand(100, 1) * 100  # Random values between 0 and 100\n",
    "\n",
    "# Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Plot original vs scaled data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=30, color='orange', alpha=0.7)\n",
    "plt.title(\"Original Data\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(scaled_data, bins=30, color='green', alpha=0.7)\n",
    "plt.title(\"Standard Scaled Data\")\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### üîç **Key Points:**\n",
    "- **StandardScaler** in **Scikit-Learn** is used for Z-score scaling.\n",
    "- Notice how the scaled data is centered around **0** with a **standard deviation of 1**.\n",
    "\n",
    "\n",
    "\n",
    "## üõ† **Summary: When to Use Which Transformation?**\n",
    "\n",
    "| Transformation      | Use Case                                | Example                                  |\n",
    "|---------------------|-----------------------------------------|------------------------------------------|\n",
    "| **Log Transformation** | Right-skewed data                      | Income, Prices                           |\n",
    "| **Box-Cox Transformation** | Both right and left-skewed data        | Power Consumption, Population Sizes      |\n",
    "| **Standard Scaling**  | Standardizing data without changing shape | Machine Learning Algorithms              |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](log.png)\n",
    "![](box-cox.png)\n",
    "![](scaling.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ **What is Yeo-Johnson Transformation?**\n",
    "\n",
    "The **Yeo-Johnson Transformation** is a **generalized transformation method** that helps make your data look more **Gaussian-like** (normally distributed). It is similar to the **Box-Cox Transformation**, but with one important difference:\n",
    "\n",
    "‚úÖ **It can handle both positive and negative values!**  \n",
    "‚úÖ **It works for skewed data (both left-skewed and right-skewed).**  \n",
    "\n",
    "\n",
    "\n",
    "## üìà **When to Use Yeo-Johnson Transformation?**\n",
    "Use the Yeo-Johnson Transformation when:\n",
    "\n",
    "- Your data contains **both positive and negative values**.\n",
    "- Your data is **skewed** (either left or right).\n",
    "- You need a **more flexible transformation** compared to Box-Cox.\n",
    "\n",
    "\n",
    "\n",
    "## üßÆ **The Formula for Yeo-Johnson:**\n",
    "\n",
    "$$\n",
    "y(\\lambda) = \n",
    "\\begin{cases} \n",
    "\\left[ \\left( y + 1 \\right)^\\lambda - 1 \\right] / \\lambda & \\text{if } y \\geq 0, \\lambda \\neq 0 \\\\\n",
    "\\log(y + 1) & \\text{if } y \\geq 0, \\lambda = 0 \\\\\n",
    "- \\left[ \\left( -y + 1 \\right)^{2 - \\lambda} - 1 \\right] / (2 - \\lambda) & \\text{if } y < 0, \\lambda \\neq 2 \\\\\n",
    "-\\log(-y + 1) & \\text{if } y < 0, \\lambda = 2\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Don't worry if this looks complicated! It basically adjusts the transformation based on whether the values are **positive or negative**, and uses a **lambda (Œª)** parameter to control the transformation strength.\n",
    "\n",
    "\n",
    "\n",
    "## ü§î **Difference Between Yeo-Johnson and Box-Cox:**\n",
    "\n",
    "| Feature                | Box-Cox Transformation               | Yeo-Johnson Transformation             |\n",
    "|------------------------|--------------------------------------|---------------------------------------|\n",
    "| **Handles Negative Values** | ‚ùå No                                 | ‚úÖ Yes                                 |\n",
    "| **Requires Positive Values** | ‚úÖ Yes (all values must be > 0)        | ‚ùå No (can handle both positive & negative) |\n",
    "| **Flexibility**         | Works for right-skewed & left-skewed | Works for all types of skewed data    |\n",
    "\n",
    "\n",
    "\n",
    "## ‚úÖ **Example in Python:**\n",
    "\n",
    "Let's apply the **Yeo-Johnson Transformation** on a dataset with **both positive and negative values**.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Generate a dataset with both positive and negative values\n",
    "data = np.random.normal(loc=0, scale=5, size=1000)  # Normally distributed with mean 0\n",
    "\n",
    "# Apply Yeo-Johnson Transformation\n",
    "yeo_johnson = PowerTransformer(method='yeo-johnson')\n",
    "transformed_data = yeo_johnson.fit_transform(data.reshape(-1, 1))\n",
    "\n",
    "# Plot original vs transformed data\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Original data\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=30, color='orange', alpha=0.7)\n",
    "plt.title(\"Original Data\")\n",
    "\n",
    "# Transformed data\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(transformed_data, bins=30, color='green', alpha=0.7)\n",
    "plt.title(\"Yeo-Johnson Transformed Data\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## üîç **Explanation of the Code:**\n",
    "- **`PowerTransformer(method='yeo-johnson')`**: This is the Scikit-Learn function to apply the Yeo-Johnson transformation.\n",
    "- **Original Data:** The histogram shows a skewed distribution with both positive and negative values.\n",
    "- **Transformed Data:** The Yeo-Johnson transformation adjusts the data to make it look more like a **normal distribution**.\n",
    "\n",
    "\n",
    "\n",
    "## üìä **How Yeo-Johnson Works with Different Skewed Data:**\n",
    "\n",
    "| Data Type        | Effect of Yeo-Johnson Transformation |\n",
    "|------------------|-------------------------------------|\n",
    "| Right-skewed     | Reduces the **right tail** to make it more symmetric |\n",
    "| Left-skewed      | Reduces the **left tail** to make it more symmetric  |\n",
    "| Positive values  | Adjusts values like **Box-Cox**     |\n",
    "| Negative values  | Works without requiring any shift   |\n",
    "\n",
    "\n",
    "\n",
    "## üß™ **When Should You Use Yeo-Johnson vs. Box-Cox?**\n",
    "\n",
    "| Scenario                         | Transformation to Use     |\n",
    "|----------------------------------|--------------------------|\n",
    "| Data has **only positive values** | Box-Cox Transformation    |\n",
    "| Data has **positive & negative values** | Yeo-Johnson Transformation |\n",
    "\n",
    "\n",
    "\n",
    "## üß© **Advantages of Yeo-Johnson:**\n",
    "- Works for both **positive and negative values**.\n",
    "- Reduces skewness in the data.\n",
    "- Helps in improving **model performance** for algorithms that assume normally distributed data (e.g., **linear regression**, **SVM**).\n",
    "\n",
    "\n",
    "\n",
    "## ‚ö†Ô∏è **Important Notes:**\n",
    "- **Yeo-Johnson** works well for datasets with both **positive and negative values**.\n",
    "- For **Box-Cox**, all values must be **greater than zero**.\n",
    "- Both transformations use the **lambda (Œª)** parameter to control the transformation strength.\n",
    "\n",
    "\n",
    "\n",
    "## ‚úÖ **Summary:**\n",
    "\n",
    "| Transformation      | Handles Negative Values | Handles Skewed Data | Normalizes Data | Common Use Case                |\n",
    "|---------------------|------------------------|---------------------|-----------------|--------------------------------|\n",
    "| **Log Transformation** | ‚ùå No                   | ‚úÖ Yes               | ‚úÖ Yes          | Right-skewed data              |\n",
    "| **Box-Cox Transformation** | ‚ùå No                   | ‚úÖ Yes               | ‚úÖ Yes          | Positive right-skewed data     |\n",
    "| **Yeo-Johnson Transformation** | ‚úÖ Yes                  | ‚úÖ Yes               | ‚úÖ Yes          | Both positive & negative values |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](yeo-jhonson.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö **Transformations in Statistics**\n",
    "\n",
    "**Transformations** in statistics are mathematical operations applied to a dataset to make it easier to analyze, interpret, and model. They are often used to:\n",
    "\n",
    "‚úÖ **Reduce skewness**  \n",
    "‚úÖ **Stabilize variance**  \n",
    "‚úÖ **Make data more Gaussian-like**  \n",
    "‚úÖ **Improve model performance**\n",
    "\n",
    "\n",
    "\n",
    "## üß© **Types of Transformations:**\n",
    "\n",
    "1. **Log Transformation**  \n",
    "2. **Square Root Transformation**  \n",
    "3. **Reciprocal Transformation**  \n",
    "4. **Box-Cox Transformation**  \n",
    "5. **Yeo-Johnson Transformation**  \n",
    "6. **Power Transformation**  \n",
    "7. **Z-score Normalization (Standard Scaling)**  \n",
    "8. **Min-Max Scaling (Normalization)**\n",
    "\n",
    "Let‚Äôs explore each transformation in detail.\n",
    "\n",
    "\n",
    "\n",
    "## üßÆ **1Ô∏è‚É£ Log Transformation**\n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "y' = \\log(y)\n",
    "$$\n",
    "\n",
    "**Purpose:**  \n",
    "- Reduces **right skewness**.  \n",
    "- Helps when the data has **large outliers**.\n",
    "\n",
    "**Example:** Income data often has a **right-skewed** distribution, where most people earn average salaries, and a few earn very high amounts.\n",
    "\n",
    "### ‚úÖ **Python Code Example:**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "data = np.random.exponential(scale=2, size=1000)\n",
    "\n",
    "# Log transformation\n",
    "log_data = np.log(data + 1)  # Adding 1 to avoid log(0)\n",
    "\n",
    "# Plot original vs transformed data\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=30, color='orange')\n",
    "plt.title(\"Original Data\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(log_data, bins=30, color='green')\n",
    "plt.title(\"Log Transformed Data\")\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## üßÆ **2Ô∏è‚É£ Square Root Transformation**\n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "y' = \\sqrt{y}\n",
    "$$\n",
    "\n",
    "**Purpose:**  \n",
    "- Useful for **count data** (e.g., number of visits to a website).  \n",
    "- Reduces the impact of **large values** and stabilizes **variance**.\n",
    "\n",
    "**Example:** If you have count data like **number of customer visits** or **sales transactions**, this transformation helps reduce skewness.\n",
    "\n",
    "### ‚úÖ **Python Code Example:**\n",
    "\n",
    "```python\n",
    "# Sample data\n",
    "count_data = np.random.poisson(lam=5, size=1000)\n",
    "\n",
    "# Square root transformation\n",
    "sqrt_data = np.sqrt(count_data)\n",
    "\n",
    "# Plot original vs transformed data\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(count_data, bins=30, color='orange')\n",
    "plt.title(\"Original Count Data\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(sqrt_data, bins=30, color='green')\n",
    "plt.title(\"Square Root Transformed Data\")\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## üßÆ **3Ô∏è‚É£ Reciprocal Transformation**\n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "y' = \\frac{1}{y}\n",
    "$$\n",
    "\n",
    "**Purpose:**  \n",
    "- Reduces the impact of **large values**.  \n",
    "- Often used for **right-skewed** data.\n",
    "\n",
    "**Example:** Useful for **rates or ratios**, like **speed (1/time)** or **frequency**.\n",
    "\n",
    "\n",
    "\n",
    "## üßÆ **4Ô∏è‚É£ Box-Cox Transformation**\n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "y'(\\lambda) = \n",
    "\\begin{cases} \n",
    "\\frac{y^\\lambda - 1}{\\lambda} & \\lambda \\neq 0 \\\\\n",
    "\\log(y) & \\lambda = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Purpose:**  \n",
    "- Makes data **more Gaussian-like**.  \n",
    "- Works only for **positive values**.\n",
    "\n",
    "**Lambda (Œª):** The parameter that controls the transformation.\n",
    "\n",
    "### ‚úÖ **Python Code Example:**\n",
    "\n",
    "```python\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Sample data\n",
    "data = np.random.exponential(scale=2, size=1000)\n",
    "\n",
    "# Apply Box-Cox Transformation\n",
    "boxcox_data, lambda_val = boxcox(data + 1)  # Adding 1 to avoid issues with zero values\n",
    "\n",
    "print(f\"Optimal Lambda: {lambda_val}\")\n",
    "\n",
    "# Plot original vs transformed data\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=30, color='orange')\n",
    "plt.title(\"Original Data\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(boxcox_data, bins=30, color='green')\n",
    "plt.title(\"Box-Cox Transformed Data\")\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## üßÆ **5Ô∏è‚É£ Yeo-Johnson Transformation**  \n",
    "(Explained earlier)\n",
    "\n",
    "\n",
    "\n",
    "## üßÆ **6Ô∏è‚É£ Power Transformation (Generalized)**\n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "y' = y^\\lambda\n",
    "$$\n",
    "\n",
    "**Purpose:**  \n",
    "- Stabilizes **variance**.  \n",
    "- Reduces **skewness**.\n",
    "\n",
    "### ‚úÖ **Python Code Example:**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Sample data\n",
    "data = np.random.normal(loc=5, scale=10, size=1000)\n",
    "\n",
    "# Apply Power Transformation (Yeo-Johnson method)\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "transformed_data = pt.fit_transform(data.reshape(-1, 1))\n",
    "\n",
    "# Plot original vs transformed data\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=30, color='orange')\n",
    "plt.title(\"Original Data\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(transformed_data, bins=30, color='green')\n",
    "plt.title(\"Power Transformed Data\")\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## üßÆ **7Ô∏è‚É£ Z-score Normalization (Standard Scaling)**\n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "**Purpose:**  \n",
    "- Centers the data around **mean = 0** and **standard deviation = 1**.  \n",
    "- Does not change the **shape** of the distribution.\n",
    "\n",
    "\n",
    "\n",
    "## üßÆ **8Ô∏è‚É£ Min-Max Scaling (Normalization)**\n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "x' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n",
    "$$\n",
    "\n",
    "**Purpose:**  \n",
    "- Rescales data to a **fixed range**, typically **[0, 1]**.  \n",
    "- Useful for **features with different scales**.\n",
    "\n",
    "## üìä **Comparison of Transformations:**\n",
    "\n",
    "| Transformation       | Purpose                               | Handles Negative Values? | Stabilizes Variance? | Reduces Skewness? |\n",
    "|----------------------|---------------------------------------|-------------------------|----------------------|-------------------|\n",
    "| Log Transformation   | Reduces right skew                    | ‚ùå No                    | ‚úÖ Yes               | ‚úÖ Yes            |\n",
    "| Square Root          | Stabilizes variance                   | ‚úÖ Yes                  | ‚úÖ Yes               | ‚úÖ Yes            |\n",
    "| Reciprocal           | Reduces impact of large values        | ‚ùå No                    | ‚úÖ Yes               | ‚úÖ Yes            |\n",
    "| Box-Cox              | Makes data Gaussian-like              | ‚ùå No                    | ‚úÖ Yes               | ‚úÖ Yes            |\n",
    "| Yeo-Johnson          | Makes data Gaussian-like              | ‚úÖ Yes                  | ‚úÖ Yes               | ‚úÖ Yes            |\n",
    "| Power Transformation | Generalized transformation            | ‚úÖ Yes                  | ‚úÖ Yes               | ‚úÖ Yes            |\n",
    "| Z-score Scaling      | Centers data                          | ‚úÖ Yes                  | ‚ùå No                | ‚ùå No             |\n",
    "| Min-Max Scaling      | Rescales data to [0, 1]               | ‚úÖ Yes                  | ‚ùå No                | ‚ùå No             |\n",
    "\n",
    "\n",
    "## ‚úÖ **Summary:**\n",
    "Transformations help handle skewed data, stabilize variance, and improve the performance of statistical models. Here‚Äôs when to use each:\n",
    "\n",
    "- **Log Transformation**: Right-skewed data with large outliers.  \n",
    "- **Box-Cox**: Positive data only, when you want a Gaussian-like distribution.  \n",
    "- **Yeo-Johnson**: For both positive and negative values.  \n",
    "- **Z-score Scaling**: Standardizes data without changing distribution shape.  \n",
    "- **Min-Max Scaling**: Rescales features to a fixed range.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](sqrt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
