{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent:\n",
    "\n",
    "Gradient Descent is an optimization algorithm used to train machine learning models by adjusting their parameters (weights and biases) to minimize a given loss function. It is fundamental in machine learning, particularly in training models like linear regression, logistic regression, and neural networks.\n",
    "\n",
    "Here’s a complete explanation:\n",
    "\n",
    "\n",
    "\n",
    "### **1. The Goal of Gradient Descent**\n",
    "The primary objective of gradient descent is to find the parameters of a model that minimize the loss function, which measures the error between predicted outputs and actual outputs. Lower loss indicates a better-performing model.\n",
    "\n",
    "\n",
    "\n",
    "### **2. The Concept of Gradients**\n",
    "- A **gradient** is a vector that points in the direction of the steepest increase of a function.\n",
    "- For gradient descent, we are interested in minimizing a function (the loss), so we move in the direction opposite to the gradient.\n",
    "\n",
    "\n",
    "\n",
    "### **3. How Gradient Descent Works**\n",
    "Gradient descent works iteratively to update model parameters. The process can be summarized as:\n",
    "\n",
    "#### **Step 1: Initialization**\n",
    "- Randomly initialize the parameters (weights $w$ and bias $b$).\n",
    "\n",
    "#### **Step 2: Compute the Gradient**\n",
    "- Calculate the gradient of the loss function with respect to each parameter. This gives the direction and rate of change of the loss.\n",
    "\n",
    "#### **Step 3: Update Parameters**\n",
    "- Update the parameters by moving them in the opposite direction of the gradient. The update rule for each parameter is:\n",
    "  $$\n",
    "  \\theta \\gets \\theta - \\eta \\cdot \\frac{\\partial L}{\\partial \\theta}\n",
    "  $$\n",
    "  Where:\n",
    "  - $\\theta$: The parameter being updated (e.g., weight or bias).\n",
    "  - $\\eta$: The learning rate (step size).\n",
    "  - $\\frac{\\partial L}{\\partial \\theta}$: The gradient of the loss $L$ with respect to $\\theta$.\n",
    "\n",
    "#### **Step 4: Repeat**\n",
    "- Repeat steps 2 and 3 until convergence (when the loss stops decreasing significantly).\n",
    "\n",
    "\n",
    "\n",
    "### **4. Learning Rate ($\\eta$)**\n",
    "The learning rate is a crucial hyperparameter:\n",
    "- If $\\eta$ is too large, updates may overshoot the minimum, causing divergence.\n",
    "- If $\\eta$ is too small, convergence will be slow.\n",
    "\n",
    "\n",
    "\n",
    "### **5. Types of Gradient Descent**\n",
    "There are three main variants of gradient descent, differing in how they calculate the gradient:\n",
    "\n",
    "#### (a) **Batch Gradient Descent**\n",
    "- Uses the entire dataset to compute the gradient in each iteration.\n",
    "- Pros: Converges steadily.\n",
    "- Cons: Can be computationally expensive for large datasets.\n",
    "\n",
    "#### (b) **Stochastic Gradient Descent (SGD)**\n",
    "- Computes the gradient using only one data point (randomly selected) at a time.\n",
    "- Pros: Faster and can escape local minima.\n",
    "- Cons: Noisy updates can cause fluctuations around the minimum.\n",
    "\n",
    "#### (c) **Mini-Batch Gradient Descent**\n",
    "- Uses a small batch of data points (e.g., 32 or 64) to compute the gradient.\n",
    "- Pros: Combines the benefits of batch and stochastic gradient descent.\n",
    "\n",
    "\n",
    "\n",
    "### **6. Gradient Descent in Machine Learning**\n",
    "In supervised learning:\n",
    "- **For Linear Regression**: Gradient descent minimizes the Mean Squared Error (MSE) loss.\n",
    "- **For Logistic Regression**: Gradient descent minimizes the Log Loss (Cross-Entropy Loss).\n",
    "- **For Neural Networks**: Gradient descent minimizes a loss function by backpropagating errors.\n",
    "\n",
    "\n",
    "\n",
    "### **7. Challenges and Solutions**\n",
    "1. **Local Minima**:\n",
    "   - For some loss functions, gradient descent might get stuck in a local minimum.\n",
    "   - Solution: Use techniques like momentum or Adam optimizer.\n",
    "\n",
    "2. **Vanishing/Exploding Gradients**:\n",
    "   - Gradients may become too small or too large in deep networks.\n",
    "   - Solution: Use techniques like ReLU activations, batch normalization, or gradient clipping.\n",
    "\n",
    "3. **Choosing the Right Learning Rate**:\n",
    "   - Solution: Use learning rate schedules or adaptive learning rate optimizers (e.g., Adam, RMSProp).\n",
    "\n",
    "\n",
    "\n",
    "### **8. Visual Understanding**\n",
    "- Imagine a ball rolling down a hill. The slope of the hill represents the gradient. The ball's movement (parameter updates) will eventually lead it to the bottom of the hill (the minimum of the loss function).\n",
    "\n",
    "\n",
    "\n",
    "### **Mathematical Example**\n",
    "Let’s minimize the function $f(w) = w^2$ (a simple loss function).\n",
    "\n",
    "1. Compute the gradient: $\\frac{\\partial f}{\\partial w} = 2w$.\n",
    "2. Update rule: $w \\gets w - \\eta \\cdot 2w$.\n",
    "3. If $w = 1$ and $\\eta = 0.1$:\n",
    "   - Gradient: $2 \\times 1 = 2$.\n",
    "   - Update: $w = 1 - 0.1 \\times 2 = 0.8$.\n",
    "   - Repeat until $w \\approx 0$.\n",
    "\n",
    "\n",
    "\n",
    "### **Key Takeaway**\n",
    "Gradient Descent iteratively optimizes the parameters of a model by minimizing the loss function, enabling the model to make better predictions. Variants and adaptive techniques ensure its efficiency for various types of problems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Equations of Gradient Descent:\n",
    "\n",
    "Let’s dive deep into the **mathematics of gradient descent**, covering all the essential concepts, starting from the loss function to the update formulas for the parameters. This includes derivatives, gradients, and step-by-step explanation.\n",
    "\n",
    "\n",
    "\n",
    "### **1. Loss Function**\n",
    "The **loss function** $L(\\theta)$ quantifies the error of a model's prediction. \n",
    "\n",
    "#### Example Loss Functions:\n",
    "- **For Regression**: Mean Squared Error (MSE):\n",
    "  $$\n",
    "  L(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\left( y_i - \\hat{y}_i \\right)^2\n",
    "  $$\n",
    "  where:\n",
    "  - $m$: Number of training samples.\n",
    "  - $y_i$: True value of the $i$-th sample.\n",
    "  - $\\hat{y}_i$: Predicted value of the $i$-th sample.\n",
    "  \n",
    "- **For Classification**: Binary Cross-Entropy (Log Loss):\n",
    "  $$\n",
    "  L(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
    "  $$\n",
    "\n",
    "Here, $\\theta$ represents the parameters (weights and biases) of the model. The goal is to minimize $L(\\theta)$.\n",
    "\n",
    "\n",
    "\n",
    "### **2. Gradient Calculation**\n",
    "To minimize the loss function, we compute the **gradient** of the loss function with respect to the model parameters, denoted as:\n",
    "$$\n",
    "\\nabla_\\theta L(\\theta) = \\left[ \\frac{\\partial L}{\\partial \\theta_1}, \\frac{\\partial L}{\\partial \\theta_2}, \\dots, \\frac{\\partial L}{\\partial \\theta_n} \\right]\n",
    "$$\n",
    "\n",
    "#### General Form of Gradient:\n",
    "For any function $f(\\theta)$, the gradient points in the direction of the steepest increase:\n",
    "$$\n",
    "\\frac{\\partial f(\\theta)}{\\partial \\theta} = \\lim_{h \\to 0} \\frac{f(\\theta + h) - f(\\theta)}{h}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### **3. Gradient Descent Algorithm**\n",
    "Gradient descent updates the model parameters iteratively to reduce the loss function. The **update rule** is:\n",
    "\n",
    "#### Update Rule:\n",
    "$$\n",
    "\\theta \\gets \\theta - \\eta \\cdot \\nabla_\\theta L(\\theta)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\theta$: Current parameters (e.g., weights and biases).\n",
    "- $\\eta$: Learning rate (a hyperparameter controlling the step size).\n",
    "- $\\nabla_\\theta L(\\theta)$: Gradient of the loss function with respect to $\\theta$.\n",
    "\n",
    "\n",
    "\n",
    "### **4. Step-by-Step Explanation**\n",
    "#### Step 1: Compute the Prediction\n",
    "For a model $h_\\theta(x)$:\n",
    "- **Linear Regression**: $h_\\theta(x) = \\theta_0 + \\theta_1 x$.\n",
    "- **Logistic Regression**: $h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}}$.\n",
    "\n",
    "#### Step 2: Define the Loss Function\n",
    "The loss function $L(\\theta)$ measures the error between predictions $h_\\theta(x)$ and true values $y$.\n",
    "\n",
    "#### Step 3: Compute the Gradient\n",
    "For each parameter $\\theta_j$:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_j} = \\text{gradient of the loss function with respect to } \\theta_j\n",
    "$$\n",
    "\n",
    "Example for MSE:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_j} = -\\frac{2}{m} \\sum_{i=1}^m \\left( y_i - \\hat{y}_i \\right) \\cdot x_{ij}\n",
    "$$\n",
    "\n",
    "#### Step 4: Update the Parameters\n",
    "Using the update rule:\n",
    "$$\n",
    "\\theta_j \\gets \\theta_j - \\eta \\cdot \\frac{\\partial L}{\\partial \\theta_j}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### **5. Gradient Descent for Linear Regression**\n",
    "Let’s solve a practical example to illustrate the formulas:\n",
    "\n",
    "#### Model:\n",
    "$$\n",
    "h_\\theta(x) = \\theta_0 + \\theta_1 x\n",
    "$$\n",
    "\n",
    "#### Loss Function (MSE):\n",
    "$$\n",
    "L(\\theta_0, \\theta_1) = \\frac{1}{m} \\sum_{i=1}^m \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right)^2\n",
    "$$\n",
    "\n",
    "#### Gradients:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_0} = -\\frac{2}{m} \\sum_{i=1}^m \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_1} = -\\frac{2}{m} \\sum_{i=1}^m \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right) \\cdot x_i\n",
    "$$\n",
    "\n",
    "#### Updates:\n",
    "$$\n",
    "\\theta_0 \\gets \\theta_0 - \\eta \\cdot \\frac{\\partial L}{\\partial \\theta_0}\n",
    "$$\n",
    "$$\n",
    "\\theta_1 \\gets \\theta_1 - \\eta \\cdot \\frac{\\partial L}{\\partial \\theta_1}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### **6. Gradient Descent for Logistic Regression**\n",
    "For binary classification using logistic regression:\n",
    "\n",
    "#### Model:\n",
    "$$\n",
    "h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}}\n",
    "$$\n",
    "\n",
    "#### Loss Function (Binary Cross-Entropy):\n",
    "$$\n",
    "L(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y_i \\log(h_\\theta(x_i)) + (1 - y_i) \\log(1 - h_\\theta(x_i)) \\right]\n",
    "$$\n",
    "\n",
    "#### Gradient:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta(x_i) - y_i \\right) \\cdot x_{ij}\n",
    "$$\n",
    "\n",
    "#### Updates:\n",
    "$$\n",
    "\\theta_j \\gets \\theta_j - \\eta \\cdot \\frac{\\partial L}{\\partial \\theta_j}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### **7. Convergence**\n",
    "Gradient descent repeats until the algorithm converges, i.e., when:\n",
    "- The loss $L(\\theta)$ stops decreasing significantly.\n",
    "- The gradients $\\nabla_\\theta L(\\theta)$ are close to zero.\n",
    "\n",
    "\n",
    "\n",
    "### **8. Variants of Gradient Descent**\n",
    "- **Batch Gradient Descent**: Uses the entire dataset.\n",
    "- **Stochastic Gradient Descent (SGD)**: Uses one data point per iteration.\n",
    "- **Mini-Batch Gradient Descent**: Uses a subset of data points per iteration.\n",
    "\n",
    "\n",
    "\n",
    "### Example Illustration\n",
    "Let’s optimize the simple quadratic function $f(w) = w^2$:\n",
    "\n",
    "1. Loss function: $f(w) = w^2$.\n",
    "2. Gradient: $\\frac{df}{dw} = 2w$.\n",
    "3. Update rule: $w \\gets w - \\eta \\cdot 2w$.\n",
    "\n",
    "For $w = 1$ and $\\eta = 0.1$:\n",
    "- Gradient: $2 \\times 1 = 2$.\n",
    "- Update: $w = 1 - 0.1 \\times 2 = 0.8$.\n",
    "- Repeat until $w \\approx 0$.\n",
    "\n",
    "\n",
    "\n",
    "### Summary of Key Formulas\n",
    "1. **Gradient Descent Update**:\n",
    "   $$\n",
    "   \\theta \\gets \\theta - \\eta \\cdot \\nabla_\\theta L(\\theta)\n",
    "   $$\n",
    "2. **Gradient for Each Parameter**:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\theta_j} = \\text{Partial derivative of the loss with respect to } \\theta_j\n",
    "   $$\n",
    "\n",
    "Gradient descent systematically minimizes the loss by adjusting parameters step by step, guided by the calculated gradients.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Batch Gradient Descent:**\n",
    "\n",
    "Batch Gradient Descent is a type of gradient descent algorithm that computes the gradient of the entire **loss function** over the complete dataset in each iteration. It updates the parameters after considering all the training data.\n",
    "\n",
    "\n",
    "\n",
    "### **1. Steps in Batch Gradient Descent**\n",
    "\n",
    "#### **Step 1: Initialize Parameters**\n",
    "Randomly initialize the model parameters (e.g., weights $ \\theta $).\n",
    "\n",
    "#### **Step 2: Compute Predictions**\n",
    "For all training examples:\n",
    "$$\n",
    "\\hat{y}_i = h_\\theta(x_i)\n",
    "$$\n",
    "Where:\n",
    "- $h_\\theta(x_i)$ is the model’s prediction (e.g., $h_\\theta(x) = \\theta^T x$ for linear regression).\n",
    "\n",
    "#### **Step 3: Define the Loss Function**\n",
    "The loss function $L(\\theta)$ measures the error between predictions ($\\hat{y}_i$) and true values ($y_i$):\n",
    "\n",
    "- **For Linear Regression (Mean Squared Error)**:\n",
    "$$\n",
    "L(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\left( y_i - \\hat{y}_i \\right)^2\n",
    "$$\n",
    "\n",
    "- **For Logistic Regression (Binary Cross-Entropy)**:\n",
    "$$\n",
    "L(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- $m$: Number of training samples.\n",
    "- $y_i$: True label for the $i$-th example.\n",
    "- $\\hat{y}_i$: Predicted value for the $i$-th example.\n",
    "\n",
    "#### **Step 4: Compute Gradients**\n",
    "The gradient is computed as the derivative of the loss function $L(\\theta)$ with respect to each parameter $\\theta_j$.\n",
    "\n",
    "- **General Gradient Formula**:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( \\hat{y}_i - y_i \\right) \\cdot x_{ij}\n",
    "$$\n",
    "Where:\n",
    "- $x_{ij}$: The value of the $j$-th feature for the $i$-th example.\n",
    "\n",
    "#### **Step 5: Update Parameters**\n",
    "Update all parameters $\\theta_j$ simultaneously using the formula:\n",
    "$$\n",
    "\\theta_j \\gets \\theta_j - \\eta \\cdot \\frac{\\partial L}{\\partial \\theta_j}\n",
    "$$\n",
    "Where:\n",
    "- $\\eta$: Learning rate (controls the step size).\n",
    "- $\\frac{\\partial L}{\\partial \\theta_j}$: Gradient of the loss with respect to $\\theta_j$.\n",
    "\n",
    "#### **Step 6: Repeat**\n",
    "Repeat steps 2–5 until:\n",
    "- The loss function $L(\\theta)$ converges (i.e., changes very little).\n",
    "- The gradient $\\nabla_\\theta L(\\theta)$ becomes close to zero.\n",
    "\n",
    "\n",
    "### **2. Mathematical Example for Linear Regression**\n",
    "\n",
    "#### **Model:**\n",
    "$$\n",
    "h_\\theta(x_i) = \\theta_0 + \\theta_1 x_i\n",
    "$$\n",
    "\n",
    "#### **Loss Function (MSE):**\n",
    "$$\n",
    "L(\\theta_0, \\theta_1) = \\frac{1}{m} \\sum_{i=1}^m \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right)^2\n",
    "$$\n",
    "\n",
    "#### **Gradients:**\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_0} = -\\frac{2}{m} \\sum_{i=1}^m \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_1} = -\\frac{2}{m} \\sum_{i=1}^m \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right) \\cdot x_i\n",
    "$$\n",
    "\n",
    "#### **Parameter Updates:**\n",
    "$$\n",
    "\\theta_0 \\gets \\theta_0 - \\eta \\cdot \\frac{\\partial L}{\\partial \\theta_0}\n",
    "$$\n",
    "$$\n",
    "\\theta_1 \\gets \\theta_1 - \\eta \\cdot \\frac{\\partial L}{\\partial \\theta_1}\n",
    "$$\n",
    "\n",
    "\n",
    "### **3. Properties of Batch Gradient Descent**\n",
    "\n",
    "#### **Advantages:**\n",
    "1. **Convergence Stability**: The gradient is calculated over the entire dataset, leading to stable and smooth convergence.\n",
    "2. **Exact Gradient**: Since the entire dataset is used, the gradient is accurate.\n",
    "3. **Deterministic Updates**: Each update is the same for the same data, ensuring repeatability.\n",
    "\n",
    "#### **Disadvantages:**\n",
    "1. **Computationally Expensive**: For large datasets, computing the gradient for the entire dataset in every iteration is slow.\n",
    "2. **Memory Intensive**: Requires loading the entire dataset into memory, which can be infeasible for very large datasets.\n",
    "\n",
    "\n",
    "### **4. Visual Understanding**\n",
    "- Imagine a ball rolling down a hill. In batch gradient descent, you compute the average slope of the entire hill (dataset) before taking a step. While this ensures precision, it may take longer to reach the bottom of the hill.\n",
    "\n",
    "\n",
    "### **5. Convergence Criterion**\n",
    "Batch Gradient Descent stops when:\n",
    "1. The change in the loss function $L(\\theta)$ between iterations becomes very small:\n",
    "   $$\n",
    "   |L_{\\text{new}} - L_{\\text{old}}| < \\epsilon\n",
    "   $$\n",
    "   Where $\\epsilon$ is a small threshold value.\n",
    "2. A maximum number of iterations is reached.\n",
    "\n",
    "\n",
    "### **6. Comparison with Other Gradient Descent Variants**\n",
    "\n",
    "| Feature                        | Batch Gradient Descent            | Stochastic Gradient Descent (SGD)      | Mini-Batch Gradient Descent          |\n",
    "|--------------------------------|-----------------------------------|---------------------------------------|---------------------------------------|\n",
    "| **Gradient Calculation**       | Entire dataset                   | One data point                        | Small batch of data points           |\n",
    "| **Stability**                  | Very stable                      | Noisy, fluctuates                     | Moderately stable                    |\n",
    "| **Speed**                      | Slow for large datasets          | Faster                                | Balances speed and stability         |\n",
    "| **Memory Requirement**         | High (entire dataset in memory)  | Low (one point in memory)             | Medium                               |\n",
    "\n",
    "\n",
    "### **7. Example Walkthrough**\n",
    "\n",
    "#### Dataset:\n",
    "| $x$   | $y$   |\n",
    "|---------|---------|\n",
    "| 1       | 2       |\n",
    "| 2       | 4       |\n",
    "| 3       | 6       |\n",
    "\n",
    "#### Model:\n",
    "$$\n",
    "h_\\theta(x) = \\theta_0 + \\theta_1 x\n",
    "$$\n",
    "\n",
    "#### Loss Function:\n",
    "$$\n",
    "L(\\theta) = \\frac{1}{3} \\sum_{i=1}^3 \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right)^2\n",
    "$$\n",
    "\n",
    "#### Gradients:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_0} = -\\frac{2}{3} \\sum_{i=1}^3 \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta_1} = -\\frac{2}{3} \\sum_{i=1}^3 \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right) \\cdot x_i\n",
    "$$\n",
    "\n",
    "#### Updates (with $\\eta = 0.01$):\n",
    "1. Initialize $\\theta_0 = 0$, $\\theta_1 = 0$.\n",
    "2. Compute predictions $\\hat{y}_i = \\theta_0 + \\theta_1 x_i$ and update $\\theta_0, \\theta_1$ using the formulas above.\n",
    "3. Repeat until convergence.\n",
    "\n",
    "\n",
    "### **8. Summary**\n",
    "- **Batch Gradient Descent** updates parameters using the average gradient computed over the entire dataset.\n",
    "- It is computationally expensive but provides precise and stable updates.\n",
    "- Best suited for smaller datasets or cases where high accuracy is critical.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stochastic Gradient Descent** :\n",
    "\n",
    "\n",
    "Stochastic Gradient Descent is a variant of the gradient descent optimization algorithm where the gradient is computed and updated using only **one training sample** at a time, instead of the entire dataset. This makes it faster and more memory-efficient for large datasets but introduces some noise in the updates.\n",
    "\n",
    "\n",
    "\n",
    "### **1. Steps in Stochastic Gradient Descent**\n",
    "\n",
    "#### **Step 1: Initialize Parameters**\n",
    "Randomly initialize the parameters $ \\theta $ (e.g., weights for a model).\n",
    "\n",
    "#### **Step 2: Compute Prediction**\n",
    "For a single randomly selected training example $(x_i, y_i)$:\n",
    "$$\n",
    "\\hat{y}_i = h_\\theta(x_i)\n",
    "$$\n",
    "Where $ h_\\theta(x_i) $ is the model's prediction.\n",
    "\n",
    "#### **Step 3: Define the Loss Function**\n",
    "The loss function $L_i(\\theta)$ measures the error for the chosen training sample:\n",
    "- **For Linear Regression (Mean Squared Error):**\n",
    "$$\n",
    "L_i(\\theta) = \\left( y_i - h_\\theta(x_i) \\right)^2\n",
    "$$\n",
    "\n",
    "- **For Logistic Regression (Binary Cross-Entropy):**\n",
    "$$\n",
    "L_i(\\theta) = -\\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 4: Compute the Gradient**\n",
    "Compute the gradient of the loss function with respect to each parameter $ \\theta_j $:\n",
    "$$\n",
    "\\frac{\\partial L_i}{\\partial \\theta_j} = \\left( \\hat{y}_i - y_i \\right) x_{ij}\n",
    "$$\n",
    "Where:\n",
    "- $x_{ij}$: Value of the $j$-th feature for the $i$-th training example.\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 5: Update Parameters**\n",
    "Update the parameters using the computed gradient:\n",
    "$$\n",
    "\\theta_j \\gets \\theta_j - \\eta \\cdot \\frac{\\partial L_i}{\\partial \\theta_j}\n",
    "$$\n",
    "Where:\n",
    "- $\\eta$: Learning rate, controls the size of the step.\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 6: Repeat for Each Training Example**\n",
    "Repeat steps 2–5 for a fixed number of epochs or until convergence:\n",
    "1. Shuffle the dataset at the start of each epoch to reduce bias.\n",
    "2. Iterate through all training examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Mathematical Example for Linear Regression**\n",
    "\n",
    "#### Dataset:\n",
    "| $x_i$ | $y_i$ |\n",
    "|---------|---------|\n",
    "| 1       | 2       |\n",
    "| 2       | 4       |\n",
    "| 3       | 6       |\n",
    "\n",
    "#### Model:\n",
    "$$\n",
    "h_\\theta(x) = \\theta_0 + \\theta_1 x\n",
    "$$\n",
    "\n",
    "#### Loss Function:\n",
    "$$\n",
    "L_i(\\theta_0, \\theta_1) = \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right)^2\n",
    "$$\n",
    "\n",
    "#### Gradients:\n",
    "$$\n",
    "\\frac{\\partial L_i}{\\partial \\theta_0} = -2 \\cdot \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L_i}{\\partial \\theta_1} = -2 \\cdot \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right) \\cdot x_i\n",
    "$$\n",
    "\n",
    "#### Updates:\n",
    "1. Initialize $\\theta_0 = 0$, $\\theta_1 = 0$.\n",
    "2. For each example $(x_i, y_i)$:\n",
    "   $$\n",
    "   \\theta_0 \\gets \\theta_0 - \\eta \\cdot \\frac{\\partial L_i}{\\partial \\theta_0}\n",
    "   $$\n",
    "   $$\n",
    "   \\theta_1 \\gets \\theta_1 - \\eta \\cdot \\frac{\\partial L_i}{\\partial \\theta_1}\n",
    "   $$\n",
    "\n",
    "\n",
    "\n",
    "### **3. Key Features of SGD**\n",
    "\n",
    "#### **Advantages:**\n",
    "1. **Faster Updates**: Each update is computed for a single training example, making the algorithm faster for large datasets.\n",
    "2. **Memory Efficient**: Only one example is loaded into memory at a time, making it ideal for large datasets.\n",
    "3. **Online Learning**: Can be used for streaming data, as it updates the model parameters incrementally.\n",
    "\n",
    "#### **Disadvantages:**\n",
    "1. **Noisy Updates**: Each update uses a single example, leading to high variance and oscillations in the convergence path.\n",
    "2. **May Overshoot**: Because of the noisy updates, SGD may overshoot the minimum or take a longer, winding path to convergence.\n",
    "3. **Requires Careful Tuning**: Learning rate $ \\eta $ must be carefully chosen to avoid divergence.\n",
    "\n",
    "\n",
    "\n",
    "### **4. Comparison to Batch Gradient Descent**\n",
    "\n",
    "| Feature                        | Stochastic Gradient Descent         | Batch Gradient Descent               |\n",
    "|--------------------------------|-------------------------------------|--------------------------------------|\n",
    "| **Gradient Calculation**       | Single training example             | Entire dataset                       |\n",
    "| **Speed per Update**           | Faster                              | Slower                               |\n",
    "| **Convergence Stability**      | Noisy, may oscillate                | Stable                               |\n",
    "| **Memory Requirement**         | Low (single example)                | High (entire dataset)                |\n",
    "| **Use Case**                   | Large datasets, online learning     | Small datasets, stable optimization  |\n",
    "\n",
    "\n",
    "\n",
    "### **5. Variants to Improve SGD**\n",
    "\n",
    "1. **Mini-Batch Gradient Descent**:\n",
    "   - Combines advantages of SGD and Batch Gradient Descent by computing gradients on a small subset (batch) of data.\n",
    "\n",
    "2. **Learning Rate Schedulers**:\n",
    "   - Adjust the learning rate over time to improve convergence (e.g., exponential decay, step decay).\n",
    "\n",
    "3. **Momentum**:\n",
    "   - Incorporates a fraction of the previous update to smooth out oscillations:\n",
    "     $$\n",
    "     v_j = \\gamma v_j + \\eta \\cdot \\frac{\\partial L_i}{\\partial \\theta_j}\n",
    "     $$\n",
    "     $$\n",
    "     \\theta_j \\gets \\theta_j - v_j\n",
    "     $$\n",
    "\n",
    "4. **Adaptive Methods**:\n",
    "   - Techniques like **Adam** or **RMSprop** adapt the learning rate for each parameter, improving convergence speed and stability.\n",
    "\n",
    "\n",
    "\n",
    "### **6. Visual Intuition**\n",
    "- Imagine a ball rolling down a hilly path. With SGD, the ball takes steps based on the local slope at its current position, leading to quick, uneven progress. While it may zig-zag around the optimal solution, it gets there faster than Batch Gradient Descent.\n",
    "\n",
    "\n",
    "\n",
    "### **7. Convergence Criteria**\n",
    "1. **Loss Function Convergence**:\n",
    "   - Stop when the change in loss is less than a small threshold:\n",
    "     $$\n",
    "     |L_{\\text{new}} - L_{\\text{old}}| < \\epsilon\n",
    "     $$\n",
    "2. **Gradient Norm Convergence**:\n",
    "   - Stop when the norm of the gradient is close to zero:\n",
    "     $$\n",
    "     \\|\\nabla_\\theta L_i(\\theta)\\| < \\epsilon\n",
    "     $$\n",
    "\n",
    "\n",
    "\n",
    "### **8. Summary**\n",
    "- **Stochastic Gradient Descent** updates parameters using a single training sample at a time.\n",
    "- It is computationally efficient for large datasets but may converge noisily.\n",
    "- Enhancements like momentum, learning rate schedules, or adaptive optimizers can mitigate its weaknesses.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mini-Batch Gradient Descent (MBGD)**\n",
    "\n",
    "Mini-Batch Gradient Descent is a variant of the Gradient Descent algorithm that splits the dataset into smaller groups called *mini-batches*. Instead of computing gradients for the entire dataset (like Batch Gradient Descent) or for one sample (like Stochastic Gradient Descent), MBGD computes the gradient using a **subset of training samples** at each step.\n",
    "\n",
    "\n",
    "\n",
    "### **1. How Mini-Batch Gradient Descent Works**\n",
    "\n",
    "#### **Step 1: Initialize Parameters**\n",
    "Randomly initialize the parameters $ \\theta $ (e.g., weights for the model).\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 2: Divide Dataset into Mini-Batches**\n",
    "Split the training dataset $ D $ of size $ N $ into $ M $ mini-batches, each of size $ B $:\n",
    "$$\n",
    "B = \\frac{N}{M}\n",
    "$$\n",
    "Where:\n",
    "- $N$: Total number of training examples.\n",
    "- $B$: Batch size (e.g., 32, 64, 128).\n",
    "- $M$: Number of mini-batches.\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 3: Compute Prediction**\n",
    "For each mini-batch $ B_k $ containing a subset of examples $ \\{(x_1, y_1), (x_2, y_2), \\dots, (x_B, y_B)\\} $, compute the model's predictions:\n",
    "$$\n",
    "\\hat{y}_i = h_\\theta(x_i), \\quad i \\in B_k\n",
    "$$\n",
    "Where $ h_\\theta(x_i) $ is the model's prediction for the $i$-th sample in the mini-batch.\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 4: Define the Loss Function**\n",
    "Calculate the average loss over all examples in the mini-batch:\n",
    "$$\n",
    "L_{B_k}(\\theta) = \\frac{1}{B} \\sum_{i \\in B_k} L_i(\\theta)\n",
    "$$\n",
    "Where:\n",
    "- $ L_i(\\theta) $ is the loss for each individual training sample (e.g., Mean Squared Error or Cross-Entropy Loss).\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 5: Compute the Gradient**\n",
    "Compute the gradient of the loss function with respect to parameters $ \\theta_j $:\n",
    "$$\n",
    "\\frac{\\partial L_{B_k}}{\\partial \\theta_j} = \\frac{1}{B} \\sum_{i \\in B_k} \\frac{\\partial L_i}{\\partial \\theta_j}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 6: Update Parameters**\n",
    "Update parameters $ \\theta $ using the computed gradients:\n",
    "$$\n",
    "\\theta_j \\gets \\theta_j - \\eta \\cdot \\frac{\\partial L_{B_k}}{\\partial \\theta_j}\n",
    "$$\n",
    "Where:\n",
    "- $\\eta$: Learning rate.\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 7: Repeat for All Mini-Batches**\n",
    "1. Iterate through all mini-batches in the dataset for one **epoch**.\n",
    "2. Repeat the process for multiple epochs until convergence.\n",
    "\n",
    "\n",
    "### **2. Mathematical Example**\n",
    "\n",
    "#### Dataset:\n",
    "| $x_i$ | $y_i$ |\n",
    "|---------|---------|\n",
    "| 1       | 2       |\n",
    "| 2       | 4       |\n",
    "| 3       | 6       |\n",
    "| 4       | 8       |\n",
    "\n",
    "\n",
    "\n",
    "#### Model:\n",
    "$$\n",
    "h_\\theta(x) = \\theta_0 + \\theta_1 x\n",
    "$$\n",
    "\n",
    "#### Loss Function:\n",
    "$$\n",
    "L_i(\\theta) = \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right)^2\n",
    "$$\n",
    "\n",
    "#### Mini-Batch Size:\n",
    "Let $ B = 2 $. Split the dataset into 2 mini-batches:\n",
    "- $B_1 = \\{(1, 2), (2, 4)\\}$\n",
    "- $B_2 = \\{(3, 6), (4, 8)\\}$\n",
    "\n",
    "#### Gradient Updates:\n",
    "For $B_1$, compute the gradients:\n",
    "$$\n",
    "\\frac{\\partial L_{B_1}}{\\partial \\theta_0} = \\frac{1}{2} \\sum_{i=1}^2 -2 \\cdot \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L_{B_1}}{\\partial \\theta_1} = \\frac{1}{2} \\sum_{i=1}^2 -2 \\cdot \\left( y_i - (\\theta_0 + \\theta_1 x_i) \\right) \\cdot x_i\n",
    "$$\n",
    "\n",
    "Update parameters:\n",
    "$$\n",
    "\\theta_j \\gets \\theta_j - \\eta \\cdot \\frac{\\partial L_{B_1}}{\\partial \\theta_j}\n",
    "$$\n",
    "\n",
    "Repeat for $B_2$.\n",
    "\n",
    "### **3. Comparison with Other Gradient Descent Variants**\n",
    "\n",
    "| Feature                        | Stochastic Gradient Descent         | Mini-Batch Gradient Descent         | Batch Gradient Descent            |\n",
    "|--------------------------------|-------------------------------------|-------------------------------------|-----------------------------------|\n",
    "| **Gradient Calculation**       | Single training example             | Subset of training examples         | Entire dataset                    |\n",
    "| **Speed per Update**           | Fast                                | Moderate                            | Slow                              |\n",
    "| **Convergence Stability**      | Noisy                               | Balanced                            | Stable                            |\n",
    "| **Memory Requirement**         | Low (single example)                | Moderate (mini-batch size)          | High (entire dataset)             |\n",
    "| **Use Case**                   | Streaming data, large datasets      | Most common choice                  | Small datasets, high precision    |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### **4. Advantages of Mini-Batch Gradient Descent**\n",
    "\n",
    "1. **Efficient Computation**:\n",
    "   - Uses vectorized operations on mini-batches, leveraging hardware accelerations like GPUs.\n",
    "   \n",
    "2. **Stable Updates**:\n",
    "   - Reduces the noisy oscillations of SGD while being faster than Batch Gradient Descent.\n",
    "\n",
    "3. **Memory-Friendly**:\n",
    "   - Suitable for large datasets that do not fit into memory, as it processes smaller batches.\n",
    "\n",
    "4. **Faster Convergence**:\n",
    "   - Provides a good trade-off between convergence stability (Batch) and computational speed (SGD).\n",
    "\n",
    "\n",
    "\n",
    "### **5. Challenges in Mini-Batch Gradient Descent**\n",
    "\n",
    "1. **Choosing Batch Size**:\n",
    "   - Small batches ($ B < 32 $) may lead to noisy updates, similar to SGD.\n",
    "   - Large batches ($ B > 512 $) may approach Batch Gradient Descent and slow down.\n",
    "\n",
    "2. **Hyperparameter Tuning**:\n",
    "   - Requires careful tuning of the learning rate $\\eta$ and batch size $B$ for optimal performance.\n",
    "\n",
    "3. **Convergence**:\n",
    "   - May still get stuck in local minima or saddle points, especially for non-convex problems.\n",
    "\n",
    "\n",
    "\n",
    "### **6. Practical Considerations**\n",
    "\n",
    "1. **Batch Size**:\n",
    "   - Common choices: $32, 64, 128, 256$.\n",
    "   - Depends on hardware (GPU/CPU) and dataset size.\n",
    "\n",
    "2. **Learning Rate**:\n",
    "   - Combine with learning rate schedulers to adjust $\\eta$ during training.\n",
    "\n",
    "3. **Shuffling**:\n",
    "   - Shuffle the dataset at the start of each epoch to ensure diverse mini-batches and reduce bias.\n",
    "\n",
    "4. **Regularization**:\n",
    "   - Use techniques like $ L2 $-regularization or dropout to avoid overfitting.\n",
    "\n",
    "\n",
    "\n",
    "### **7. Applications**\n",
    "\n",
    "1. **Deep Learning**:\n",
    "   - Mini-Batch Gradient Descent is the standard choice for training deep neural networks due to its ability to balance memory usage and computation speed.\n",
    "\n",
    "2. **Large Datasets**:\n",
    "   - Suitable for datasets too large to fit into memory.\n",
    "\n",
    "\n",
    "\n",
    "### **8. Summary**\n",
    "\n",
    "Mini-Batch Gradient Descent computes updates using a subset of training data, combining the benefits of Stochastic and Batch Gradient Descent:\n",
    "- **Efficiency**: Faster than Batch Gradient Descent and less noisy than SGD.\n",
    "- **Flexibility**: Works well for large datasets using hardware acceleration.\n",
    "- **Challenges**: Requires careful tuning of batch size and learning rate for optimal results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
