{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrices:\n",
    "\n",
    "Regression metrics are statistical measures used to evaluate the performance of a regression model. They help quantify how well a model predicts continuous outcomes by comparing the predicted values with the actual target values. Each metric captures different aspects of model performance.\n",
    "\n",
    "### 1. **Mean Absolute Error (MAE)**  \n",
    "**Formula**:  \n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$  \n",
    "**Where**:  \n",
    "- $ y_i $: Actual value for the $ i $-th observation  \n",
    "- $ \\hat{y}_i $: Predicted value for the $ i $-th observation  \n",
    "- $ n $: Total number of observations  \n",
    "\n",
    "**Explanation**:  \n",
    "- MAE calculates the average absolute difference between predicted and actual values.  \n",
    "- It measures the average magnitude of errors in predictions, irrespective of direction (positive or negative).  \n",
    "- **Units**: The same as the target variable.  \n",
    "\n",
    "**Characteristics**:  \n",
    "- MAE is **robust to outliers** compared to other metrics like MSE because it doesn't square the errors.  \n",
    "- It provides an intuitive sense of average error magnitude.\n",
    "\n",
    "**Example**:  \n",
    "If your target variable represents house prices in thousands, and MAE is 5, it means your model's predictions are, on average, off by $5,000.\n",
    "\n",
    "\n",
    "\n",
    "### 2. **Mean Squared Error (MSE)**  \n",
    "**Formula**:  \n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$  \n",
    "**Explanation**:  \n",
    "- MSE computes the average squared difference between predicted and actual values.  \n",
    "- Squaring the errors penalizes larger errors more heavily than smaller ones.  \n",
    "\n",
    "**Units**:  \n",
    "- The square of the target variable’s unit (e.g., if the target is in thousands of dollars, MSE is in $ \\text{thousands}^2 $).\n",
    "\n",
    "**Characteristics**:  \n",
    "- **Sensitive to outliers**: Larger errors contribute disproportionately due to squaring.  \n",
    "- Useful for situations where larger errors are more significant than smaller ones.  \n",
    "\n",
    "**Example**:  \n",
    "If house prices have an MSE of 25 (in thousands squared), the large value indicates significant variance in errors.\n",
    "\n",
    "\n",
    "\n",
    "### 3. **Root Mean Squared Error (RMSE)**  \n",
    "**Formula**:  \n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "$$  \n",
    "**Explanation**:  \n",
    "- RMSE is simply the square root of MSE.  \n",
    "- It gives the error in the same unit as the target variable, making it more interpretable than MSE.  \n",
    "\n",
    "**Units**:  \n",
    "- Same as the target variable.  \n",
    "\n",
    "**Characteristics**:  \n",
    "- RMSE is **sensitive to outliers**, like MSE, due to squaring before averaging.  \n",
    "- Offers a balance between penalizing larger errors and interpretability.  \n",
    "\n",
    "**Example**:  \n",
    "If house prices have an RMSE of 5 (in thousands), it implies the typical prediction error is $5,000.\n",
    "\n",
    "### Comparison Between MAE, MSE, and RMSE:\n",
    "| **Metric** | **Key Feature** | **Sensitivity to Outliers** | **Units** |\n",
    "|------------|-----------------|----------------------------|-----------|\n",
    "| MAE        | Average absolute error | Less sensitive           | Same as target |\n",
    "| MSE        | Average squared error  | Highly sensitive         | Squared of target |\n",
    "| RMSE       | Square root of MSE     | Highly sensitive         | Same as target |\n",
    "\n",
    "\n",
    "\n",
    "### When to Use Which Metric:\n",
    "1. **MAE**: Use when you want to minimize the average magnitude of errors, regardless of their direction or size. It’s best when the impact of outliers isn’t critical.  \n",
    "2. **MSE**: Use when you want to emphasize larger errors in your model evaluation. Suitable for datasets where big errors are significantly worse.  \n",
    "3. **RMSE**: A compromise between interpretability (units) and penalizing larger errors. Widely used in practice for general regression problems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Score and Adjusted R2 Score:\n",
    "\n",
    "The $ R^2 $ score and Adjusted $ R^2 $ score are metrics used to evaluate the performance of a regression model. They measure how well the independent variables (features) explain the variability of the dependent variable (target). These metrics are particularly useful for understanding the fit of a model in relation to the data.\n",
    "\n",
    "\n",
    "\n",
    "### **1. $ R^2 $ Score (Coefficient of Determination)**  \n",
    "\n",
    "#### **Formula**:  \n",
    "$$\n",
    "R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\n",
    "$$  \n",
    "\n",
    "Where:  \n",
    "- $ SS_{res} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $: Residual sum of squares (unexplained variance).  \n",
    "- $ SS_{tot} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2 $: Total sum of squares (total variance in the target).  \n",
    "- $ y_i $: Actual target value for the $ i $-th observation.  \n",
    "- $ \\hat{y}_i $: Predicted target value for the $ i $-th observation.  \n",
    "- $ \\bar{y} $: Mean of the actual target values.  \n",
    "- $ n $: Number of observations.\n",
    "\n",
    "\n",
    "\n",
    "#### **Interpretation**:  \n",
    "- $ R^2 $ represents the proportion of the variance in the target variable ($ y $) that is explained by the features ($ X $).  \n",
    "- Its value ranges from $ 0 $ to $ 1 $:  \n",
    "  - $ R^2 = 0 $: The model explains none of the variability; it is as good as guessing the mean ($ \\bar{y} $).  \n",
    "  - $ R^2 = 1 $: The model explains all the variability perfectly.  \n",
    "  - $ R^2 < 0 $: Indicates that the model performs worse than a simple mean-based prediction.\n",
    "\n",
    "\n",
    "\n",
    "#### **Advantages of $ R^2 $**:  \n",
    "- Provides a quick way to assess how well the regression model fits the data.  \n",
    "- Easy to interpret: A higher $ R^2 $ means better model performance.\n",
    "\n",
    "#### **Disadvantages**:  \n",
    "- $ R^2 $ always increases with the addition of more features, even if those features don't improve the model's predictive power.  \n",
    "- Doesn't account for the number of features used in the model, leading to potential overfitting.\n",
    "\n",
    "\n",
    "\n",
    "### **2. Adjusted $ R^2 $ Score**  \n",
    "\n",
    "To address the issue of $ R^2 $'s sensitivity to the number of features, the Adjusted $ R^2 $ score was introduced.\n",
    "\n",
    "#### **Formula**:  \n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - \\left( \\frac{(1 - R^2)(n - 1)}{n - p - 1} \\right)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $ n $: Total number of observations (data points).  \n",
    "- $ p $: Number of independent variables (features) in the model.  \n",
    "- $ R^2 $: Standard $ R^2 $ score.\n",
    "\n",
    "\n",
    "\n",
    "#### **Interpretation**:  \n",
    "- Adjusted $ R^2 $ adjusts the $ R^2 $ score based on the number of features.  \n",
    "- It penalizes adding features that do not improve the model and rewards features that contribute significantly to the model's performance.  \n",
    "- Unlike $ R^2 $, Adjusted $ R^2 $ can decrease if unnecessary features are added to the model.\n",
    "\n",
    "#### **Key Properties**:  \n",
    "- When $ p = 0 $ (no predictors), Adjusted $ R^2 = R^2 = 0 $.  \n",
    "- If a new feature improves the model (reduces residual error), Adjusted $ R^2 $ increases.  \n",
    "- If a new feature doesn't improve the model, Adjusted $ R^2 $ decreases.\n",
    "\n",
    "### **Comparison Between $ R^2 $ and Adjusted $ R^2 $:**\n",
    "\n",
    "| Metric          | **Sensitivity to Feature Count** | **Interpretation**                | **Use Case**                          |\n",
    "|------------------|----------------------------------|------------------------------------|----------------------------------------|\n",
    "| $ R^2 $        | Increases with more features    | Total variance explained           | Quick assessment of model fit.         |\n",
    "| Adjusted $ R^2 $ | Penalizes unnecessary features | Variance explained with penalty    | For comparing models with different features. |\n",
    "\n",
    "\n",
    "### **Example for $ R^2 $ and Adjusted $ R^2 $:**\n",
    "\n",
    "1. **Scenario**: Predicting house prices with 10 features:  \n",
    "   - $ R^2 = 0.85 $ (85% of the variance in prices is explained by the model).  \n",
    "   - Adding a feature that has no correlation with house prices increases $ R^2 $ slightly to 0.86.  \n",
    "\n",
    "2. **Adjusted $ R^2 $**:  \n",
    "   - If the new feature doesn’t improve predictions significantly, Adjusted $ R^2 $ might decrease (e.g., from 0.83 to 0.82), indicating the model is overfitting.\n",
    "\n",
    "\n",
    "\n",
    "### **When to Use Which?**\n",
    "\n",
    "1. Use **$ R^2 $**:  \n",
    "   - For a single model with a fixed set of features.  \n",
    "   - When the focus is solely on variance explanation.  \n",
    "\n",
    "2. Use **Adjusted $ R^2 $**:  \n",
    "   - To compare models with different numbers of features.  \n",
    "   - When you want to ensure that only meaningful features are included.  \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
