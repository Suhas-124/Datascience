{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270b3af8",
   "metadata": {},
   "source": [
    "### 🔍 What is MLOps?\n",
    "\n",
    "**MLOps** stands for **Machine Learning Operations**.  \n",
    "It’s a **set of practices** that aims to **deploy and maintain machine learning models in production reliably and efficiently**.\n",
    "\n",
    "It’s like **DevOps** but for **Machine Learning**.\n",
    "\n",
    "\n",
    "\n",
    "### 🧩 Why Do We Need MLOps?\n",
    "\n",
    "Building an ML model is just **10-20%** of the entire machine learning project. The real challenge is:\n",
    "- Putting the model into **production**\n",
    "- **Monitoring** it\n",
    "- **Maintaining** it as data changes\n",
    "- **Updating** it when needed\n",
    "\n",
    "Without MLOps, your ML model may just sit in a notebook or Jupyter file and never deliver real value to users or businesses.\n",
    "\n",
    "\n",
    "\n",
    "### 🛠️ MLOps Covers the Entire ML Lifecycle\n",
    "\n",
    "Here's a breakdown:\n",
    "\n",
    "#### 1. **Data Engineering**  \n",
    "- Collecting data  \n",
    "- Cleaning and preprocessing  \n",
    "- Versioning datasets (using tools like DVC or LakeFS)\n",
    "\n",
    "#### 2. **Model Development**  \n",
    "- Training models  \n",
    "- Hyperparameter tuning  \n",
    "- Experiment tracking (using MLflow, Weights & Biases)\n",
    "\n",
    "#### 3. **Model Validation**  \n",
    "- Evaluating performance  \n",
    "- Checking for fairness, bias, and drift  \n",
    "- Getting approval for deployment\n",
    "\n",
    "#### 4. **Model Deployment**  \n",
    "- Moving the model from dev to production (can be REST API, batch job, etc.)  \n",
    "- Using tools like Docker, Kubernetes, FastAPI, or Flask\n",
    "\n",
    "#### 5. **Monitoring & Maintenance**  \n",
    "- Track model accuracy, latency, input data drift  \n",
    "- Alert if model performance drops  \n",
    "- Automate re-training if needed\n",
    "\n",
    "#### 6. **Model Retraining**  \n",
    "- As new data comes in, retrain the model  \n",
    "- Use CI/CD pipelines to automate this\n",
    "\n",
    "\n",
    "\n",
    "### 🔄 MLOps = Collaboration\n",
    "\n",
    "MLOps encourages collaboration between:\n",
    "- **Data Scientists** (build the model)\n",
    "- **ML Engineers** (optimize and deploy it)\n",
    "- **DevOps Engineers** (manage infrastructure)\n",
    "\n",
    "### 🧰 Common MLOps Tools\n",
    "\n",
    "| Stage | Tools |\n",
    "|------|-------|\n",
    "| Data versioning | DVC, Delta Lake |\n",
    "| Experiment tracking | MLflow, Weights & Biases |\n",
    "| Model deployment | FastAPI, Flask, Docker, Kubernetes |\n",
    "| Monitoring | Prometheus, Grafana, Evidently AI |\n",
    "| Pipelines | Airflow, Kubeflow, MLflow Pipelines |\n",
    "\n",
    "\n",
    "\n",
    "### 💡 Real-Life Analogy\n",
    "\n",
    "Think of ML as building a car 🏎️.  \n",
    "- Data scientists design and prototype the engine.  \n",
    "- MLOps makes sure the car runs reliably, can be mass-produced, monitored on the road, and fixed when needed.\n",
    "\n",
    "\n",
    "### ✅ Final Thought\n",
    "\n",
    "MLOps ensures **your ML model doesn’t stop at a great accuracy score in Jupyter Notebook**, but actually runs smoothly and reliably **in the real world**, helping users or driving business decisions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd77496",
   "metadata": {},
   "source": [
    "### 🧱 Key Components of MLOps\n",
    "\n",
    "\n",
    "\n",
    "### 1. **Data Management**\n",
    "> 🔁 Think of this as fuel for your ML engine.\n",
    "\n",
    "- **Data Collection** – Gathering raw data from different sources.\n",
    "- **Data Validation** – Checking for missing values, schema mismatches, or anomalies.\n",
    "- **Data Versioning** – Keeping track of different versions of data using tools like **DVC**.\n",
    "- **Data Storage** – Using storage systems (S3, GCS, databases, etc.) to securely store and retrieve data.\n",
    "\n",
    "\n",
    "\n",
    "### 2. **Model Development**\n",
    "> 🧠 The brain of your system is trained here.\n",
    "\n",
    "- **Model Training** – Applying ML algorithms to learn from data.\n",
    "- **Experiment Tracking** – Recording model parameters, metrics, and results (with tools like **MLflow**, **Weights & Biases**).\n",
    "- **Model Validation** – Evaluating model performance using cross-validation, confusion matrices, etc.\n",
    "- **Model Registry** – A centralized place to store and manage different versions of trained models.\n",
    "\n",
    "\n",
    "\n",
    "### 3. **Model Deployment**\n",
    "> 🚀 Getting your model from Jupyter Notebook to the real world.\n",
    "\n",
    "- **Serving the Model** – Exposing the model via REST APIs using **FastAPI**, **Flask**, or **TensorFlow Serving**.\n",
    "- **Containerization** – Using **Docker** to package everything (code + dependencies).\n",
    "- **Orchestration** – Using **Kubernetes** to scale and manage containers.\n",
    "- **CI/CD Pipelines** – Automating build, test, and deployment with tools like **GitHub Actions**, **Jenkins**, or **GitLab CI/CD**.\n",
    "\n",
    "\n",
    "\n",
    "### 4. **Model Monitoring**\n",
    "> 👀 Keep an eye on your model like a hawk.\n",
    "\n",
    "- **Performance Monitoring** – Check accuracy, precision, recall over time.\n",
    "- **Drift Detection** – Track **data drift** and **concept drift** using tools like **Evidently AI**.\n",
    "- **Logging and Alerts** – Set up real-time alerts when something goes wrong using **Prometheus**, **Grafana**, or **Sentry**.\n",
    "\n",
    "\n",
    "\n",
    "### 5. **Model Retraining & Feedback Loop**\n",
    "> 🔄 Adapt and evolve with new data.\n",
    "\n",
    "- **Scheduled Retraining** – Periodically retrain with fresh data (daily, weekly, etc.).\n",
    "- **Feedback Loop** – Collect predictions and actual outcomes to refine models.\n",
    "- **AutoML Pipelines** – Automate retraining pipelines with tools like **Kubeflow Pipelines** or **Airflow**.\n",
    "\n",
    "\n",
    "\n",
    "### 6. **Infrastructure & Environment Management**\n",
    "> 🏗️ Build once, run anywhere — smoothly.\n",
    "\n",
    "- **Cloud & On-Prem Integration** – Support for AWS, Azure, GCP, or your own servers.\n",
    "- **Resource Management** – Use GPUs/CPUs wisely with Kubernetes.\n",
    "- **Environment Isolation** – Use **virtual environments**, **Docker**, or **Conda** to avoid conflicts.\n",
    "\n",
    "\n",
    "\n",
    "### 7. **Collaboration & Governance**\n",
    "> 🤝 Teams working together, with clear rules.\n",
    "\n",
    "- **Role-based Access** – Who can deploy, retrain, or monitor?\n",
    "- **Audit Trails** – Track who changed what and when.\n",
    "- **Documentation** – Maintain proper documentation and model cards for transparency.\n",
    "\n",
    "### 🧰 Summary of Tools by Component\n",
    "\n",
    "| Component | Tools |\n",
    "|----------|-------|\n",
    "| Data Versioning | DVC, LakeFS |\n",
    "| Experiment Tracking | MLflow, W&B |\n",
    "| Deployment | Docker, FastAPI, Kubernetes |\n",
    "| Monitoring | Prometheus, Grafana, Evidently |\n",
    "| Pipelines | Kubeflow, Airflow, TFX |\n",
    "| CI/CD | GitHub Actions, Jenkins |\n",
    "| Model Registry | MLflow Model Registry, Sagemaker Model Registry |\n",
    "\n",
    "\n",
    "### 🎯 Final Thought\n",
    "\n",
    "MLOps ensures your ML models are **reliable**, **scalable**, and **maintainable** — transforming one-time experiments into production-grade systems that deliver consistent value.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b333b",
   "metadata": {},
   "source": [
    "# 🌟 **End-to-End MLOps Project Summary**  \n",
    "_Based on a YouTube Sentiment Analysis Chrome Extension Project_\n",
    "\n",
    "\n",
    "\n",
    "## 🧠 **Why This Project?**\n",
    "\n",
    "- 📈 **MLOps skills are in demand** — companies expect ML engineers to know them.\n",
    "- ✅ Goal: Build a full ML project using **MLOps tools & automation**.\n",
    "\n",
    "\n",
    "\n",
    "## 🔍 **Project Idea: YouTube Comment Sentiment Analyzer**\n",
    "\n",
    "- 🧩 Chrome plugin shows sentiment of YouTube comments.\n",
    "- 🔥 Shows:\n",
    "  - Sentiment per comment (Positive/Neutral/Negative)\n",
    "  - 📊 Pie chart with sentiment percentage\n",
    "  - 📈 Sentiment trend over months\n",
    "  - ☁️ Word cloud of frequent words\n",
    "  - 🏅 Predictions for top 25 comments\n",
    "\n",
    "\n",
    "\n",
    "## 🧰 **Components**\n",
    "\n",
    "| Component     | Tech Used                   |\n",
    "|---------------|-----------------------------|\n",
    "| 🖼 Front-end   | HTML + CSS + JavaScript     |\n",
    "| ⚙️ Back-end    | Flask API                   |\n",
    "| 🤖 ML Model    | Trained using Reddit data   |\n",
    "\n",
    "\n",
    "\n",
    "## 🧪 **Model Building (Core ML)**\n",
    "\n",
    "- 📦 **Dataset**: Kaggle Reddit comments with sentiment labels\n",
    "- ✅ **Problem Type**: Multi-class Classification (Positive, Neutral, Negative)\n",
    "- 🧹 **Preprocessing & EDA** done to clean and explore data\n",
    "\n",
    "### 💡 Key Questions Asked:\n",
    "\n",
    "1. Which text feature method? `TF-IDF`, `Bag of Words`, `Word2Vec`?\n",
    "2. How to handle imbalance? `Oversampling`, `SMOTE`, etc.?\n",
    "3. Which algorithm? `Random Forest`, `XGBoost`, `LightGBM`?\n",
    "\n",
    "\n",
    "\n",
    "## 🔁 **Experiment Tracking with MLflow**\n",
    "\n",
    "- 📋 Tried different combinations\n",
    "- 🏆 Best results:\n",
    "  - ✅ `TF-IDF` as feature technique\n",
    "  - ✅ `LightGBM` as algorithm\n",
    "  - ✅ Handled imbalance using **class weights**\n",
    "- 📊 MLflow used to **track and compare experiments**\n",
    "\n",
    "\n",
    "\n",
    "## 🔄 **Automation with DVC (Data Version Control)**\n",
    "\n",
    "- 🔗 Built a DVC pipeline with stages:\n",
    "  - `Data Ingestion`\n",
    "  - `Data Cleaning`\n",
    "  - `Feature Engineering`\n",
    "  - `Model Training`\n",
    "- 🔧 Parameters in `params.yaml`\n",
    "- 📦 DVC detects parameter change ➝ triggers retraining\n",
    "\n",
    "\n",
    "\n",
    "## 📦 **Model Registry with MLflow**\n",
    "\n",
    "- 🗂️ Tracks different **model versions**\n",
    "- 🧪 Tested models before production\n",
    "- 🟢 Promoted good models from `staging` ➝ `production`\n",
    "\n",
    "\n",
    "\n",
    "## 🧪 **Model Testing**\n",
    "\n",
    "- ✅ **Load test**: Can model load & predict?\n",
    "- 🧠 **Performance test**: Is it better than the old one?\n",
    "\n",
    "\n",
    "\n",
    "## 🚀 **Deployment**\n",
    "\n",
    "### 🧊 **Flask API + Docker**\n",
    "\n",
    "- Docker container built with the Flask API\n",
    "\n",
    "### ☁️ **AWS Deployment**\n",
    "\n",
    "- 🚢 Docker image pushed to **AWS ECR**\n",
    "- 🌍 Deployed on **EC2 with Auto Scaling + Load Balancer**\n",
    "- 🔁 Used **AWS CodeDeploy** for **rolling updates** (zero downtime)\n",
    "\n",
    "\n",
    "\n",
    "## 🔄 **CI/CD with GitHub Actions**\n",
    "\n",
    "- ✨ Fully automated flow:\n",
    "  - Install dependencies\n",
    "  - Train model with DVC\n",
    "  - Test and promote model\n",
    "  - Build Docker image\n",
    "  - Push to AWS ECR\n",
    "  - Deploy with AWS CodeDeploy\n",
    "\n",
    "🔁 **One change in params.yaml** ➝ 💥 Entire pipeline runs automatically\n",
    "\n",
    "\n",
    "\n",
    "## 📈 **What's Next?**\n",
    "\n",
    "- 📊 **Monitoring**: Use Prometheus & Grafana\n",
    "- 🔄 **Auto-Retraining** when model performance drops\n",
    "\n",
    "\n",
    "\n",
    "## 🛠 **Tool Alternatives**\n",
    "\n",
    "| Task                    | Alternative Tools              |\n",
    "|-------------------------|--------------------------------|\n",
    "| Experiment Tracking     | Weights & Biases               |\n",
    "| Workflow Orchestration | Apache Airflow, Kubeflow       |\n",
    "| Cloud Platform          | GCP, Azure                     |\n",
    "| All-in-one ML platform  | AWS SageMaker                  |\n",
    "\n",
    "\n",
    "\n",
    "## 🎯 **Key Takeaways**\n",
    "\n",
    "- 📌 MLOps = Experimentation + Versioning + Automation + Deployment\n",
    "- 💡 Tools can vary, but **concepts are key**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e11735b",
   "metadata": {},
   "source": [
    "# 🚀 **Data Management in MLOps (ETL Pipeline)**  \n",
    "\n",
    "\n",
    "## 🧩 **Video Structure**\n",
    "\n",
    "1. 🔁 **Part 1** – Quick revision of MLOps fundamentals  \n",
    "2. 💾 **Part 2** – Main topic: **Data Management** (ETL)\n",
    "\n",
    "\n",
    "\n",
    "## 🧠 **Part 1: MLOps Recap**\n",
    "\n",
    "### 📌 **Why MLOps?**\n",
    "- ML systems are more complex than regular software 💻\n",
    "- Involves:  \n",
    "  ✅ Code  \n",
    "  ✅ **Data**  \n",
    "  ✅ **ML models**\n",
    "\n",
    "### 📌 **What is MLOps?**\n",
    "- MLOps = *Practices + Tools* for taking ML to production\n",
    "- 🎯 Analogy: Good food (model) ≠ Successful restaurant (production system)\n",
    "- 🔄 MLOps = Intersection of:\n",
    "  - 🧠 Machine Learning  \n",
    "  - ⚙️ Data Engineering  \n",
    "  - 🔧 DevOps\n",
    "\n",
    "\n",
    "\n",
    "## 💾 **Part 2: Data Management in MLOps**\n",
    "\n",
    "> 💡 **Data is the backbone of ML!** Without proper data handling, ML projects fail.\n",
    "\n",
    "### 🧭 **12 Sub-Aspects of Data Management**  \n",
    "Not every company uses all 12 — depends on the **use case**  \n",
    "Examples:\n",
    "- 🚗 **Data Annotation** → critical for self-driving cars  \n",
    "- 📜 **Data Governance** → needed for legal safety (e.g., ChatGPT)\n",
    "\n",
    "\n",
    "\n",
    "# 🔁 **ETL Pipeline: Extract - Transform - Load**\n",
    "\n",
    "> The heart of Data Management ❤️\n",
    "\n",
    "\n",
    "\n",
    "## 1️⃣ **Data Ingestion** – 📥 _Extract_\n",
    "\n",
    "- Bringing data from multiple sources into one place 🧲\n",
    "- 🏢 Example: **Samsung** collecting sales data:\n",
    "  - 🌐 Website → Database\n",
    "  - 🛒 Amazon → Real-time stream\n",
    "  - 🏬 Offline Stores → POS APIs\n",
    "\n",
    "### 🛠 Tools Used:\n",
    "- **SQL** – for databases\n",
    "- **Apache Kafka** / **AWS Kinesis** – for real-time ingestion\n",
    "- **Python** + `requests` – to access APIs\n",
    "\n",
    "\n",
    "\n",
    "## 2️⃣ **Data Transformation** – 🛠 _Transform_\n",
    "\n",
    "- Cleaning, merging, and converting data into usable form\n",
    "\n",
    "### 🧼 Steps:\n",
    "- 🔗 **Join** normalized DB tables using SQL\n",
    "- ➕ **Concatenate** data from different sources\n",
    "- 📅 **Sort** by date\n",
    "- 💱 **Normalize** currency (e.g., INR to USD)\n",
    "- 📊 **Aggregate** (e.g., total revenue per product per day)\n",
    "\n",
    "### 🛠 Tools Used:\n",
    "- **Pandas** – for small/medium datasets\n",
    "- **Spark / PySpark** – for large-scale data\n",
    "\n",
    "\n",
    "\n",
    "## 3️⃣ **Data Storage** – 💽 _Load_\n",
    "\n",
    "- Store the clean data for analysis or future ML use\n",
    "\n",
    "### 🗃️ Options:\n",
    "| Type              | Examples                                   |\n",
    "|-------------------|--------------------------------------------|\n",
    "| 🧊 **Data Warehouse** | Snowflake, AWS Redshift, Google BigQuery |\n",
    "| 🌊 **Data Lake**      | AWS S3                                   |\n",
    "| 🗄 **Relational DB**   | MySQL, Oracle, SQL Server               |\n",
    "| 📦 **NoSQL**          | MongoDB                                  |\n",
    "| 📁 **File Storage**   | CSVs, AWS S3                              |\n",
    "\n",
    "\n",
    "\n",
    "# ⚒️ **ETL Pipeline Tools Overview**\n",
    "\n",
    "| Function            | Tools                                      |\n",
    "|---------------------|--------------------------------------------|\n",
    "| 📥 Data Ingestion    | Python, SQL, Apache Kafka, AWS Kinesis     |\n",
    "| 🔄 Data Transformation | Pandas, PySpark, Apache Spark             |\n",
    "| 💾 Data Storage      | MySQL, Oracle, MongoDB, S3, Redshift, etc. |\n",
    "| 🔗 All-in-One ETL    | AWS Glue, Talend, Informatica, Apache NiFi |\n",
    "\n",
    "\n",
    "\n",
    "## 🎯 **Key Takeaways**\n",
    "\n",
    "- 🔌 ETL is essential in any ML pipeline\n",
    "- 🧑‍💻 **Data Engineers** manage and fix ETL pipelines\n",
    "- ⚙️ MLOps = tools + automation, but **concepts matter most**\n",
    "- 🧰 Familiarity with tools removes fear and boosts confidence 💪\n",
    "\n",
    "\n",
    "\n",
    "## 📚 **Homework (As per video)**\n",
    "\n",
    "🔍 Research the listed tools to:\n",
    "- Understand their use\n",
    "- Reduce tool anxiety\n",
    "- Prepare for real-world MLOps tasks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd5b56",
   "metadata": {},
   "source": [
    "# 🚀 MLOPS Overview:\n",
    "\n",
    "### 🛠️ **Tool Coverage**\n",
    "| Category              | Tools Covered                            |\n",
    "|-----------------------|-------------------------------------------|\n",
    "| 🧑‍💻 Coding & Versioning | Git, GitHub, Modular Coding, Logging      |\n",
    "| 🧪 Experiment Tracking | DVC, MLflow                              |\n",
    "| 📦 Containerization   | Docker, Docker Hub                        |\n",
    "| 🔁 CI/CD              | GitHub Actions, CircleCI, Travis CI       |\n",
    "| ☁️ Cloud              | AWS (IAM, EC2, S3)                        |\n",
    "| 📊 Monitoring         | Kubernetes, Prometheus, Grafana           |\n",
    "\n",
    "### 🔁 **End-to-End Learning**\n",
    "- Hosting on GitHub 📁\n",
    "- Writing powerful README 📃\n",
    "- How to put projects on your **CV** 📄\n",
    "- How to explain your work to **recruiters** 💬\n",
    "\n",
    "\n",
    "\n",
    "## ⚠️ Common Problems in Traditional ML Projects (Before MLOps)\n",
    "\n",
    "| Problem                | Why it’s an Issue                              | MLOps Solution                          |\n",
    "|------------------------|------------------------------------------------|------------------------------------------|\n",
    "| 📓 Jupyter Coding      | Not production-ready                           | OOP, Modular Coding                      |\n",
    "| 📂 Data Management     | No standard method to update real-world data   | Automated pipelines                      |\n",
    "| 🧾 Versioning          | No version control for data/models             | DVC, MLflow                              |\n",
    "| 🔬 Experimentation     | Difficult to track and automate                | Integrated ML workflow tools             |\n",
    "| ⚙️ CI/CD               | Manual deployment processes                    | GitHub Actions, CircleCI, Travis CI      |\n",
    "| 📈 Monitoring          | No performance monitoring post-deployment      | Prometheus, Grafana                      |\n",
    "| 🤝 Team Friction       | Dependencies on other teams                    | MLOps broadens ML engineer skillset      |\n",
    "\n",
    "\n",
    "\n",
    "## 🧰 Tools & Scope of the Playlist\n",
    "\n",
    "- **✅ OOP & Modular Coding** (from scratch)\n",
    "- **✅ Git + GitHub** (in-depth)\n",
    "- **✅ DVC + MLflow** (for versioning & experiments)\n",
    "- **✅ CI/CD** with GitHub Actions, CircleCI, Travis CI\n",
    "- **✅ Docker** for containerization\n",
    "- **✅ Kubernetes**, Prometheus, Grafana for monitoring/scalability\n",
    "- **✅ AWS (IAM, EC2, S3)** for cloud hands-on\n",
    "- 🔒 Platforms like SageMaker, Vertex AI, Azure ML are **optional** (can be covered on request)\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2395e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
