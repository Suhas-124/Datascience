{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270b3af8",
   "metadata": {},
   "source": [
    "### ğŸ” What is MLOps?\n",
    "\n",
    "**MLOps** stands for **Machine Learning Operations**.  \n",
    "Itâ€™s a **set of practices** that aims to **deploy and maintain machine learning models in production reliably and efficiently**.\n",
    "\n",
    "Itâ€™s like **DevOps** but for **Machine Learning**.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§© Why Do We Need MLOps?\n",
    "\n",
    "Building an ML model is just **10-20%** of the entire machine learning project. The real challenge is:\n",
    "- Putting the model into **production**\n",
    "- **Monitoring** it\n",
    "- **Maintaining** it as data changes\n",
    "- **Updating** it when needed\n",
    "\n",
    "Without MLOps, your ML model may just sit in a notebook or Jupyter file and never deliver real value to users or businesses.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ› ï¸ MLOps Covers the Entire ML Lifecycle\n",
    "\n",
    "Here's a breakdown:\n",
    "\n",
    "#### 1. **Data Engineering**  \n",
    "- Collecting data  \n",
    "- Cleaning and preprocessing  \n",
    "- Versioning datasets (using tools like DVC or LakeFS)\n",
    "\n",
    "#### 2. **Model Development**  \n",
    "- Training models  \n",
    "- Hyperparameter tuning  \n",
    "- Experiment tracking (using MLflow, Weights & Biases)\n",
    "\n",
    "#### 3. **Model Validation**  \n",
    "- Evaluating performance  \n",
    "- Checking for fairness, bias, and drift  \n",
    "- Getting approval for deployment\n",
    "\n",
    "#### 4. **Model Deployment**  \n",
    "- Moving the model from dev to production (can be REST API, batch job, etc.)  \n",
    "- Using tools like Docker, Kubernetes, FastAPI, or Flask\n",
    "\n",
    "#### 5. **Monitoring & Maintenance**  \n",
    "- Track model accuracy, latency, input data drift  \n",
    "- Alert if model performance drops  \n",
    "- Automate re-training if needed\n",
    "\n",
    "#### 6. **Model Retraining**  \n",
    "- As new data comes in, retrain the model  \n",
    "- Use CI/CD pipelines to automate this\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ”„ MLOps = Collaboration\n",
    "\n",
    "MLOps encourages collaboration between:\n",
    "- **Data Scientists** (build the model)\n",
    "- **ML Engineers** (optimize and deploy it)\n",
    "- **DevOps Engineers** (manage infrastructure)\n",
    "\n",
    "### ğŸ§° Common MLOps Tools\n",
    "\n",
    "| Stage | Tools |\n",
    "|------|-------|\n",
    "| Data versioning | DVC, Delta Lake |\n",
    "| Experiment tracking | MLflow, Weights & Biases |\n",
    "| Model deployment | FastAPI, Flask, Docker, Kubernetes |\n",
    "| Monitoring | Prometheus, Grafana, Evidently AI |\n",
    "| Pipelines | Airflow, Kubeflow, MLflow Pipelines |\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ’¡ Real-Life Analogy\n",
    "\n",
    "Think of ML as building a car ğŸï¸.  \n",
    "- Data scientists design and prototype the engine.  \n",
    "- MLOps makes sure the car runs reliably, can be mass-produced, monitored on the road, and fixed when needed.\n",
    "\n",
    "\n",
    "### âœ… Final Thought\n",
    "\n",
    "MLOps ensures **your ML model doesnâ€™t stop at a great accuracy score in Jupyter Notebook**, but actually runs smoothly and reliably **in the real world**, helping users or driving business decisions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd77496",
   "metadata": {},
   "source": [
    "### ğŸ§± Key Components of MLOps\n",
    "\n",
    "\n",
    "\n",
    "### 1. **Data Management**\n",
    "> ğŸ” Think of this as fuel for your ML engine.\n",
    "\n",
    "- **Data Collection** â€“ Gathering raw data from different sources.\n",
    "- **Data Validation** â€“ Checking for missing values, schema mismatches, or anomalies.\n",
    "- **Data Versioning** â€“ Keeping track of different versions of data using tools like **DVC**.\n",
    "- **Data Storage** â€“ Using storage systems (S3, GCS, databases, etc.) to securely store and retrieve data.\n",
    "\n",
    "\n",
    "\n",
    "### 2. **Model Development**\n",
    "> ğŸ§  The brain of your system is trained here.\n",
    "\n",
    "- **Model Training** â€“ Applying ML algorithms to learn from data.\n",
    "- **Experiment Tracking** â€“ Recording model parameters, metrics, and results (with tools like **MLflow**, **Weights & Biases**).\n",
    "- **Model Validation** â€“ Evaluating model performance using cross-validation, confusion matrices, etc.\n",
    "- **Model Registry** â€“ A centralized place to store and manage different versions of trained models.\n",
    "\n",
    "\n",
    "\n",
    "### 3. **Model Deployment**\n",
    "> ğŸš€ Getting your model from Jupyter Notebook to the real world.\n",
    "\n",
    "- **Serving the Model** â€“ Exposing the model via REST APIs using **FastAPI**, **Flask**, or **TensorFlow Serving**.\n",
    "- **Containerization** â€“ Using **Docker** to package everything (code + dependencies).\n",
    "- **Orchestration** â€“ Using **Kubernetes** to scale and manage containers.\n",
    "- **CI/CD Pipelines** â€“ Automating build, test, and deployment with tools like **GitHub Actions**, **Jenkins**, or **GitLab CI/CD**.\n",
    "\n",
    "\n",
    "\n",
    "### 4. **Model Monitoring**\n",
    "> ğŸ‘€ Keep an eye on your model like a hawk.\n",
    "\n",
    "- **Performance Monitoring** â€“ Check accuracy, precision, recall over time.\n",
    "- **Drift Detection** â€“ Track **data drift** and **concept drift** using tools like **Evidently AI**.\n",
    "- **Logging and Alerts** â€“ Set up real-time alerts when something goes wrong using **Prometheus**, **Grafana**, or **Sentry**.\n",
    "\n",
    "\n",
    "\n",
    "### 5. **Model Retraining & Feedback Loop**\n",
    "> ğŸ”„ Adapt and evolve with new data.\n",
    "\n",
    "- **Scheduled Retraining** â€“ Periodically retrain with fresh data (daily, weekly, etc.).\n",
    "- **Feedback Loop** â€“ Collect predictions and actual outcomes to refine models.\n",
    "- **AutoML Pipelines** â€“ Automate retraining pipelines with tools like **Kubeflow Pipelines** or **Airflow**.\n",
    "\n",
    "\n",
    "\n",
    "### 6. **Infrastructure & Environment Management**\n",
    "> ğŸ—ï¸ Build once, run anywhere â€” smoothly.\n",
    "\n",
    "- **Cloud & On-Prem Integration** â€“ Support for AWS, Azure, GCP, or your own servers.\n",
    "- **Resource Management** â€“ Use GPUs/CPUs wisely with Kubernetes.\n",
    "- **Environment Isolation** â€“ Use **virtual environments**, **Docker**, or **Conda** to avoid conflicts.\n",
    "\n",
    "\n",
    "\n",
    "### 7. **Collaboration & Governance**\n",
    "> ğŸ¤ Teams working together, with clear rules.\n",
    "\n",
    "- **Role-based Access** â€“ Who can deploy, retrain, or monitor?\n",
    "- **Audit Trails** â€“ Track who changed what and when.\n",
    "- **Documentation** â€“ Maintain proper documentation and model cards for transparency.\n",
    "\n",
    "### ğŸ§° Summary of Tools by Component\n",
    "\n",
    "| Component | Tools |\n",
    "|----------|-------|\n",
    "| Data Versioning | DVC, LakeFS |\n",
    "| Experiment Tracking | MLflow, W&B |\n",
    "| Deployment | Docker, FastAPI, Kubernetes |\n",
    "| Monitoring | Prometheus, Grafana, Evidently |\n",
    "| Pipelines | Kubeflow, Airflow, TFX |\n",
    "| CI/CD | GitHub Actions, Jenkins |\n",
    "| Model Registry | MLflow Model Registry, Sagemaker Model Registry |\n",
    "\n",
    "\n",
    "### ğŸ¯ Final Thought\n",
    "\n",
    "MLOps ensures your ML models are **reliable**, **scalable**, and **maintainable** â€” transforming one-time experiments into production-grade systems that deliver consistent value.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b333b",
   "metadata": {},
   "source": [
    "# ğŸŒŸ **End-to-End MLOps Project Summary**  \n",
    "_Based on a YouTube Sentiment Analysis Chrome Extension Project_\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ§  **Why This Project?**\n",
    "\n",
    "- ğŸ“ˆ **MLOps skills are in demand** â€” companies expect ML engineers to know them.\n",
    "- âœ… Goal: Build a full ML project using **MLOps tools & automation**.\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ” **Project Idea: YouTube Comment Sentiment Analyzer**\n",
    "\n",
    "- ğŸ§© Chrome plugin shows sentiment of YouTube comments.\n",
    "- ğŸ”¥ Shows:\n",
    "  - Sentiment per comment (Positive/Neutral/Negative)\n",
    "  - ğŸ“Š Pie chart with sentiment percentage\n",
    "  - ğŸ“ˆ Sentiment trend over months\n",
    "  - â˜ï¸ Word cloud of frequent words\n",
    "  - ğŸ… Predictions for top 25 comments\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ§° **Components**\n",
    "\n",
    "| Component     | Tech Used                   |\n",
    "|---------------|-----------------------------|\n",
    "| ğŸ–¼ Front-end   | HTML + CSS + JavaScript     |\n",
    "| âš™ï¸ Back-end    | Flask API                   |\n",
    "| ğŸ¤– ML Model    | Trained using Reddit data   |\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ§ª **Model Building (Core ML)**\n",
    "\n",
    "- ğŸ“¦ **Dataset**: Kaggle Reddit comments with sentiment labels\n",
    "- âœ… **Problem Type**: Multi-class Classification (Positive, Neutral, Negative)\n",
    "- ğŸ§¹ **Preprocessing & EDA** done to clean and explore data\n",
    "\n",
    "### ğŸ’¡ Key Questions Asked:\n",
    "\n",
    "1. Which text feature method? `TF-IDF`, `Bag of Words`, `Word2Vec`?\n",
    "2. How to handle imbalance? `Oversampling`, `SMOTE`, etc.?\n",
    "3. Which algorithm? `Random Forest`, `XGBoost`, `LightGBM`?\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ” **Experiment Tracking with MLflow**\n",
    "\n",
    "- ğŸ“‹ Tried different combinations\n",
    "- ğŸ† Best results:\n",
    "  - âœ… `TF-IDF` as feature technique\n",
    "  - âœ… `LightGBM` as algorithm\n",
    "  - âœ… Handled imbalance using **class weights**\n",
    "- ğŸ“Š MLflow used to **track and compare experiments**\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ”„ **Automation with DVC (Data Version Control)**\n",
    "\n",
    "- ğŸ”— Built a DVC pipeline with stages:\n",
    "  - `Data Ingestion`\n",
    "  - `Data Cleaning`\n",
    "  - `Feature Engineering`\n",
    "  - `Model Training`\n",
    "- ğŸ”§ Parameters in `params.yaml`\n",
    "- ğŸ“¦ DVC detects parameter change â triggers retraining\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ“¦ **Model Registry with MLflow**\n",
    "\n",
    "- ğŸ—‚ï¸ Tracks different **model versions**\n",
    "- ğŸ§ª Tested models before production\n",
    "- ğŸŸ¢ Promoted good models from `staging` â `production`\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ§ª **Model Testing**\n",
    "\n",
    "- âœ… **Load test**: Can model load & predict?\n",
    "- ğŸ§  **Performance test**: Is it better than the old one?\n",
    "\n",
    "\n",
    "\n",
    "## ğŸš€ **Deployment**\n",
    "\n",
    "### ğŸ§Š **Flask API + Docker**\n",
    "\n",
    "- Docker container built with the Flask API\n",
    "\n",
    "### â˜ï¸ **AWS Deployment**\n",
    "\n",
    "- ğŸš¢ Docker image pushed to **AWS ECR**\n",
    "- ğŸŒ Deployed on **EC2 with Auto Scaling + Load Balancer**\n",
    "- ğŸ” Used **AWS CodeDeploy** for **rolling updates** (zero downtime)\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ”„ **CI/CD with GitHub Actions**\n",
    "\n",
    "- âœ¨ Fully automated flow:\n",
    "  - Install dependencies\n",
    "  - Train model with DVC\n",
    "  - Test and promote model\n",
    "  - Build Docker image\n",
    "  - Push to AWS ECR\n",
    "  - Deploy with AWS CodeDeploy\n",
    "\n",
    "ğŸ” **One change in params.yaml** â ğŸ’¥ Entire pipeline runs automatically\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ“ˆ **What's Next?**\n",
    "\n",
    "- ğŸ“Š **Monitoring**: Use Prometheus & Grafana\n",
    "- ğŸ”„ **Auto-Retraining** when model performance drops\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ›  **Tool Alternatives**\n",
    "\n",
    "| Task                    | Alternative Tools              |\n",
    "|-------------------------|--------------------------------|\n",
    "| Experiment Tracking     | Weights & Biases               |\n",
    "| Workflow Orchestration | Apache Airflow, Kubeflow       |\n",
    "| Cloud Platform          | GCP, Azure                     |\n",
    "| All-in-one ML platform  | AWS SageMaker                  |\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ¯ **Key Takeaways**\n",
    "\n",
    "- ğŸ“Œ MLOps = Experimentation + Versioning + Automation + Deployment\n",
    "- ğŸ’¡ Tools can vary, but **concepts are key**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e11735b",
   "metadata": {},
   "source": [
    "# ğŸš€ **Data Management in MLOps (ETL Pipeline)**  \n",
    "\n",
    "\n",
    "## ğŸ§© **Video Structure**\n",
    "\n",
    "1. ğŸ” **Part 1** â€“ Quick revision of MLOps fundamentals  \n",
    "2. ğŸ’¾ **Part 2** â€“ Main topic: **Data Management** (ETL)\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ§  **Part 1: MLOps Recap**\n",
    "\n",
    "### ğŸ“Œ **Why MLOps?**\n",
    "- ML systems are more complex than regular software ğŸ’»\n",
    "- Involves:  \n",
    "  âœ… Code  \n",
    "  âœ… **Data**  \n",
    "  âœ… **ML models**\n",
    "\n",
    "### ğŸ“Œ **What is MLOps?**\n",
    "- MLOps = *Practices + Tools* for taking ML to production\n",
    "- ğŸ¯ Analogy: Good food (model) â‰  Successful restaurant (production system)\n",
    "- ğŸ”„ MLOps = Intersection of:\n",
    "  - ğŸ§  Machine Learning  \n",
    "  - âš™ï¸ Data Engineering  \n",
    "  - ğŸ”§ DevOps\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ’¾ **Part 2: Data Management in MLOps**\n",
    "\n",
    "> ğŸ’¡ **Data is the backbone of ML!** Without proper data handling, ML projects fail.\n",
    "\n",
    "### ğŸ§­ **12 Sub-Aspects of Data Management**  \n",
    "Not every company uses all 12 â€” depends on the **use case**  \n",
    "Examples:\n",
    "- ğŸš— **Data Annotation** â†’ critical for self-driving cars  \n",
    "- ğŸ“œ **Data Governance** â†’ needed for legal safety (e.g., ChatGPT)\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ” **ETL Pipeline: Extract - Transform - Load**\n",
    "\n",
    "> The heart of Data Management â¤ï¸\n",
    "\n",
    "\n",
    "\n",
    "## 1ï¸âƒ£ **Data Ingestion** â€“ ğŸ“¥ _Extract_\n",
    "\n",
    "- Bringing data from multiple sources into one place ğŸ§²\n",
    "- ğŸ¢ Example: **Samsung** collecting sales data:\n",
    "  - ğŸŒ Website â†’ Database\n",
    "  - ğŸ›’ Amazon â†’ Real-time stream\n",
    "  - ğŸ¬ Offline Stores â†’ POS APIs\n",
    "\n",
    "### ğŸ›  Tools Used:\n",
    "- **SQL** â€“ for databases\n",
    "- **Apache Kafka** / **AWS Kinesis** â€“ for real-time ingestion\n",
    "- **Python** + `requests` â€“ to access APIs\n",
    "\n",
    "\n",
    "\n",
    "## 2ï¸âƒ£ **Data Transformation** â€“ ğŸ›  _Transform_\n",
    "\n",
    "- Cleaning, merging, and converting data into usable form\n",
    "\n",
    "### ğŸ§¼ Steps:\n",
    "- ğŸ”— **Join** normalized DB tables using SQL\n",
    "- â• **Concatenate** data from different sources\n",
    "- ğŸ“… **Sort** by date\n",
    "- ğŸ’± **Normalize** currency (e.g., INR to USD)\n",
    "- ğŸ“Š **Aggregate** (e.g., total revenue per product per day)\n",
    "\n",
    "### ğŸ›  Tools Used:\n",
    "- **Pandas** â€“ for small/medium datasets\n",
    "- **Spark / PySpark** â€“ for large-scale data\n",
    "\n",
    "\n",
    "\n",
    "## 3ï¸âƒ£ **Data Storage** â€“ ğŸ’½ _Load_\n",
    "\n",
    "- Store the clean data for analysis or future ML use\n",
    "\n",
    "### ğŸ—ƒï¸ Options:\n",
    "| Type              | Examples                                   |\n",
    "|-------------------|--------------------------------------------|\n",
    "| ğŸ§Š **Data Warehouse** | Snowflake, AWS Redshift, Google BigQuery |\n",
    "| ğŸŒŠ **Data Lake**      | AWS S3                                   |\n",
    "| ğŸ—„ **Relational DB**   | MySQL, Oracle, SQL Server               |\n",
    "| ğŸ“¦ **NoSQL**          | MongoDB                                  |\n",
    "| ğŸ“ **File Storage**   | CSVs, AWS S3                              |\n",
    "\n",
    "\n",
    "\n",
    "# âš’ï¸ **ETL Pipeline Tools Overview**\n",
    "\n",
    "| Function            | Tools                                      |\n",
    "|---------------------|--------------------------------------------|\n",
    "| ğŸ“¥ Data Ingestion    | Python, SQL, Apache Kafka, AWS Kinesis     |\n",
    "| ğŸ”„ Data Transformation | Pandas, PySpark, Apache Spark             |\n",
    "| ğŸ’¾ Data Storage      | MySQL, Oracle, MongoDB, S3, Redshift, etc. |\n",
    "| ğŸ”— All-in-One ETL    | AWS Glue, Talend, Informatica, Apache NiFi |\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ¯ **Key Takeaways**\n",
    "\n",
    "- ğŸ”Œ ETL is essential in any ML pipeline\n",
    "- ğŸ§‘â€ğŸ’» **Data Engineers** manage and fix ETL pipelines\n",
    "- âš™ï¸ MLOps = tools + automation, but **concepts matter most**\n",
    "- ğŸ§° Familiarity with tools removes fear and boosts confidence ğŸ’ª\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ“š **Homework (As per video)**\n",
    "\n",
    "ğŸ” Research the listed tools to:\n",
    "- Understand their use\n",
    "- Reduce tool anxiety\n",
    "- Prepare for real-world MLOps tasks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd5b56",
   "metadata": {},
   "source": [
    "# ğŸš€ MLOPS Overview:\n",
    "\n",
    "### ğŸ› ï¸ **Tool Coverage**\n",
    "| Category              | Tools Covered                            |\n",
    "|-----------------------|-------------------------------------------|\n",
    "| ğŸ§‘â€ğŸ’» Coding & Versioning | Git, GitHub, Modular Coding, Logging      |\n",
    "| ğŸ§ª Experiment Tracking | DVC, MLflow                              |\n",
    "| ğŸ“¦ Containerization   | Docker, Docker Hub                        |\n",
    "| ğŸ” CI/CD              | GitHub Actions, CircleCI, Travis CI       |\n",
    "| â˜ï¸ Cloud              | AWS (IAM, EC2, S3)                        |\n",
    "| ğŸ“Š Monitoring         | Kubernetes, Prometheus, Grafana           |\n",
    "\n",
    "### ğŸ” **End-to-End Learning**\n",
    "- Hosting on GitHub ğŸ“\n",
    "- Writing powerful README ğŸ“ƒ\n",
    "- How to put projects on your **CV** ğŸ“„\n",
    "- How to explain your work to **recruiters** ğŸ’¬\n",
    "\n",
    "\n",
    "\n",
    "## âš ï¸ Common Problems in Traditional ML Projects (Before MLOps)\n",
    "\n",
    "| Problem                | Why itâ€™s an Issue                              | MLOps Solution                          |\n",
    "|------------------------|------------------------------------------------|------------------------------------------|\n",
    "| ğŸ““ Jupyter Coding      | Not production-ready                           | OOP, Modular Coding                      |\n",
    "| ğŸ“‚ Data Management     | No standard method to update real-world data   | Automated pipelines                      |\n",
    "| ğŸ§¾ Versioning          | No version control for data/models             | DVC, MLflow                              |\n",
    "| ğŸ”¬ Experimentation     | Difficult to track and automate                | Integrated ML workflow tools             |\n",
    "| âš™ï¸ CI/CD               | Manual deployment processes                    | GitHub Actions, CircleCI, Travis CI      |\n",
    "| ğŸ“ˆ Monitoring          | No performance monitoring post-deployment      | Prometheus, Grafana                      |\n",
    "| ğŸ¤ Team Friction       | Dependencies on other teams                    | MLOps broadens ML engineer skillset      |\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ§° Tools & Scope of the Playlist\n",
    "\n",
    "- **âœ… OOP & Modular Coding** (from scratch)\n",
    "- **âœ… Git + GitHub** (in-depth)\n",
    "- **âœ… DVC + MLflow** (for versioning & experiments)\n",
    "- **âœ… CI/CD** with GitHub Actions, CircleCI, Travis CI\n",
    "- **âœ… Docker** for containerization\n",
    "- **âœ… Kubernetes**, Prometheus, Grafana for monitoring/scalability\n",
    "- **âœ… AWS (IAM, EC2, S3)** for cloud hands-on\n",
    "- ğŸ”’ Platforms like SageMaker, Vertex AI, Azure ML are **optional** (can be covered on request)\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2395e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
