{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['go india',\n",
    "\t\t'india india',\n",
    "\t\t'hip hip hurray',\n",
    "\t\t'jeetega bhai jeetega india jeetega',\n",
    "\t\t'bharat mata ki jai',\n",
    "\t\t'kohli kohli',\n",
    "\t\t'sachin sachin',\n",
    "\t\t'dhoni dhoni',\n",
    "\t\t'modi ji ki jai',\n",
    "\t\t'inquilab zindabad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 1],\n",
       " [1, 1],\n",
       " [3, 3, 10],\n",
       " [2, 11, 2, 1, 2],\n",
       " [12, 13, 4, 5],\n",
       " [6, 6],\n",
       " [7, 7],\n",
       " [8, 8],\n",
       " [14, 15, 4, 5],\n",
       " [16, 17]]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "sequences = pad_sequences(sequences,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(word_index) +1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  1,  0,  0,  0],\n",
       "       [ 1,  1,  0,  0,  0],\n",
       "       [ 3,  3, 10,  0,  0],\n",
       "       [ 2, 11,  2,  1,  2],\n",
       "       [12, 13,  4,  5,  0],\n",
       "       [ 6,  6,  0,  0,  0],\n",
       "       [ 7,  7,  0,  0,  0],\n",
       "       [ 8,  8,  0,  0,  0],\n",
       "       [14, 15,  4,  5,  0],\n",
       "       [16, 17,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 5, 2)              36        \n",
      "=================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,SimpleRNN,Embedding,Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=input_dim,output_dim=2,input_length=sequences.shape[1]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam','accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f47a30f0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.04898475,  0.04162392],\n",
       "        [-0.04031254, -0.0060967 ],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342]],\n",
       "\n",
       "       [[-0.04031254, -0.0060967 ],\n",
       "        [-0.04031254, -0.0060967 ],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342]],\n",
       "\n",
       "       [[ 0.03806852,  0.03887692],\n",
       "        [ 0.03806852,  0.03887692],\n",
       "        [-0.04958303, -0.00452346],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342]],\n",
       "\n",
       "       [[-0.0124109 , -0.00147189],\n",
       "        [ 0.04637999,  0.03408921],\n",
       "        [-0.0124109 , -0.00147189],\n",
       "        [-0.04031254, -0.0060967 ],\n",
       "        [-0.0124109 , -0.00147189]],\n",
       "\n",
       "       [[-0.01544033,  0.04550531],\n",
       "        [ 0.00267696,  0.03877702],\n",
       "        [-0.02205317, -0.00393245],\n",
       "        [-0.00633357, -0.00841608],\n",
       "        [ 0.02401431,  0.02752342]],\n",
       "\n",
       "       [[-0.03904586, -0.02637096],\n",
       "        [-0.03904586, -0.02637096],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342]],\n",
       "\n",
       "       [[ 0.00557267,  0.02571856],\n",
       "        [ 0.00557267,  0.02571856],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342]],\n",
       "\n",
       "       [[ 0.02509706,  0.03377999],\n",
       "        [ 0.02509706,  0.03377999],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342]],\n",
       "\n",
       "       [[ 0.0438912 ,  0.01794847],\n",
       "        [-0.02593169, -0.028552  ],\n",
       "        [-0.02205317, -0.00393245],\n",
       "        [-0.00633357, -0.00841608],\n",
       "        [ 0.02401431,  0.02752342]],\n",
       "\n",
       "       [[-0.0424605 ,  0.0260048 ],\n",
       "        [-0.02203985, -0.0183499 ],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342],\n",
       "        [ 0.02401431,  0.02752342]]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train,padding='post',maxlen=50)\n",
    "X_test = pad_sequences(X_test,padding='post',maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 50)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 50, 2)             20000     \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 32)                1120      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 21,153\n",
      "Trainable params: 21,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000,output_dim=2,input_length=50))\n",
    "model.add(SimpleRNN(32,return_sequences=False))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.6472 - acc: 0.5872 - val_loss: 0.5279 - val_acc: 0.7342\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4169 - acc: 0.8135 - val_loss: 0.4345 - val_acc: 0.8018\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.3333 - acc: 0.8609 - val_loss: 0.4292 - val_acc: 0.8118\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.2897 - acc: 0.8839 - val_loss: 0.4385 - val_acc: 0.8072\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.2575 - acc: 0.8998 - val_loss: 0.4699 - val_acc: 0.7965\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "history = model.fit(X_train,y_train,epochs=5,validation_data=(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
