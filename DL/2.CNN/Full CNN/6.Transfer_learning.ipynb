{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎨 **Pretrained Models in CNN: The Ultimate Guide** 🚀  \n",
    "\n",
    "## **What Are Pretrained Models? 🤔**  \n",
    "A **pretrained model** is a deep learning model that has already been trained on a **large dataset** (like ImageNet) and can be used for **transfer learning** in other tasks. Instead of training a CNN from scratch, you can **leverage a pretrained model** to save time, computation, and data.\n",
    "\n",
    "💡 **Imagine this:** You're learning to drive. Instead of starting from zero, you get trained by an **expert driver**—this is what pretrained models do for CNNs!\n",
    "\n",
    "\n",
    "\n",
    "## **🔥 Why Use Pretrained Models?**\n",
    "✅ **Faster Training** – Instead of days or weeks, training takes only minutes to hours.  \n",
    "✅ **Better Accuracy** – These models are trained on millions of images, giving them a strong ability to recognize patterns.  \n",
    "✅ **Less Data Required** – You don’t need a massive dataset; even a few hundred images work!  \n",
    "✅ **Reduces Computational Cost** – Instead of requiring expensive GPUs for weeks, you can fine-tune in hours.  \n",
    "\n",
    "\n",
    "\n",
    "## **Popular Pretrained Models 🏆**\n",
    "Most pretrained models are trained on **ImageNet** (a dataset with 1.2M images across 1,000 categories). Here are some of the most famous ones:\n",
    "\n",
    "| Model       | Year | Parameters | Top-5 Error Rate | Key Feature 🧐 |\n",
    "|------------|------|------------|-----------------|----------------|\n",
    "| **AlexNet** 🏛️ | 2012 | 60M | 15.3% | First deep CNN to win ImageNet |\n",
    "| **VGG16/VGG19** 🏗️ | 2014 | 138M | 7.3% | Deep but slow, famous for simplicity |\n",
    "| **GoogLeNet (Inception V1)** 🌟 | 2014 | 6.8M | 6.67% | Uses inception modules for efficiency |\n",
    "| **ResNet50/ResNet101** 🏆 | 2015 | 25.5M | 3.57% | Introduced residual learning to go deeper |\n",
    "| **DenseNet** 🔗 | 2016 | 8M | 3.46% | Feature reuse via dense connections |\n",
    "| **EfficientNet** ⚡ | 2019 | 5M+ | <2% | SOTA accuracy with low compute |\n",
    "| **Vision Transformers (ViTs)** 🤖 | 2021+ | Varies | <1% | Uses attention instead of convolutions |\n",
    "\n",
    "\n",
    "\n",
    "## **🛠️ How to Use Pretrained Models in TensorFlow/Keras**\n",
    "### **1️⃣ Load a Pretrained Model**\n",
    "```python\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load the VGG16 model with pre-trained ImageNet weights\n",
    "model = VGG16(weights='imagenet')\n",
    "```\n",
    "\n",
    "### **2️⃣ Preprocess an Image for Prediction**\n",
    "```python\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = cv2.imread('cat.jpg')\n",
    "img = cv2.resize(img, (224, 224))  # Resize to 224x224\n",
    "img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "img = preprocess_input(img)  # Normalize as per VGG16\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(img)\n",
    "label = decode_predictions(predictions, top=3)[0]  # Get top 3 predictions\n",
    "\n",
    "for _, name, score in label:\n",
    "    print(f\"{name}: {score:.2%}\")  # Show probability\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## **💡 Transfer Learning with Pretrained Models**\n",
    "Most real-world tasks require **customizing** a pretrained model.  \n",
    "You can **freeze early layers** (to keep general features) and **fine-tune deeper layers** (to adapt to your specific dataset).\n",
    "\n",
    "### **🔹 Method 1: Feature Extraction (Freezing Early Layers)**\n",
    "Useful when your dataset is **small** (few images).  \n",
    "```python\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Load Pretrained Model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze Base Layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # Keep existing weights\n",
    "\n",
    "# Add Custom Layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(10, activation='softmax')(x)  # 10 classes\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "### **🔹 Method 2: Fine-Tuning (Unfreezing Some Layers)**\n",
    "Useful when your dataset is **large** (thousands of images).  \n",
    "```python\n",
    "# Unfreeze some deeper layers\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## **🔥 Pretrained Models in PyTorch**\n",
    "If you're a **PyTorch** fan, you can load models easily:\n",
    "```python\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load Pretrained Model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()  # Set to inference mode\n",
    "\n",
    "# Load and Preprocess an Image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img = Image.open(\"cat.jpg\")\n",
    "img = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Predict\n",
    "output = model(img)\n",
    "_, predicted_class = torch.max(output, 1)\n",
    "print(predicted_class)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## **🎯 When to Use Which Model?**\n",
    "| **Scenario** | **Best Model** |\n",
    "|-------------|---------------|\n",
    "| **Fast inference (mobile, web apps)** | MobileNet, EfficientNet |\n",
    "| **High accuracy (image classification)** | ResNet, EfficientNet |\n",
    "| **Limited data (small dataset)** | VGG16, ResNet (with feature extraction) |\n",
    "| **Object detection** | YOLO, Faster R-CNN |\n",
    "| **Medical Imaging** | DenseNet, ViT |\n",
    "\n",
    "\n",
    "\n",
    "## **🚀 Future of Pretrained Models**\n",
    "1. **Vision Transformers (ViTs) replacing CNNs** 📜  \n",
    "2. **Self-supervised learning reducing reliance on labeled data** 🤖  \n",
    "3. **Efficient models optimized for edge devices** (TinyML) 📱  \n",
    "\n",
    "\n",
    "\n",
    "## **🌟 Summary**\n",
    "✅ **Pretrained models** help in image classification, object detection, and feature extraction.  \n",
    "✅ **Popular choices**: VGG, ResNet, EfficientNet, Transformers.  \n",
    "✅ **Can be fine-tuned** for **custom datasets** (e.g., medical, satellite, facial recognition).  \n",
    "✅ **Easy to implement** in TensorFlow/Keras & PyTorch!  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎨 **Transfer Learning in Deep Learning: A Simple, Colorful Guide!** 🚀  \n",
    "\n",
    "Imagine you're learning to **play the guitar 🎸**. At first, it's tough—fingers hurt, chords are confusing, and strumming feels awkward. But once you **master basic chords**, learning a new song becomes much easier. You **don’t start from scratch**; you **reuse what you already know** and just tweak it a little for the new song.  \n",
    "\n",
    "**That’s exactly how transfer learning works in deep learning!** 😃  \n",
    "\n",
    "\n",
    "\n",
    "## 🌟 **What is Transfer Learning?**  \n",
    "**Transfer learning** means **taking a pre-trained model** (one trained on a huge dataset) and **reusing it** for a new but related task. Instead of training a deep neural network from scratch (which takes tons of data & computing power 🖥️🔥), you **leverage an existing model’s knowledge** and fine-tune it for your needs.  \n",
    "\n",
    "🔹 **Think of it as a shortcut in AI learning!** Instead of spending days training a model from scratch, you **borrow knowledge** from models trained by experts on massive datasets.  \n",
    "\n",
    "\n",
    "\n",
    "## 🏆 **Why Use Transfer Learning?**  \n",
    "\n",
    "✅ **Faster Training ⏳** – Since the model already knows a lot, you don’t have to train from scratch.  \n",
    "✅ **Requires Less Data 📊** – Pre-trained models are trained on massive datasets, so you need **fewer** new samples.  \n",
    "✅ **Better Accuracy 🎯** – Instead of training a weak model from scratch, you start with a strong one and improve it!  \n",
    "✅ **Saves Compute Power ⚡** – Training deep models from scratch is expensive. Transfer learning is a cost-effective alternative.  \n",
    "\n",
    "\n",
    "\n",
    "## 🏗️ **How Does Transfer Learning Work?**  \n",
    "\n",
    "Here’s how it typically works in deep learning:  \n",
    "\n",
    "### 🎭 **1. Pick a Pre-trained Model**  \n",
    "A deep learning model (like VGG16, ResNet, BERT, etc.) that has been trained on massive datasets like **ImageNet (for vision tasks) or Wikipedia (for NLP tasks)**.  \n",
    "\n",
    "### 🏗️ **2. Modify the Model for Your Task**  \n",
    "You usually **remove the last few layers** (which were specific to the original task) and **replace them with new layers** tailored for your dataset.  \n",
    "\n",
    "### 🔥 **3. Fine-Tune (or Feature Extraction)**  \n",
    "- **Option 1: Feature Extraction 🛠️** – Freeze most layers and only train the last few new layers.  \n",
    "- **Option 2: Fine-Tuning 🎯** – Train the whole model (but at a very low learning rate to avoid destroying existing knowledge).  \n",
    "\n",
    "### 📊 **4. Train on Your Data & Enjoy 🚀**  \n",
    "Now, train the model on your dataset and get amazing results with much less effort!  \n",
    "\n",
    "\n",
    "\n",
    "## 🖼️ **Example: Transfer Learning for Image Classification**  \n",
    "Let’s say you want to classify **cats 🐱 and dogs 🐶**, but you don’t have millions of images to train from scratch. Instead, you can:  \n",
    "\n",
    "1️⃣ Take a **pre-trained model** like ResNet (trained on ImageNet).  \n",
    "2️⃣ Remove the last layer (which originally classified 1,000 objects).  \n",
    "3️⃣ Replace it with a new **classification layer** (with just \"Cat\" & \"Dog\" classes).  \n",
    "4️⃣ Train on your small dataset with fine-tuning.  \n",
    "\n",
    "🎉 **Boom! Your model is now an expert at distinguishing cats from dogs without needing a huge dataset!**  \n",
    "\n",
    "\n",
    "\n",
    "## 🗣️ **Transfer Learning in NLP (Text Data)**  \n",
    "For text-related tasks like chatbots 🤖, speech-to-text 🎙️, or sentiment analysis 😊😡, we use **pre-trained models like BERT, GPT, or T5** and fine-tune them on specific datasets.  \n",
    "\n",
    "Example:  \n",
    "1️⃣ Use **BERT**, which is trained on **billions** of words.  \n",
    "2️⃣ Fine-tune it with **your** text data (like customer reviews 📢).  \n",
    "3️⃣ Now, your model understands your data better and can classify sentiments accurately!  \n",
    "\n",
    "\n",
    "\n",
    "## 🔥 **Popular Pre-trained Models for Transfer Learning**  \n",
    "\n",
    "### 🖼️ **Computer Vision** (Images)  \n",
    "📌 **ResNet** – Great for general image classification.  \n",
    "📌 **VGG16** – Simple and effective for image tasks.  \n",
    "📌 **EfficientNet** – High accuracy with fewer parameters.  \n",
    "📌 **YOLO** – Perfect for object detection tasks.  \n",
    "\n",
    "### 🗣️ **Natural Language Processing (NLP)**  \n",
    "📌 **BERT** – Best for understanding text context.  \n",
    "📌 **GPT-3/GPT-4** – Powerful for text generation.  \n",
    "📌 **T5** – Great for text summarization & translation.  \n",
    "📌 **XLNet** – Advanced alternative to BERT.  \n",
    "\n",
    "\n",
    "\n",
    "## 💡 **Key Takeaways**  \n",
    "\n",
    "✅ **Transfer learning helps deep learning models learn faster, better, and with less data.**  \n",
    "✅ **It’s widely used in image recognition, NLP, and even audio/speech processing.**  \n",
    "✅ **Fine-tuning a pre-trained model is the key to adapting it to your needs.**  \n",
    "✅ **Popular pre-trained models exist for both image and text-based tasks.**  \n",
    "\n",
    "\n",
    "\n",
    "🔮 **Future of Transfer Learning?**  \n",
    "With AI growing rapidly, **transfer learning is becoming the standard approach** in deep learning. Instead of training models from scratch, businesses and researchers **reuse and fine-tune powerful AI models** for various real-world applications.  \n",
    "\n",
    "So, next time you’re working on an AI project, **think like a smart learner—reuse what already exists and build on top of it!** 🚀💡\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input,decode_predictions\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('/home/suhas/Downloads/chima.jpeg')\n",
    "img = cv2.resize(img,(224,224))\n",
    "img = np.expand_dims(img,axis=0)\n",
    "img = preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = decode_predictions(predictions,top=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chimpanzee:60.56%\n",
      "gorilla:33.62%\n",
      "macaque:1.66%\n"
     ]
    }
   ],
   "source": [
    "for _,name,score in label:\n",
    "    print(f\"{name}:{score:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
