{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¨ **Pretrained Models in CNN: The Ultimate Guide** ğŸš€  \n",
    "\n",
    "## **What Are Pretrained Models? ğŸ¤”**  \n",
    "A **pretrained model** is a deep learning model that has already been trained on a **large dataset** (like ImageNet) and can be used for **transfer learning** in other tasks. Instead of training a CNN from scratch, you can **leverage a pretrained model** to save time, computation, and data.\n",
    "\n",
    "ğŸ’¡ **Imagine this:** You're learning to drive. Instead of starting from zero, you get trained by an **expert driver**â€”this is what pretrained models do for CNNs!\n",
    "\n",
    "\n",
    "\n",
    "## **ğŸ”¥ Why Use Pretrained Models?**\n",
    "âœ… **Faster Training** â€“ Instead of days or weeks, training takes only minutes to hours.  \n",
    "âœ… **Better Accuracy** â€“ These models are trained on millions of images, giving them a strong ability to recognize patterns.  \n",
    "âœ… **Less Data Required** â€“ You donâ€™t need a massive dataset; even a few hundred images work!  \n",
    "âœ… **Reduces Computational Cost** â€“ Instead of requiring expensive GPUs for weeks, you can fine-tune in hours.  \n",
    "\n",
    "\n",
    "\n",
    "## **Popular Pretrained Models ğŸ†**\n",
    "Most pretrained models are trained on **ImageNet** (a dataset with 1.2M images across 1,000 categories). Here are some of the most famous ones:\n",
    "\n",
    "| Model       | Year | Parameters | Top-5 Error Rate | Key Feature ğŸ§ |\n",
    "|------------|------|------------|-----------------|----------------|\n",
    "| **AlexNet** ğŸ›ï¸ | 2012 | 60M | 15.3% | First deep CNN to win ImageNet |\n",
    "| **VGG16/VGG19** ğŸ—ï¸ | 2014 | 138M | 7.3% | Deep but slow, famous for simplicity |\n",
    "| **GoogLeNet (Inception V1)** ğŸŒŸ | 2014 | 6.8M | 6.67% | Uses inception modules for efficiency |\n",
    "| **ResNet50/ResNet101** ğŸ† | 2015 | 25.5M | 3.57% | Introduced residual learning to go deeper |\n",
    "| **DenseNet** ğŸ”— | 2016 | 8M | 3.46% | Feature reuse via dense connections |\n",
    "| **EfficientNet** âš¡ | 2019 | 5M+ | <2% | SOTA accuracy with low compute |\n",
    "| **Vision Transformers (ViTs)** ğŸ¤– | 2021+ | Varies | <1% | Uses attention instead of convolutions |\n",
    "\n",
    "\n",
    "\n",
    "## **ğŸ› ï¸ How to Use Pretrained Models in TensorFlow/Keras**\n",
    "### **1ï¸âƒ£ Load a Pretrained Model**\n",
    "```python\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load the VGG16 model with pre-trained ImageNet weights\n",
    "model = VGG16(weights='imagenet')\n",
    "```\n",
    "\n",
    "### **2ï¸âƒ£ Preprocess an Image for Prediction**\n",
    "```python\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = cv2.imread('cat.jpg')\n",
    "img = cv2.resize(img, (224, 224))  # Resize to 224x224\n",
    "img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "img = preprocess_input(img)  # Normalize as per VGG16\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(img)\n",
    "label = decode_predictions(predictions, top=3)[0]  # Get top 3 predictions\n",
    "\n",
    "for _, name, score in label:\n",
    "    print(f\"{name}: {score:.2%}\")  # Show probability\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## **ğŸ’¡ Transfer Learning with Pretrained Models**\n",
    "Most real-world tasks require **customizing** a pretrained model.  \n",
    "You can **freeze early layers** (to keep general features) and **fine-tune deeper layers** (to adapt to your specific dataset).\n",
    "\n",
    "### **ğŸ”¹ Method 1: Feature Extraction (Freezing Early Layers)**\n",
    "Useful when your dataset is **small** (few images).  \n",
    "```python\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Load Pretrained Model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze Base Layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # Keep existing weights\n",
    "\n",
    "# Add Custom Layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(10, activation='softmax')(x)  # 10 classes\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "### **ğŸ”¹ Method 2: Fine-Tuning (Unfreezing Some Layers)**\n",
    "Useful when your dataset is **large** (thousands of images).  \n",
    "```python\n",
    "# Unfreeze some deeper layers\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## **ğŸ”¥ Pretrained Models in PyTorch**\n",
    "If you're a **PyTorch** fan, you can load models easily:\n",
    "```python\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load Pretrained Model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()  # Set to inference mode\n",
    "\n",
    "# Load and Preprocess an Image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img = Image.open(\"cat.jpg\")\n",
    "img = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Predict\n",
    "output = model(img)\n",
    "_, predicted_class = torch.max(output, 1)\n",
    "print(predicted_class)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## **ğŸ¯ When to Use Which Model?**\n",
    "| **Scenario** | **Best Model** |\n",
    "|-------------|---------------|\n",
    "| **Fast inference (mobile, web apps)** | MobileNet, EfficientNet |\n",
    "| **High accuracy (image classification)** | ResNet, EfficientNet |\n",
    "| **Limited data (small dataset)** | VGG16, ResNet (with feature extraction) |\n",
    "| **Object detection** | YOLO, Faster R-CNN |\n",
    "| **Medical Imaging** | DenseNet, ViT |\n",
    "\n",
    "\n",
    "\n",
    "## **ğŸš€ Future of Pretrained Models**\n",
    "1. **Vision Transformers (ViTs) replacing CNNs** ğŸ“œ  \n",
    "2. **Self-supervised learning reducing reliance on labeled data** ğŸ¤–  \n",
    "3. **Efficient models optimized for edge devices** (TinyML) ğŸ“±  \n",
    "\n",
    "\n",
    "\n",
    "## **ğŸŒŸ Summary**\n",
    "âœ… **Pretrained models** help in image classification, object detection, and feature extraction.  \n",
    "âœ… **Popular choices**: VGG, ResNet, EfficientNet, Transformers.  \n",
    "âœ… **Can be fine-tuned** for **custom datasets** (e.g., medical, satellite, facial recognition).  \n",
    "âœ… **Easy to implement** in TensorFlow/Keras & PyTorch!  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¨ **Transfer Learning in Deep Learning: A Simple, Colorful Guide!** ğŸš€  \n",
    "\n",
    "Imagine you're learning to **play the guitar ğŸ¸**. At first, it's toughâ€”fingers hurt, chords are confusing, and strumming feels awkward. But once you **master basic chords**, learning a new song becomes much easier. You **donâ€™t start from scratch**; you **reuse what you already know** and just tweak it a little for the new song.  \n",
    "\n",
    "**Thatâ€™s exactly how transfer learning works in deep learning!** ğŸ˜ƒ  \n",
    "\n",
    "\n",
    "\n",
    "## ğŸŒŸ **What is Transfer Learning?**  \n",
    "**Transfer learning** means **taking a pre-trained model** (one trained on a huge dataset) and **reusing it** for a new but related task. Instead of training a deep neural network from scratch (which takes tons of data & computing power ğŸ–¥ï¸ğŸ”¥), you **leverage an existing modelâ€™s knowledge** and fine-tune it for your needs.  \n",
    "\n",
    "ğŸ”¹ **Think of it as a shortcut in AI learning!** Instead of spending days training a model from scratch, you **borrow knowledge** from models trained by experts on massive datasets.  \n",
    "\n",
    "\n",
    "\n",
    "## ğŸ† **Why Use Transfer Learning?**  \n",
    "\n",
    "âœ… **Faster Training â³** â€“ Since the model already knows a lot, you donâ€™t have to train from scratch.  \n",
    "âœ… **Requires Less Data ğŸ“Š** â€“ Pre-trained models are trained on massive datasets, so you need **fewer** new samples.  \n",
    "âœ… **Better Accuracy ğŸ¯** â€“ Instead of training a weak model from scratch, you start with a strong one and improve it!  \n",
    "âœ… **Saves Compute Power âš¡** â€“ Training deep models from scratch is expensive. Transfer learning is a cost-effective alternative.  \n",
    "\n",
    "\n",
    "\n",
    "## ğŸ—ï¸ **How Does Transfer Learning Work?**  \n",
    "\n",
    "Hereâ€™s how it typically works in deep learning:  \n",
    "\n",
    "### ğŸ­ **1. Pick a Pre-trained Model**  \n",
    "A deep learning model (like VGG16, ResNet, BERT, etc.) that has been trained on massive datasets like **ImageNet (for vision tasks) or Wikipedia (for NLP tasks)**.  \n",
    "\n",
    "### ğŸ—ï¸ **2. Modify the Model for Your Task**  \n",
    "You usually **remove the last few layers** (which were specific to the original task) and **replace them with new layers** tailored for your dataset.  \n",
    "\n",
    "### ğŸ”¥ **3. Fine-Tune (or Feature Extraction)**  \n",
    "- **Option 1: Feature Extraction ğŸ› ï¸** â€“ Freeze most layers and only train the last few new layers.  \n",
    "- **Option 2: Fine-Tuning ğŸ¯** â€“ Train the whole model (but at a very low learning rate to avoid destroying existing knowledge).  \n",
    "\n",
    "### ğŸ“Š **4. Train on Your Data & Enjoy ğŸš€**  \n",
    "Now, train the model on your dataset and get amazing results with much less effort!  \n",
    "\n",
    "\n",
    "\n",
    "## ğŸ–¼ï¸ **Example: Transfer Learning for Image Classification**  \n",
    "Letâ€™s say you want to classify **cats ğŸ± and dogs ğŸ¶**, but you donâ€™t have millions of images to train from scratch. Instead, you can:  \n",
    "\n",
    "1ï¸âƒ£ Take a **pre-trained model** like ResNet (trained on ImageNet).  \n",
    "2ï¸âƒ£ Remove the last layer (which originally classified 1,000 objects).  \n",
    "3ï¸âƒ£ Replace it with a new **classification layer** (with just \"Cat\" & \"Dog\" classes).  \n",
    "4ï¸âƒ£ Train on your small dataset with fine-tuning.  \n",
    "\n",
    "ğŸ‰ **Boom! Your model is now an expert at distinguishing cats from dogs without needing a huge dataset!**  \n",
    "\n",
    "\n",
    "\n",
    "## ğŸ—£ï¸ **Transfer Learning in NLP (Text Data)**  \n",
    "For text-related tasks like chatbots ğŸ¤–, speech-to-text ğŸ™ï¸, or sentiment analysis ğŸ˜ŠğŸ˜¡, we use **pre-trained models like BERT, GPT, or T5** and fine-tune them on specific datasets.  \n",
    "\n",
    "Example:  \n",
    "1ï¸âƒ£ Use **BERT**, which is trained on **billions** of words.  \n",
    "2ï¸âƒ£ Fine-tune it with **your** text data (like customer reviews ğŸ“¢).  \n",
    "3ï¸âƒ£ Now, your model understands your data better and can classify sentiments accurately!  \n",
    "\n",
    "\n",
    "\n",
    "## ğŸ”¥ **Popular Pre-trained Models for Transfer Learning**  \n",
    "\n",
    "### ğŸ–¼ï¸ **Computer Vision** (Images)  \n",
    "ğŸ“Œ **ResNet** â€“ Great for general image classification.  \n",
    "ğŸ“Œ **VGG16** â€“ Simple and effective for image tasks.  \n",
    "ğŸ“Œ **EfficientNet** â€“ High accuracy with fewer parameters.  \n",
    "ğŸ“Œ **YOLO** â€“ Perfect for object detection tasks.  \n",
    "\n",
    "### ğŸ—£ï¸ **Natural Language Processing (NLP)**  \n",
    "ğŸ“Œ **BERT** â€“ Best for understanding text context.  \n",
    "ğŸ“Œ **GPT-3/GPT-4** â€“ Powerful for text generation.  \n",
    "ğŸ“Œ **T5** â€“ Great for text summarization & translation.  \n",
    "ğŸ“Œ **XLNet** â€“ Advanced alternative to BERT.  \n",
    "\n",
    "\n",
    "\n",
    "## ğŸ’¡ **Key Takeaways**  \n",
    "\n",
    "âœ… **Transfer learning helps deep learning models learn faster, better, and with less data.**  \n",
    "âœ… **Itâ€™s widely used in image recognition, NLP, and even audio/speech processing.**  \n",
    "âœ… **Fine-tuning a pre-trained model is the key to adapting it to your needs.**  \n",
    "âœ… **Popular pre-trained models exist for both image and text-based tasks.**  \n",
    "\n",
    "\n",
    "\n",
    "ğŸ”® **Future of Transfer Learning?**  \n",
    "With AI growing rapidly, **transfer learning is becoming the standard approach** in deep learning. Instead of training models from scratch, businesses and researchers **reuse and fine-tune powerful AI models** for various real-world applications.  \n",
    "\n",
    "So, next time youâ€™re working on an AI project, **think like a smart learnerâ€”reuse what already exists and build on top of it!** ğŸš€ğŸ’¡\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input,decode_predictions\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('/home/suhas/Downloads/chima.jpeg')\n",
    "img = cv2.resize(img,(224,224))\n",
    "img = np.expand_dims(img,axis=0)\n",
    "img = preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = decode_predictions(predictions,top=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chimpanzee:60.56%\n",
      "gorilla:33.62%\n",
      "macaque:1.66%\n"
     ]
    }
   ],
   "source": [
    "for _,name,score in label:\n",
    "    print(f\"{name}:{score:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
