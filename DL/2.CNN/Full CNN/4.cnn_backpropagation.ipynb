{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Backpropagation in CNN (Convolutional Neural Networks) ‚Äì Full Explanation**\n",
    "\n",
    "### **üìå What is Backpropagation?**\n",
    "Backpropagation is a key **learning algorithm** that helps a neural network **adjust its weights** to reduce errors. In **CNNs**, backpropagation is used to update the **convolutional filters** (kernels) and weights in **fully connected layers** based on the error made by the model.\n",
    "\n",
    "\n",
    "\n",
    "### **üìå Steps in Backpropagation for CNN**\n",
    "Backpropagation in a CNN follows **four main steps**:\n",
    "\n",
    "1. **Forward Propagation** (Compute Predictions)\n",
    "2. **Compute Loss** (How wrong is the prediction?)\n",
    "3. **Backward Propagation** (Calculate gradients)\n",
    "4. **Update Weights** (Adjust kernels & weights)\n",
    "\n",
    "Let‚Äôs break it down step by step in a **simple way**. üöÄ\n",
    "\n",
    "\n",
    "\n",
    "## **1Ô∏è‚É£ Forward Propagation (Making Predictions)**\n",
    "- **Input Image**: The CNN receives an image as input.\n",
    "- **Convolution Layers**: Filters (kernels) extract features (edges, textures).\n",
    "- **Pooling Layers**: Reduce the feature map size.\n",
    "- **Fully Connected Layers**: Convert feature maps into a final prediction.\n",
    "- **Softmax / Sigmoid**: Outputs probabilities for classification.\n",
    "\n",
    "‚úÖ **Example**:  \n",
    "If the CNN is classifying handwritten digits (MNIST), it outputs probabilities for each digit **(0-9)**.\n",
    "\n",
    "\n",
    "\n",
    "## **2Ô∏è‚É£ Compute Loss (How Wrong is the Prediction?)**\n",
    "- The CNN‚Äôs predicted output is compared to the **actual label** using a **loss function** (e.g., Cross-Entropy Loss for classification).\n",
    "- The loss measures **how far the predicted output is from the true value**.\n",
    "\n",
    "‚úÖ **Example**:  \n",
    "If the CNN predicts **7**, but the correct label is **5**, the loss is high.\n",
    "\n",
    "\n",
    "\n",
    "## **3Ô∏è‚É£ Backward Propagation (Calculating Gradients)**\n",
    "Now, the CNN needs to **adjust its filters and weights** so that the error decreases.  \n",
    "This is done using the **chain rule of calculus** to compute gradients.\n",
    "\n",
    "üìå **Key steps:**\n",
    "1. **Calculate error in the output layer**:  \n",
    "   - The **gradient of the loss function** tells us how much the error changes with respect to the output.\n",
    "  \n",
    "2. **Backpropagate through the fully connected layers**:  \n",
    "   - The gradients flow backward to adjust weights.\n",
    "\n",
    "3. **Backpropagate through the pooling & convolution layers**:  \n",
    "   - Since pooling layers don‚Äôt have weights, only **convolution filters** get updated.\n",
    "   - Gradients pass through **activation functions (ReLU, Tanh, etc.)**.\n",
    "\n",
    "4. **Compute Gradients for Kernels (Filters)**:  \n",
    "   - Each **filter** in a convolutional layer is updated based on the gradient.\n",
    "   - Filters that detect important features (e.g., edges) get stronger.\n",
    "   - Unimportant filters get weaker.\n",
    "\n",
    "‚úÖ **Example**:  \n",
    "If a filter is responsible for detecting a **dog‚Äôs ear** but predicts **incorrectly**, the CNN reduces its influence.  \n",
    "If another filter detects a **dog‚Äôs nose correctly**, it strengthens that filter.\n",
    "\n",
    "\n",
    "\n",
    "## **4Ô∏è‚É£ Update Weights (Using Gradient Descent)**\n",
    "- The computed gradients are used to **update the filters and weights**.\n",
    "- The most common optimization algorithm is **Stochastic Gradient Descent (SGD) or Adam**:\n",
    "  \n",
    "  $$\n",
    "  W_{\\text{new}} = W_{\\text{old}} - \\eta \\times \\text{gradient}\n",
    "  $$\n",
    "  \n",
    "  where **Œ∑ (eta) is the learning rate**.\n",
    "\n",
    "- This step **adjusts the CNN's filters** so that they learn better in the next iteration.\n",
    "\n",
    "‚úÖ **Example**:  \n",
    "If the CNN made a mistake in detecting a cat‚Äôs eyes, after backpropagation, the filter responsible for detecting eyes gets **stronger**.\n",
    "\n",
    "## **üìå Key Differences in Backpropagation in CNN vs ANN**\n",
    "| Feature | ANN (Fully Connected) | CNN (Convolutional) |\n",
    "|---------|-----------------------|---------------------|\n",
    "| Weights to update | All neuron connections | Filters/Kernels in Conv layers |\n",
    "| Error Calculation | Each neuron‚Äôs weight | Error backpropagates through convolution operations |\n",
    "| Computation Cost | Lower | Higher (due to convolutional layers) |\n",
    "\n",
    "\n",
    "## **üîπ Summary**\n",
    "‚úÖ **Backpropagation in CNNs** helps filters learn the best features by adjusting kernel weights.  \n",
    "‚úÖ It follows **Forward Pass ‚Üí Loss Calculation ‚Üí Backpropagation ‚Üí Weight Update**.  \n",
    "‚úÖ **Gradient Descent** helps CNN improve its predictions.  \n",
    "‚úÖ CNNs are better at extracting spatial features than ANNs because **filters are updated** rather than just weights.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it's possible to manually calculate a **tiny** CNN example step by step. However, doing a full-fledged CNN manually is very complex due to the sheer number of calculations involved. But I can walk you through a **simplified example** where we calculate a single forward and backward pass for a small **convolutional layer** with a **1x1 filter** on a tiny input.  \n",
    "\n",
    "Let's go step by step. üöÄ  \n",
    "\n",
    "\n",
    "\n",
    "## **üìå Example Setup**\n",
    "We will use a **very small input**, a **single filter (kernel)**, and compute **one forward pass and one backward pass (gradient update).**  \n",
    "\n",
    "üîπ **Input image (3x3 matrix):**\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "  \n",
    "üîπ **Filter (Kernel) (2x2 matrix):**\n",
    "$$\n",
    "W =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "-1 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "üîπ **Stride = 1**, **No Padding**, **Learning Rate = 0.01**  \n",
    "üîπ **Loss function:** Mean Squared Error (MSE)  \n",
    "\n",
    "\n",
    "\n",
    "## **üîπ Step 1: Forward Pass (Convolution Operation)**\n",
    "A **2√ó2 filter** slides over the input (stride = 1), multiplying values and summing them up.\n",
    "\n",
    "### **Computing Convolution Outputs**\n",
    "The filter applies on different 2√ó2 sections of the input:\n",
    "\n",
    "#### **Top-left (First Window)**\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "4 & 5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Applying the filter:\n",
    "$$\n",
    "(1 \\times 1) + (2 \\times 0) + (4 \\times -1) + (5 \\times 2) = 1 + 0 - 4 + 10 = 7\n",
    "$$\n",
    "\n",
    "#### **Top-right (Second Window)**\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "2 & 3 \\\\\n",
    "5 & 6\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "(2 \\times 1) + (3 \\times 0) + (5 \\times -1) + (6 \\times 2) = 2 + 0 - 5 + 12 = 9\n",
    "$$\n",
    "\n",
    "#### **Bottom-left (Third Window)**\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "4 & 5 \\\\\n",
    "7 & 8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "(4 \\times 1) + (5 \\times 0) + (7 \\times -1) + (8 \\times 2) = 4 + 0 - 7 + 16 = 13\n",
    "$$\n",
    "\n",
    "#### **Bottom-right (Fourth Window)**\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "5 & 6 \\\\\n",
    "8 & 9\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "(5 \\times 1) + (6 \\times 0) + (8 \\times -1) + (9 \\times 2) = 5 + 0 - 8 + 18 = 15\n",
    "$$\n",
    "\n",
    "### **Convolution Output (Feature Map)**\n",
    "$$\n",
    "Y =\n",
    "\\begin{bmatrix}\n",
    "7 & 9 \\\\\n",
    "13 & 15\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "## **üîπ Step 2: Compute Loss**\n",
    "Assume the true output (ground truth) is:\n",
    "$$\n",
    "Y_{\\text{true}} =\n",
    "\\begin{bmatrix}\n",
    "6 & 8 \\\\\n",
    "12 & 14\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Using **Mean Squared Error (MSE)**:\n",
    "$$\n",
    "\\text{Loss} = \\frac{1}{4} \\sum (Y - Y_{\\text{true}})^2\n",
    "$$\n",
    "$$\n",
    "= \\frac{1}{4} [(7-6)^2 + (9-8)^2 + (13-12)^2 + (15-14)^2]\n",
    "$$\n",
    "$$\n",
    "= \\frac{1}{4} [1 + 1 + 1 + 1] = \\frac{4}{4} = 1\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "## **üîπ Step 3: Backpropagation (Gradient Calculation)**\n",
    "To update the filter, we compute **gradients of the loss with respect to the filter values**.\n",
    "\n",
    "### **Compute Partial Derivative w.r.t Filter W**\n",
    "Using **Chain Rule**:\n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}}{\\partial W} = \\frac{\\partial \\text{Loss}}{\\partial Y} \\times \\frac{\\partial Y}{\\partial W}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Gradient} = 2(Y - Y_{\\text{true}})\n",
    "$$\n",
    "$$\n",
    "= 2 \\times\n",
    "\\begin{bmatrix}\n",
    "(7-6) & (9-8) \\\\\n",
    "(13-12) & (15-14)\n",
    "\\end{bmatrix}\n",
    "= 2 \\times\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "2 & 2 \\\\\n",
    "2 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Each weight in the **2x2 kernel W** gets a gradient value based on its contribution.\n",
    "\n",
    "\n",
    "\n",
    "## **üîπ Step 4: Update Filter Weights**\n",
    "Using Gradient Descent:\n",
    "$$\n",
    "W_{\\text{new}} = W_{\\text{old}} - \\eta \\times \\text{Gradient}\n",
    "$$\n",
    "Given **learning rate** **Œ∑ = 0.01**:\n",
    "$$\n",
    "W_{\\text{new}} = W - 0.01 \\times\n",
    "\\begin{bmatrix}\n",
    "2 & 2 \\\\\n",
    "2 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_{\\text{new}} =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "-1 & 2\n",
    "\\end{bmatrix}\n",
    "-\n",
    "\\begin{bmatrix}\n",
    "0.02 & 0.02 \\\\\n",
    "0.02 & 0.02\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.98 & -0.02 \\\\\n",
    "-1.02 & 1.98\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "üöÄ **Updated Filter (W_new)**:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.98 & -0.02 \\\\\n",
    "-1.02 & 1.98\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "## **üîπ Final Summary**\n",
    "1Ô∏è‚É£ **Forward pass:** We performed convolution and obtained a **feature map**.  \n",
    "2Ô∏è‚É£ **Computed loss:** Used MSE to measure error.  \n",
    "3Ô∏è‚É£ **Backpropagation:** Found gradients for filters.  \n",
    "4Ô∏è‚É£ **Updated filters:** Using **gradient descent**.  \n",
    "\n",
    "This process repeats for **many iterations** until the filter learns the correct features.\n",
    "\n",
    "\n",
    "\n",
    "## **üîπ Why is Manual Calculation Hard for Larger CNNs?**\n",
    "- **Millions of parameters**: Real CNNs have hundreds of filters, and each filter is updated.\n",
    "- **Matrix operations get complex**: Large images (e.g., 224√ó224) make calculations impractical by hand.\n",
    "- **Backpropagation through multiple layers**: Deeper CNNs need backpropagation across convolutional, pooling, and fully connected layers.\n",
    "\n",
    "But this small example gives you **a clear intuition** of how CNNs **adjust filters** through backpropagation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Backpropagation in CNN ‚Äì A Simple Layman Explanation** üé®  \n",
    "\n",
    "Alright, imagine training a Convolutional Neural Network (CNN) is like **teaching a child how to draw a perfect circle** üé®.  \n",
    "\n",
    "Every time the child tries to draw a circle, you compare it to a **perfect reference circle** and tell them how much they need to improve. The child then **adjusts their hand movements** a little each time, getting better and better.  \n",
    "\n",
    "In CNN, this learning process is done by **Backpropagation**! Let's break it down into **super simple steps.** üöÄ  \n",
    "\n",
    "\n",
    "\n",
    "## **üìå Step 1: Forward Pass ‚Äì Making a Prediction**\n",
    "Think of the CNN as an **artistic robot** üé® that looks at an image and makes a prediction.  \n",
    "üëâ It **processes the image** through layers of filters (like looking at different details of the drawing).  \n",
    "üëâ It **gives an output** (e.g., \"This is a cat\" üê±).  \n",
    "\n",
    "But what if it's wrong? ü§î  \n",
    "\n",
    "\n",
    "\n",
    "## **üìå Step 2: Compute the Error (Loss) ‚Äì How Wrong Were We?**\n",
    "We compare the robot‚Äôs prediction with the **actual answer**.  \n",
    "üí° Example: The model predicts **\"Dog üê∂\"** but the real image is **\"Cat üê±\"**.  \n",
    "\n",
    "The difference between prediction and reality is called **\"Loss\" (Error).** The bigger the error, the worse our model is performing.  \n",
    "\n",
    "\n",
    "\n",
    "## **üìå Step 3: Backpropagation ‚Äì Learning from Mistakes**\n",
    "Backpropagation is like giving **step-by-step drawing corrections** to the robot. üñåÔ∏è  \n",
    "\n",
    "üëâ We need to **find which part of the network made the mistake** ‚Äì was it the filters? The final decision layer? The weights?  \n",
    "üëâ **Each filter (tiny detector in CNN) gets adjusted** based on how much it contributed to the mistake.  \n",
    "\n",
    "Think of this like a teacher giving feedback:  \n",
    "üé® **\"Your circle is too wobbly at the bottom ‚Äì adjust your hand here!\"**  \n",
    "‚úèÔ∏è **\"The top part is too flat, press a bit harder here!\"**  \n",
    "\n",
    "CNN does the same ‚Äì it **adjusts each layer** little by little using **gradients.**  \n",
    "\n",
    "\n",
    "\n",
    "## **üìå Step 4: Gradient Descent ‚Äì Making Small Fixes**\n",
    "Now, how do we adjust the mistakes? ü§î  \n",
    "We use something called **Gradient Descent** (fancy term, but super simple concept).  \n",
    "\n",
    "üí° Imagine you're **walking down a hill** in the dark üåô.  \n",
    "üîπ You **don‚Äôt jump all the way down** (too risky).  \n",
    "üîπ Instead, you **take small steps** ü¶∂ in the direction that goes downhill.  \n",
    "üîπ Eventually, you reach the **lowest point** (minimum error).  \n",
    "\n",
    "CNN does the same! It updates the filter values **little by little** to **reduce the error**.  \n",
    "\n",
    "\n",
    "\n",
    "## **üìå Step 5: Repeat Until It Gets Better**\n",
    "CNN does this process **again and again** until the model learns to **accurately recognize objects**.  \n",
    "üîÑ **Forward pass ‚Üí Compute loss ‚Üí Backpropagation ‚Üí Gradient update ‚Üí Repeat!**  \n",
    "\n",
    "\n",
    "\n",
    "## **üåü Final Takeaway**\n",
    "- CNN **predicts** (draws a circle).  \n",
    "- CNN **compares** with the correct answer (sees mistakes).  \n",
    "- CNN **adjusts** (fixes the mistakes with backpropagation).  \n",
    "- CNN **learns over time** (just like a child practicing drawing!).  \n",
    "\n",
    "After **thousands of trials**, the CNN gets **really good** at identifying objects correctly! üéØ  \n",
    "\n",
    "\n",
    "\n",
    "### **üé® Analogy Summary**\n",
    "üîπ **Forward pass** ‚Üí CNN **draws a picture**.  \n",
    "üîπ **Compute loss** ‚Üí We **check how wrong it is**.  \n",
    "üîπ **Backpropagation** ‚Üí We **find and correct mistakes**.  \n",
    "üîπ **Gradient Descent** ‚Üí We **make small improvements**.  \n",
    "üîπ **Repeat until perfect!**  \n",
    "\n",
    "This is how CNN **learns step by step**, just like a **child learning to draw a perfect shape**. üñåÔ∏è‚ú®  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.1252 - accuracy: 0.9625 - val_loss: 0.0419 - val_accuracy: 0.9858\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 0.0315 - val_accuracy: 0.9901\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 0.0326 - val_accuracy: 0.9893\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0295 - val_accuracy: 0.9912\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0292 - val_accuracy: 0.9910\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0292 - accuracy: 0.9910\n",
      "Test accuracy: 0.9910\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x144 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MNIST dataset (handwritten digits 0-9)\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the data to [0,1] range\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Reshape the data to add a channel dimension (needed for CNNs)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Define a CNN model (LeNet-5 inspired)\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # 10 output classes for digits 0-9\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Predict on test samples\n",
    "predictions = model.predict(x_test[:5])\n",
    "\n",
    "# Plot some test images with predictions\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    ax.set_title(f\"Pred: {np.argmax(predictions[i])}\")\n",
    "    ax.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course! Let me explain your CNN model in **super simple** terms.  \n",
    "\n",
    "\n",
    "\n",
    "### **Imagine your CNN is like a detective solving a case üïµÔ∏è‚Äç‚ôÇÔ∏è**  \n",
    "Your job is to recognize a **number (0-9) from a blurry image**.  \n",
    "To do this, you go through the following steps:\n",
    "\n",
    "\n",
    "\n",
    "### **1Ô∏è‚É£ First Convolutional Layer (Looking for Small Clues üîç)**\n",
    "```python\n",
    "layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1))\n",
    "```\n",
    "‚úÖ This layer **scans** the image **piece by piece (3√ó3 filters)**  \n",
    "‚úÖ It **looks for tiny details** like **edges, curves, and corners**  \n",
    "‚úÖ **Example:** It finds a curved line ‚Üí Maybe it‚Äôs part of the number 3 or 8?\n",
    "\n",
    "\n",
    "\n",
    "### **2Ô∏è‚É£ First Pooling Layer (Keeping the Important Stuff ‚úÖ)**\n",
    "```python\n",
    "layers.MaxPooling2D(pool_size=(2,2))\n",
    "```\n",
    "‚úÖ Think of this like a **zoom-out button** üìè  \n",
    "‚úÖ It keeps only the **strongest clues** and removes unnecessary details  \n",
    "‚úÖ This **reduces the image size** but still **keeps the most important parts**  \n",
    "‚úÖ **Example:** It ignores noise but keeps the main shape of the digit\n",
    "\n",
    "\n",
    "\n",
    "### **3Ô∏è‚É£ Second Convolutional Layer (Finding Bigger Patterns üìä)**\n",
    "```python\n",
    "layers.Conv2D(64, kernel_size=(3,3), activation='relu')\n",
    "```\n",
    "‚úÖ Now, the detective **focuses on bigger features**  \n",
    "‚úÖ Maybe it finds a **loop** ‚Üí Could be a 6, 8, or 9?  \n",
    "‚úÖ It uses **64 filters** to recognize more complex patterns  \n",
    "\n",
    "\n",
    "\n",
    "### **4Ô∏è‚É£ Second Pooling Layer (Another Zoom-Out üîç)**\n",
    "```python\n",
    "layers.MaxPooling2D(pool_size=(2,2))\n",
    "```\n",
    "‚úÖ Again, we **reduce the size** but **keep the most important details**  \n",
    "‚úÖ **Example:** The model now clearly sees a loop ‚Üí It's probably a 6 or 8!\n",
    "\n",
    "\n",
    "\n",
    "### **5Ô∏è‚É£ Flatten Layer (Turning Image into a List üìã)**\n",
    "```python\n",
    "layers.Flatten()\n",
    "```\n",
    "‚úÖ Now, we **unroll the image** into a long list of numbers  \n",
    "‚úÖ Imagine writing down **all clues in a notebook** before making a final decision  \n",
    "\n",
    "\n",
    "\n",
    "### **6Ô∏è‚É£ Fully Connected Layer (Making a Smart Guess üß†)**\n",
    "```python\n",
    "layers.Dense(128, activation='relu')\n",
    "```\n",
    "‚úÖ This layer **connects all clues together**  \n",
    "‚úÖ It tries to match the clues with known patterns  \n",
    "‚úÖ **Example:** If it sees a straight line and a loop ‚Üí It might be a 9!  \n",
    "\n",
    "\n",
    "\n",
    "### **7Ô∏è‚É£ Output Layer (Final Answer! üéØ)**\n",
    "```python\n",
    "layers.Dense(10, activation='softmax')\n",
    "```\n",
    "‚úÖ There are **10 possible answers (0-9)**  \n",
    "‚úÖ The model **chooses the most likely number**  \n",
    "‚úÖ **Example:** \"I'm 90% sure this is a 9 and 10% sure it's a 3\"  \n",
    "\n",
    "\n",
    "\n",
    "### **Final Analogy üé≠**\n",
    "Think of this process like **recognizing a friend in a blurry photo**:  \n",
    "1. üëÄ **Step 1:** You **scan** the image, looking for familiar features.  \n",
    "2. üîç **Step 2:** You **focus on the most important parts** (face, clothes).  \n",
    "3. üß© **Step 3:** You **connect the clues** (glasses, hairstyle, etc.).  \n",
    "4. üéØ **Step 4:** You **make a final decision**: \"Oh, this must be Alex!\"  \n",
    "\n",
    "\n",
    "\n",
    "### **Now, your CNN does the same for numbers!**\n",
    "It **detects tiny features**, **filters out noise**, **combines patterns**, and **makes a smart guess** üî•  \n",
    "\n",
    "I hope this makes it **super clear now**! üòä Let me know if you need **even more simplification**! üöÄ\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
