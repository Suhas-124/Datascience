{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "     |████████████████████████████████| 365 kB 4.2 MB/s            \n",
      "\u001b[?25hCollecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
      "     |████████████████████████████████| 25.6 MB 30.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from datasets) (2.27.1)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "     |████████████████████████████████| 211 kB 7.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from datasets) (4.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: dataclasses in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from datasets) (0.8)\n",
      "Collecting dill<0.3.6\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "     |████████████████████████████████| 86 kB 8.6 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: packaging in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pandas in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from datasets) (1.1.5)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (985 kB)\n",
      "     |████████████████████████████████| 985 kB 19.9 MB/s            \n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py36-none-any.whl (106 kB)\n",
      "     |████████████████████████████████| 106 kB 8.1 MB/s            \n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.17.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "     |████████████████████████████████| 133 kB 31.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from packaging->datasets) (3.0.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (2.0.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: six in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from responses<0.19->datasets) (1.15.0)\n",
      "Requirement already satisfied: importlib-resources in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from tqdm>=4.62.1->datasets) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting idna-ssl>=1.0\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (270 kB)\n",
      "     |████████████████████████████████| 270 kB 26.7 MB/s            \n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (191 kB)\n",
      "     |████████████████████████████████| 191 kB 10.9 MB/s            \n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (159 kB)\n",
      "     |████████████████████████████████| 159 kB 7.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from importlib-metadata->datasets) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/suhas/master_dataklout/venv/lib/python3.6/site-packages (from pandas->datasets) (2021.1)\n",
      "Building wheels for collected packages: idna-ssl\n",
      "  Building wheel for idna-ssl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3178 sha256=ff3a222713b8b0661f146228ea93637a21f7a69ac82c7666663a7a804f53d36d\n",
      "  Stored in directory: /home/suhas/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "Successfully built idna-ssl\n",
      "Installing collected packages: multidict, frozenlist, yarl, idna-ssl, asynctest, aiosignal, fsspec, dill, aiohttp, xxhash, responses, pyarrow, multiprocess, datasets\n",
      "Successfully installed aiohttp-3.8.6 aiosignal-1.2.0 asynctest-0.13.0 datasets-2.4.0 dill-0.3.4 frozenlist-1.2.0 fsspec-2022.1.0 idna-ssl-1.1.0 multidict-5.2.0 multiprocess-0.70.12.2 pyarrow-6.0.1 responses-0.17.0 xxhash-3.2.0 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 4.31kB [00:00, 786kB/s]                    \n",
      "Downloading metadata: 2.17kB [00:00, 908kB/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /home/suhas/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 84.1M/84.1M [01:57<00:00, 714kB/s] \n",
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb downloaded and prepared to /home/suhas/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 791.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the IMDB dataset using the correct identifier\n",
    "ds = load_dataset(\"imdb\")\n",
    "\n",
    "# Check the available splits (train, test, etc.)\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-a...\n",
      "Sentiment: [{'label': 'NEGATIVE', 'score': 0.999616265296936}] \n",
      "\n",
      "Review: Worth the entertainment value of a rental, especially if you like action movies. This one features t...\n",
      "Sentiment: [{'label': 'NEGATIVE', 'score': 0.6170604228973389}] \n",
      "\n",
      "Review: its a totally average film with a few semi-alright action sequences that make the plot seem a little...\n",
      "Sentiment: [{'label': 'NEGATIVE', 'score': 0.9997100234031677}] \n",
      "\n",
      "Review: STAR RATING: ***** Saturday Night **** Friday Night *** Friday Morning ** Sunday Night * Monday Morn...\n",
      "Sentiment: [{'label': 'NEGATIVE', 'score': 0.995756208896637}] \n",
      "\n",
      "Review: First off let me say, If you haven't enjoyed a Van Damme movie since bloodsport, you probably will n...\n",
      "Sentiment: [{'label': 'POSITIVE', 'score': 0.996307373046875}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Let's analyze sentiment on a few sample reviews from the test split\n",
    "for sample in ds[\"test\"].select(range(5)):\n",
    "    result = sentiment_pipeline(sample[\"text\"])\n",
    "    print(f\"Review: {sample['text'][:100]}...\")  # print first 100 characters for brevity\n",
    "    print(\"Sentiment:\", result, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
