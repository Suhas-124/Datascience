{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **🌟 Understanding the Concept of Gradient in Backpropagation 🌟**  \n",
    "\n",
    "In deep learning, **backpropagation** is the magic behind training a neural network. The **gradient** plays a crucial role in this process by guiding how the model updates its weights.  \n",
    "\n",
    "\n",
    "\n",
    "## **🔹 What is a Gradient?**\n",
    "A **gradient** is simply the **slope of a function**.  \n",
    "In deep learning, this function is the **loss function** (which measures how wrong the model is).  \n",
    "The gradient tells us **how much to adjust each weight** to reduce the error.\n",
    "\n",
    "🔹 Mathematically, the gradient is the **derivative** of the loss function with respect to the weights:  \n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}}{\\partial W}\n",
    "$$  \n",
    "This tells us **how a small change in weights (W) affects the loss**.  \n",
    "\n",
    "\n",
    "\n",
    "## **🚀 Step-by-Step Explanation of Gradients in Backpropagation**\n",
    "Backpropagation consists of **two main steps**:  \n",
    "1️⃣ **Forward Propagation** → Compute predictions 🔮  \n",
    "2️⃣ **Backward Propagation (Backprop)** → Compute gradients & update weights 🔄  \n",
    "\n",
    "Let’s go deeper into **step 2 (Backward Propagation)**, where the gradient plays a key role!\n",
    "\n",
    "\n",
    "\n",
    "### **📌 Step 1: Compute the Loss**\n",
    "First, we calculate how wrong the model is using a **loss function**.  \n",
    "For example, if we use **Mean Squared Error (MSE)** for regression:  \n",
    "$$\n",
    "\\text{Loss} = \\frac{1}{N} \\sum (y_{\\text{true}} - y_{\\text{predicted}})^2\n",
    "$$  \n",
    "Or for classification, we often use **Cross-Entropy Loss**:  \n",
    "$$\n",
    "\\text{Loss} = - \\sum y_{\\text{true}} \\log(y_{\\text{predicted}})\n",
    "$$  \n",
    "**Goal:** Minimize this loss by updating weights using gradients.\n",
    "\n",
    "\n",
    "\n",
    "### **📌 Step 2: Compute Gradients (Partial Derivatives)**\n",
    "Using **calculus (chain rule)**, we compute how much **each weight** contributes to the error.\n",
    "\n",
    "Example for a single neuron:\n",
    "$$\n",
    "z = W \\cdot x + b\n",
    "$$\n",
    "$$\n",
    "a = \\text{activation}(z)\n",
    "$$\n",
    "$$\n",
    "\\text{Loss} = f(a, y)\n",
    "$$\n",
    "\n",
    "To update the weights, we compute:\n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}}{\\partial W} = \\frac{\\partial \\text{Loss}}{\\partial a} \\times \\frac{\\partial a}{\\partial z} \\times \\frac{\\partial z}{\\partial W}\n",
    "$$\n",
    "\n",
    "This gives us the **gradient**, which tells us how much to update **W**.\n",
    "\n",
    "\n",
    "\n",
    "### **📌 Step 3: Update Weights Using Gradient Descent**\n",
    "Now that we have the gradients, we use **Gradient Descent** to update the weights.\n",
    "\n",
    "$$\n",
    "W_{\\text{new}} = W_{\\text{old}} - \\eta \\cdot \\frac{\\partial \\text{Loss}}{\\partial W}\n",
    "$$\n",
    "\n",
    "🔹 Here, **η (eta)** is the **learning rate**, controlling how big the updates are.  \n",
    "\n",
    "\n",
    "\n",
    "## **📌 Example: Manual Gradient Calculation**\n",
    "Let’s say we have a simple model:\n",
    "\n",
    "$$\n",
    "y = W \\cdot x + b\n",
    "$$\n",
    "\n",
    "Suppose:\n",
    "- **W = 2**, **b = 1**\n",
    "- **x = 3**\n",
    "- True **y = 10**\n",
    "- Our model predicts:  \n",
    "  $$\n",
    "  y_{\\text{pred}} = (2 \\times 3) + 1 = 7\n",
    "  $$\n",
    "\n",
    "Loss (Mean Squared Error):\n",
    "$$\n",
    "\\text{Loss} = (10 - 7)^2 = 9\n",
    "$$\n",
    "\n",
    "### **🔹 Compute Gradient**\n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}}{\\partial W} = 2 \\times (y_{\\text{pred}} - y_{\\text{true}}) \\times x\n",
    "$$\n",
    "$$\n",
    "= 2 \\times (7 - 10) \\times 3 = -18\n",
    "$$\n",
    "\n",
    "### **🔹 Update Weight**\n",
    "Using learning rate **η = 0.01**:\n",
    "$$\n",
    "W_{\\text{new}} = W_{\\text{old}} - 0.01 \\times (-18)\n",
    "$$\n",
    "$$\n",
    "= 2 + 0.18 = 2.18\n",
    "$$\n",
    "\n",
    "The weight **W** is updated from **2 to 2.18**, reducing the error in the next step.\n",
    "\n",
    "\n",
    "\n",
    "## **🌟 Summary: Why is the Gradient Important?**\n",
    "- The gradient tells **how much** to update weights in backpropagation.\n",
    "- It’s calculated using **partial derivatives** (chain rule).\n",
    "- We use **gradient descent** to adjust the weights **step by step**.\n",
    "- Small **gradients** → slow learning 📉  \n",
    "- Large **gradients** → unstable learning 📈  \n",
    "- A **proper learning rate** is needed to balance updates ⚖️  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **🌟 Understanding Minima & Convergence in Backpropagation 🌟**  \n",
    "\n",
    "Backpropagation works by adjusting the model's weights **step by step** to reduce the **loss function** (error).  \n",
    "The ultimate goal? **Find the best set of weights that minimizes the loss**. This process leads us to the concepts of **Minima** and **Convergence**.  \n",
    "\n",
    "\n",
    "\n",
    "## **🔹 What is a Minima?**\n",
    "A **minima** is a point where the **loss function is at its lowest** (or at least a local low point).  \n",
    "Since training a deep learning model is like finding the lowest point in a mountain range, we use **gradient descent** to navigate towards the **minima** step by step.\n",
    "\n",
    "🔹 **Types of Minima:**  \n",
    "1️⃣ **Global Minima** 🌍 → The lowest possible loss value  \n",
    "2️⃣ **Local Minima** 🏔️ → A low point, but not necessarily the lowest  \n",
    "3️⃣ **Saddle Point** ⚖️ → A flat region where gradients become very small  \n",
    "\n",
    "**Goal:** We want to reach the **global minima** (or at least a good local minima) where our model has the **best accuracy**.\n",
    "\n",
    "\n",
    "\n",
    "## **🔹 What is Convergence?**\n",
    "**Convergence** means that the model’s loss is **not decreasing anymore**, meaning it has reached a stable point.  \n",
    "\n",
    "🔹 **How does this happen?**\n",
    "- During backpropagation, we **update weights** using **gradient descent**.\n",
    "- If the steps are too large → We might **overshoot** the minima.  \n",
    "- If the steps are too small → The training **takes forever**.  \n",
    "- If the gradient becomes **almost zero** → The model **converged**.\n",
    "\n",
    "\n",
    "\n",
    "## **🚀 Step-by-Step Explanation of Minima & Convergence in Backpropagation**\n",
    "\n",
    "### **📌 Step 1: Compute Gradient (Direction of Movement)**\n",
    "The **gradient** tells us **which direction to move** to reduce the loss:\n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}}{\\partial W}\n",
    "$$\n",
    "\n",
    "### **📌 Step 2: Update Weights (Move Toward Minima)**\n",
    "We use **Gradient Descent** to update the weights:\n",
    "$$\n",
    "W_{\\text{new}} = W_{\\text{old}} - \\eta \\cdot \\frac{\\partial \\text{Loss}}{\\partial W}\n",
    "$$\n",
    "\n",
    "### **📌 Step 3: Check if We Reached Minima (Convergence)**\n",
    "If the **gradient is close to zero**, the model has likely **converged**.\n",
    "\n",
    "\n",
    "\n",
    "## **🌟 Example: Visualizing Minima & Convergence**\n",
    "Imagine a **bowl-shaped** loss function:\n",
    "\n",
    "🔹 If we **start at the top**, the **gradient is large**, so we take **big steps** downhill.  \n",
    "🔹 As we **get closer to the bottom**, the **gradient gets smaller**, and we take **smaller steps**.  \n",
    "🔹 When the **gradient is nearly zero**, we **stop updating weights** → **Convergence!**  \n",
    "\n",
    "\n",
    "\n",
    "## **📌 Example: Code for Minima & Convergence**\n",
    "Let’s visualize this with **Gradient Descent** in Python! 🚀  \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a simple loss function (parabola: y = x^2)\n",
    "def loss_function(x):\n",
    "    return x ** 2\n",
    "\n",
    "# Define the gradient (derivative of loss function)\n",
    "def gradient(x):\n",
    "    return 2 * x\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "x = 5  # Start at x=5 (far from minima)\n",
    "learning_rate = 0.1  # Step size\n",
    "history = [x]  # Store path of x\n",
    "\n",
    "# Run gradient descent for 20 steps\n",
    "for i in range(20):\n",
    "    grad = gradient(x)  # Compute gradient\n",
    "    x = x - learning_rate * grad  # Update x\n",
    "    history.append(x)  # Store new x\n",
    "\n",
    "# Plot the loss function\n",
    "x_vals = np.linspace(-6, 6, 100)\n",
    "y_vals = loss_function(x_vals)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_vals, y_vals, label=\"Loss Function\")\n",
    "plt.scatter(history, loss_function(np.array(history)), color=\"red\", label=\"Gradient Descent Steps\")\n",
    "plt.xlabel(\"Weight (x)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Finding the Minima Using Gradient Descent\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "### **🔹 What Happens Here?**\n",
    "✅ The model **starts at x=5** and gradually moves toward **x=0** (global minima).  \n",
    "✅ The learning rate controls **how fast we move**.  \n",
    "✅ The gradient decreases as we approach the **minima**, leading to **convergence**.  \n",
    "\n",
    "\n",
    "\n",
    "## **📌 Factors Affecting Convergence**\n",
    "1️⃣ **Learning Rate (η)**\n",
    "   - Too **high** → Overshooting 🏹  \n",
    "   - Too **low** → Slow training 🐌  \n",
    "   - **Optimal** → Fast & smooth convergence  \n",
    "\n",
    "2️⃣ **Loss Function Shape**\n",
    "   - If the function is **complex**, it may have **multiple local minima**.\n",
    "   - Some optimizers (like Adam) help avoid getting **stuck in bad local minima**.\n",
    "\n",
    "3️⃣ **Number of Iterations (Epochs)**\n",
    "   - Too **few** → No convergence 🚫  \n",
    "   - Too **many** → Wastes resources 🔋  \n",
    "\n",
    "\n",
    "\n",
    "## **🌟 Summary: Why are Minima & Convergence Important?**\n",
    "- **Minima** → The point where the loss is at its lowest.  \n",
    "- **Convergence** → When the model reaches a stable point with minimal loss.  \n",
    "- **Gradient Descent** helps us move toward the minima by updating weights.  \n",
    "- Choosing the **right learning rate** ensures smooth convergence.  \n",
    "\n",
    "![](images/bkp.png)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
