{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ğŸŒŸ Understanding the Concept of Gradient in Backpropagation ğŸŒŸ**  \n",
    "\n",
    "In deep learning, **backpropagation** is the magic behind training a neural network. The **gradient** plays a crucial role in this process by guiding how the model updates its weights.  \n",
    "\n",
    "\n",
    "\n",
    "## **ğŸ”¹ What is a Gradient?**\n",
    "A **gradient** is simply the **slope of a function**.  \n",
    "In deep learning, this function is the **loss function** (which measures how wrong the model is).  \n",
    "The gradient tells us **how much to adjust each weight** to reduce the error.\n",
    "\n",
    "ğŸ”¹ Mathematically, the gradient is the **derivative** of the loss function with respect to the weights:  \n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}}{\\partial W}\n",
    "$$  \n",
    "This tells us **how a small change in weights (W) affects the loss**.  \n",
    "\n",
    "\n",
    "\n",
    "## **ğŸš€ Step-by-Step Explanation of Gradients in Backpropagation**\n",
    "Backpropagation consists of **two main steps**:  \n",
    "1ï¸âƒ£ **Forward Propagation** â†’ Compute predictions ğŸ”®  \n",
    "2ï¸âƒ£ **Backward Propagation (Backprop)** â†’ Compute gradients & update weights ğŸ”„  \n",
    "\n",
    "Letâ€™s go deeper into **step 2 (Backward Propagation)**, where the gradient plays a key role!\n",
    "\n",
    "\n",
    "\n",
    "### **ğŸ“Œ Step 1: Compute the Loss**\n",
    "First, we calculate how wrong the model is using a **loss function**.  \n",
    "For example, if we use **Mean Squared Error (MSE)** for regression:  \n",
    "$$\n",
    "\\text{Loss} = \\frac{1}{N} \\sum (y_{\\text{true}} - y_{\\text{predicted}})^2\n",
    "$$  \n",
    "Or for classification, we often use **Cross-Entropy Loss**:  \n",
    "$$\n",
    "\\text{Loss} = - \\sum y_{\\text{true}} \\log(y_{\\text{predicted}})\n",
    "$$  \n",
    "**Goal:** Minimize this loss by updating weights using gradients.\n",
    "\n",
    "\n",
    "\n",
    "### **ğŸ“Œ Step 2: Compute Gradients (Partial Derivatives)**\n",
    "Using **calculus (chain rule)**, we compute how much **each weight** contributes to the error.\n",
    "\n",
    "Example for a single neuron:\n",
    "$$\n",
    "z = W \\cdot x + b\n",
    "$$\n",
    "$$\n",
    "a = \\text{activation}(z)\n",
    "$$\n",
    "$$\n",
    "\\text{Loss} = f(a, y)\n",
    "$$\n",
    "\n",
    "To update the weights, we compute:\n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}}{\\partial W} = \\frac{\\partial \\text{Loss}}{\\partial a} \\times \\frac{\\partial a}{\\partial z} \\times \\frac{\\partial z}{\\partial W}\n",
    "$$\n",
    "\n",
    "This gives us the **gradient**, which tells us how much to update **W**.\n",
    "\n",
    "\n",
    "\n",
    "### **ğŸ“Œ Step 3: Update Weights Using Gradient Descent**\n",
    "Now that we have the gradients, we use **Gradient Descent** to update the weights.\n",
    "\n",
    "$$\n",
    "W_{\\text{new}} = W_{\\text{old}} - \\eta \\cdot \\frac{\\partial \\text{Loss}}{\\partial W}\n",
    "$$\n",
    "\n",
    "ğŸ”¹ Here, **Î· (eta)** is the **learning rate**, controlling how big the updates are.  \n",
    "\n",
    "\n",
    "\n",
    "## **ğŸ“Œ Example: Manual Gradient Calculation**\n",
    "Letâ€™s say we have a simple model:\n",
    "\n",
    "$$\n",
    "y = W \\cdot x + b\n",
    "$$\n",
    "\n",
    "Suppose:\n",
    "- **W = 2**, **b = 1**\n",
    "- **x = 3**\n",
    "- True **y = 10**\n",
    "- Our model predicts:  \n",
    "  $$\n",
    "  y_{\\text{pred}} = (2 \\times 3) + 1 = 7\n",
    "  $$\n",
    "\n",
    "Loss (Mean Squared Error):\n",
    "$$\n",
    "\\text{Loss} = (10 - 7)^2 = 9\n",
    "$$\n",
    "\n",
    "### **ğŸ”¹ Compute Gradient**\n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}}{\\partial W} = 2 \\times (y_{\\text{pred}} - y_{\\text{true}}) \\times x\n",
    "$$\n",
    "$$\n",
    "= 2 \\times (7 - 10) \\times 3 = -18\n",
    "$$\n",
    "\n",
    "### **ğŸ”¹ Update Weight**\n",
    "Using learning rate **Î· = 0.01**:\n",
    "$$\n",
    "W_{\\text{new}} = W_{\\text{old}} - 0.01 \\times (-18)\n",
    "$$\n",
    "$$\n",
    "= 2 + 0.18 = 2.18\n",
    "$$\n",
    "\n",
    "The weight **W** is updated from **2 to 2.18**, reducing the error in the next step.\n",
    "\n",
    "\n",
    "\n",
    "## **ğŸŒŸ Summary: Why is the Gradient Important?**\n",
    "- The gradient tells **how much** to update weights in backpropagation.\n",
    "- Itâ€™s calculated using **partial derivatives** (chain rule).\n",
    "- We use **gradient descent** to adjust the weights **step by step**.\n",
    "- Small **gradients** â†’ slow learning ğŸ“‰  \n",
    "- Large **gradients** â†’ unstable learning ğŸ“ˆ  \n",
    "- A **proper learning rate** is needed to balance updates âš–ï¸  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ğŸŒŸ Understanding Minima & Convergence in Backpropagation ğŸŒŸ**  \n",
    "\n",
    "Backpropagation works by adjusting the model's weights **step by step** to reduce the **loss function** (error).  \n",
    "The ultimate goal? **Find the best set of weights that minimizes the loss**. This process leads us to the concepts of **Minima** and **Convergence**.  \n",
    "\n",
    "\n",
    "\n",
    "## **ğŸ”¹ What is a Minima?**\n",
    "A **minima** is a point where the **loss function is at its lowest** (or at least a local low point).  \n",
    "Since training a deep learning model is like finding the lowest point in a mountain range, we use **gradient descent** to navigate towards the **minima** step by step.\n",
    "\n",
    "ğŸ”¹ **Types of Minima:**  \n",
    "1ï¸âƒ£ **Global Minima** ğŸŒ â†’ The lowest possible loss value  \n",
    "2ï¸âƒ£ **Local Minima** ğŸ”ï¸ â†’ A low point, but not necessarily the lowest  \n",
    "3ï¸âƒ£ **Saddle Point** âš–ï¸ â†’ A flat region where gradients become very small  \n",
    "\n",
    "**Goal:** We want to reach the **global minima** (or at least a good local minima) where our model has the **best accuracy**.\n",
    "\n",
    "\n",
    "\n",
    "## **ğŸ”¹ What is Convergence?**\n",
    "**Convergence** means that the modelâ€™s loss is **not decreasing anymore**, meaning it has reached a stable point.  \n",
    "\n",
    "ğŸ”¹ **How does this happen?**\n",
    "- During backpropagation, we **update weights** using **gradient descent**.\n",
    "- If the steps are too large â†’ We might **overshoot** the minima.  \n",
    "- If the steps are too small â†’ The training **takes forever**.  \n",
    "- If the gradient becomes **almost zero** â†’ The model **converged**.\n",
    "\n",
    "\n",
    "\n",
    "## **ğŸš€ Step-by-Step Explanation of Minima & Convergence in Backpropagation**\n",
    "\n",
    "### **ğŸ“Œ Step 1: Compute Gradient (Direction of Movement)**\n",
    "The **gradient** tells us **which direction to move** to reduce the loss:\n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}}{\\partial W}\n",
    "$$\n",
    "\n",
    "### **ğŸ“Œ Step 2: Update Weights (Move Toward Minima)**\n",
    "We use **Gradient Descent** to update the weights:\n",
    "$$\n",
    "W_{\\text{new}} = W_{\\text{old}} - \\eta \\cdot \\frac{\\partial \\text{Loss}}{\\partial W}\n",
    "$$\n",
    "\n",
    "### **ğŸ“Œ Step 3: Check if We Reached Minima (Convergence)**\n",
    "If the **gradient is close to zero**, the model has likely **converged**.\n",
    "\n",
    "\n",
    "\n",
    "## **ğŸŒŸ Example: Visualizing Minima & Convergence**\n",
    "Imagine a **bowl-shaped** loss function:\n",
    "\n",
    "ğŸ”¹ If we **start at the top**, the **gradient is large**, so we take **big steps** downhill.  \n",
    "ğŸ”¹ As we **get closer to the bottom**, the **gradient gets smaller**, and we take **smaller steps**.  \n",
    "ğŸ”¹ When the **gradient is nearly zero**, we **stop updating weights** â†’ **Convergence!**  \n",
    "\n",
    "\n",
    "\n",
    "## **ğŸ“Œ Example: Code for Minima & Convergence**\n",
    "Letâ€™s visualize this with **Gradient Descent** in Python! ğŸš€  \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a simple loss function (parabola: y = x^2)\n",
    "def loss_function(x):\n",
    "    return x ** 2\n",
    "\n",
    "# Define the gradient (derivative of loss function)\n",
    "def gradient(x):\n",
    "    return 2 * x\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "x = 5  # Start at x=5 (far from minima)\n",
    "learning_rate = 0.1  # Step size\n",
    "history = [x]  # Store path of x\n",
    "\n",
    "# Run gradient descent for 20 steps\n",
    "for i in range(20):\n",
    "    grad = gradient(x)  # Compute gradient\n",
    "    x = x - learning_rate * grad  # Update x\n",
    "    history.append(x)  # Store new x\n",
    "\n",
    "# Plot the loss function\n",
    "x_vals = np.linspace(-6, 6, 100)\n",
    "y_vals = loss_function(x_vals)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_vals, y_vals, label=\"Loss Function\")\n",
    "plt.scatter(history, loss_function(np.array(history)), color=\"red\", label=\"Gradient Descent Steps\")\n",
    "plt.xlabel(\"Weight (x)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Finding the Minima Using Gradient Descent\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "### **ğŸ”¹ What Happens Here?**\n",
    "âœ… The model **starts at x=5** and gradually moves toward **x=0** (global minima).  \n",
    "âœ… The learning rate controls **how fast we move**.  \n",
    "âœ… The gradient decreases as we approach the **minima**, leading to **convergence**.  \n",
    "\n",
    "\n",
    "\n",
    "## **ğŸ“Œ Factors Affecting Convergence**\n",
    "1ï¸âƒ£ **Learning Rate (Î·)**\n",
    "   - Too **high** â†’ Overshooting ğŸ¹  \n",
    "   - Too **low** â†’ Slow training ğŸŒ  \n",
    "   - **Optimal** â†’ Fast & smooth convergence  \n",
    "\n",
    "2ï¸âƒ£ **Loss Function Shape**\n",
    "   - If the function is **complex**, it may have **multiple local minima**.\n",
    "   - Some optimizers (like Adam) help avoid getting **stuck in bad local minima**.\n",
    "\n",
    "3ï¸âƒ£ **Number of Iterations (Epochs)**\n",
    "   - Too **few** â†’ No convergence ğŸš«  \n",
    "   - Too **many** â†’ Wastes resources ğŸ”‹  \n",
    "\n",
    "\n",
    "\n",
    "## **ğŸŒŸ Summary: Why are Minima & Convergence Important?**\n",
    "- **Minima** â†’ The point where the loss is at its lowest.  \n",
    "- **Convergence** â†’ When the model reaches a stable point with minimal loss.  \n",
    "- **Gradient Descent** helps us move toward the minima by updating weights.  \n",
    "- Choosing the **right learning rate** ensures smooth convergence.  \n",
    "\n",
    "![](images/bkp.png)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
