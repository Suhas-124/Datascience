{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/suhas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/suhas/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download reuired nltk resources\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Suhas', 'is', 'learning', 'POS', 'tagging', 'using', 'Python', '.']\n",
      "\n",
      " POS Tags: [('Suhas', 'NNP'), ('is', 'VBZ'), ('learning', 'VBG'), ('POS', 'NNP'), ('tagging', 'VBG'), ('using', 'VBG'), ('Python', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Sample sentence\n",
    "sentence = \"Suhas is learning POS tagging using Python.\"\n",
    "\n",
    "# step: 1  Tokenize the sentence\n",
    "tokens = word_tokenize(sentence)\n",
    "print(\"Tokens:\",tokens)\n",
    "\n",
    "# step 2: Apply POS tagging\n",
    "pos_tags = pos_tag(tokens)\n",
    "print(\"\\n POS Tags:\",pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of POST Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/suhas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/suhas/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "data = {\n",
    "    \"sentence\": [\n",
    "        \"I love this product.\", \"This is a bad experience.\", \"The service was great.\", \n",
    "        \"I will never buy this again.\", \"Excellent quality and amazing service.\", \n",
    "        \"The food was terrible.\", \"Highly recommend this item.\", \"Very disappointed with the purchase.\", \n",
    "        \"The movie was fantastic.\", \"It was a complete waste of time.\",\n",
    "    ] * 20,\n",
    "    \"label\": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0] * 20\n",
    "}\n",
    "\n",
    "# convert into dataframe\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this product.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a bad experience.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The service was great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I will never buy this again.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excellent quality and amazing service.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>The food was terrible.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Highly recommend this item.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Very disappointed with the purchase.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>The movie was fantastic.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>It was a complete waste of time.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentence  label\n",
       "0                      I love this product.      1\n",
       "1                 This is a bad experience.      0\n",
       "2                    The service was great.      1\n",
       "3              I will never buy this again.      0\n",
       "4    Excellent quality and amazing service.      1\n",
       "..                                      ...    ...\n",
       "195                  The food was terrible.      0\n",
       "196             Highly recommend this item.      1\n",
       "197    Very disappointed with the purchase.      0\n",
       "198                The movie was fantastic.      1\n",
       "199        It was a complete waste of time.      0\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and apply pos tagging\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "def tokenize_and_pos_tagging(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tags = pos_tag(tokens)\n",
    "    return \" \".join([f\"{word}_{tag}\" for word,tag in tags])\n",
    "\n",
    "#Apply pos tagging\n",
    "df['pos_tags'] = df['sentence'].apply(tokenize_and_pos_tagging)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this product.</td>\n",
       "      <td>1</td>\n",
       "      <td>I_PRP love_VBP this_DT product_NN ._.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a bad experience.</td>\n",
       "      <td>0</td>\n",
       "      <td>This_DT is_VBZ a_DT bad_JJ experience_NN ._.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The service was great.</td>\n",
       "      <td>1</td>\n",
       "      <td>The_DT service_NN was_VBD great_JJ ._.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I will never buy this again.</td>\n",
       "      <td>0</td>\n",
       "      <td>I_PRP will_MD never_RB buy_VB this_DT again_RB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excellent quality and amazing service.</td>\n",
       "      <td>1</td>\n",
       "      <td>Excellent_JJ quality_NN and_CC amazing_JJ serv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence  label  \\\n",
       "0                    I love this product.      1   \n",
       "1               This is a bad experience.      0   \n",
       "2                  The service was great.      1   \n",
       "3            I will never buy this again.      0   \n",
       "4  Excellent quality and amazing service.      1   \n",
       "\n",
       "                                            pos_tags  \n",
       "0              I_PRP love_VBP this_DT product_NN ._.  \n",
       "1       This_DT is_VBZ a_DT bad_JJ experience_NN ._.  \n",
       "2             The_DT service_NN was_VBD great_JJ ._.  \n",
       "3  I_PRP will_MD never_RB buy_VB this_DT again_RB...  \n",
       "4  Excellent_JJ quality_NN and_CC amazing_JJ serv...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: convert text to numerical features using TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset into featuers X and labels y\n",
    "\n",
    "X = df['pos_tags']\n",
    "y = df['label']\n",
    "\n",
    "#convert text to numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# split into training and testing sets\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(x_vectorized,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = LogisticRegression()\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Make Predications\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print('accuracy:',accuracy)\n",
    "\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I am very happy with this service.\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Sentence: The product quality is awful.\n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Sentence: Amazing experience!\n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Sentence: I would not recommend this.\n",
      "Predicted Sentiment: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict sentiment for new sentences\n",
    "\n",
    "def predict_sentiment(sentence):\n",
    "    pos_tagging = tokenize_and_pos_tagging(sentence)\n",
    "    x_vectorized = vectorizer.transform([pos_tagging])\n",
    "    prediction = model.predict(x_vectorized)[0]\n",
    "    sentiment = \"positive\" if prediction == 1 else \"negative\"\n",
    "    return sentiment\n",
    "\n",
    "# Test new sentences\n",
    "new_sentences = [\n",
    "    \"I am very happy with this service.\", \n",
    "    \"The product quality is awful.\", \n",
    "    \"Amazing experience!\", \n",
    "    \"I would not recommend this.\"\n",
    "]\n",
    "\n",
    "for sentence in new_sentences:\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Predicted Sentiment: {predict_sentiment(sentence)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
